# 								Real-Time Rendering 4th																											

## 1.介绍

### 1.2符号和定义

​		首先，我们将解释本书中使用的数学符号。有关本节以及整本书中使用的许多术语的更详尽说明，请访问realtimerendering.com获取我们的线性代数附录。

#### 1.2.1数学定义

​		表1.1总结了我们将使用的大多数数学符号。一些概念将在这里详细描述。

​		请注意，表中的规则有一些例外，主要是着色方程使用在文献中已经极为完善的符号表示法，例如L

代表辐射度，E代表辐照度，$$\sigma_s$$代表散射系数。

​		角度和标量取自$$\mathbb{R}$$，即它们是实数。矢量和点用粗体小写字母表示，并且访问方式为

​	**向量**：
$$
\vec v=
\begin{gather*}
\begin{pmatrix}
v_x \\v_y \\v_z\\v_w
\end{pmatrix}
\end{gather*}
$$
​		列向量格式是计算机图形学世界中常用的格式。在本书的某些地方，我们使用$$(v_x,v_y,v_z)$$代替更正确的形式$$(v_x,v_y,v_z)^T$$，因为前者更容易阅读.


|            类型            |                           注意事项                           |                             例子                             |
| :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|        角度(angle)         |                         小写希腊字母                         |          $$\alpha_i,\eta,\beta,\theta,\gamma_{60}$$          |
|        因子(scalar)        | 小写英文字母*<kbd><font color=#0099ff size=4>斜体</font></kbd>* |                    *$$a,b,c,u_k,w_{ij}$$*                    |
| 向量或点(vector or point)  |     小写英文字母<kbd><font size=4>**粗体**</font></kbd>      | $$\textbf{a},\textbf{u},\textbf{v}_s,\textbf{h}(\rho),\textbf{h}_z$$ |
|        矩阵(matrix)        |         大写<kbd><font size=4>**粗体**</font></kbd>          |   $$\textbf{T}(\textbf{t}),\textbf{X},\textbf{R}_x(\rho)$$   |
|        平面(plane)         |            $\pi$:法向量点乘平面内任意向量加上因子            | $$\pi:\textbf{n}\cdot\textbf{x}+d=0\\\pi_1:\textbf{n}_1\cdot\textbf{x}+d_1=0\\$$ |
|      三角形(triangle)      |                           △和3个点                           | $$\triangle{\textbf{v}_0\textbf{v}_1\textbf{v}_2},\triangle\textbf{cba}$$ |
|     线段(line segment)     |                            两个点                            |           $$\textbf{uv},\textbf{a}_i\textbf{b}_j$$           |
| 几何物体(geometric entity) |    大写*<kbd><font color=#0099f size=4>斜体</font></kbd>*    |                   *$$A_{OBB},T,B_{AABB}$$*                   |

​		<font size=2>表1.1本书中所用符号的摘要。</font>

大写，小写

希腊字母，英文字母

粗体，非粗体

斜体，非斜体

|      |                            运算符                            |     描述     |
| :--: | :----------------------------------------------------------: | :----------: |
|  1   |                          $$\cdot$$                           |     点乘     |
|  2   |                          $$\times$$                          |     叉乘     |
|  3   |                       $$\textbf{v}^T$$                       |  向量的转置  |
|  4   |                           $$\bot$$                           |    逆运算    |
|  5   |               $$\lvert\quad\cdot\quad\rvert$$                |    绝对值    |
|  6   |               $$\lvert\quad\cdot\quad\rvert$$                | 矩阵的行列式 |
|  7   |               $$\lVert\quad\cdot\quad\rVert$$                |  结构的长度  |
|  8   |                          $$x^{+}$$                           | x的值不小于0 |
|  9   |                         $$x^{\mp}$$                          |  x限制在0~1  |
|  10  |                            $$n!$$                            |     梯乘     |
|  11  | $$\begin{gather*}\begin{pmatrix}n\\k\end{pmatrix}\end{gather*}$$ |  二项式系数  |


$$
x^{+}=

\begin{cases}
x,&x>0\\
0,&otherwise
\end{cases}
$$

$$
x^{\mp}=
\begin{cases}
1,\qquad if&x\geq1,\\
x,\qquad if&0<x<1,\\
0,&otherwise.
\end{cases}
$$



$$
n!=n(n-1)(n-2)\cdot\cdot\cdot3\cdot2\cdot1
$$


$$
\begin{gather*}\begin{pmatrix}n\\k\end{pmatrix}\end{gather*}=
\frac{n!}{k!(n-k!)!}
$$


|      |      函数      | 描述 |
| :--: | :------------: | :--: |
|  1   | $$atan2(y,x)$$ |      |
|  2   |   $$log(n)$$   |      |

#### 1.2.2几何定义

​		所有图形硬件使用的基础渲染图元是由点，线，三角形组成的。

​		在这本书中，我们把几何实体的集合称为模型或者对象。场景是所有包含在环境中被渲染的模型的集合，同时场景还包含光源，材质描述，视图大小。

​		举个例子，比如说一辆车，一栋建筑，甚至是一条线。实际上，一个对象经常由一组渲染图元组成，但有特殊情况。一个对象可能具有相比基础渲染图元更高阶的几何表示，比如bezier曲线和表面，或者再细分的表面。当然，对象可以由其他的对象组成，比如一辆车包含4个车门，4个车轮等等。		

#### 1.2.3着色

​		遵循在计算机图形学中公认的用法，在本书中，术语 shading（着色），shader（着色器）和及其相关联的词用于指两个不同但相关的概念：计算机生成的视觉外观（例如着色模型，着色方程，卡通着色”）或者渲染系统中可编程组件（例如顶点着色器，着色语言）。不论哪种情况，指代的概念都会在其上下文中描述清楚。

#### 进一步阅读和资源

​		我们可以为您推荐的最重要资源是本书的网站：realtimerendering.com。它包含指向每个章节的最新信息和网站的链接。实时渲染的领域实时变化。在本书中，我们尝试着眼于基本概念和不太可能过时的技术。在网站上，我们有机会介绍与当今的软件开发人员相关的信息，并且我们能够使其保持最新状态。
















## 2.渲染管线

​		本章介绍了实时图形的核心组件，即图形渲染管道，也简称为“管道”。管道的主要功能是在给定虚拟摄像机的情况下生成或渲染二维图像，三维物体，光源等。因此，渲染管道是实时渲染的基础工具。使用管道的过程如图2.1所示。图像中对象的位置和形状由其几何形状，环境特征以及相机在该环境中的位置决定。对象的外观受材质属性，光源，纹理（应用于表面的图像）和着色方程的影响。

![1568991361207](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1568991361207.png)

​		<font size=2>图2.1。在左图中，虚拟摄像机位于金字塔的顶端（四条线会聚的点）。仅渲染视图体积内的基元。对于以透视方式呈现的图像（如这里的情况），视图体积是平截头体，即一个头部被截取的棱椎。右图显示了相机“看到的内容”。请注意，左图中的红色圆环形状不在右侧渲染中，因为它位于视锥体外。此外，左图像中的扭曲蓝色棱镜被夹在平截头体的顶平面上。</font>

​		我们将解释渲染管道的不同阶段，重点是功能而不是实现。应用这些阶段的相关细节将在后面的章节中介绍。

### 2.1结构

​		在物理世界中，管道概念以许多不同的形式表现出来，从工厂装配线到快餐厨房。它也适用于图形渲染。管道由若干阶段组成，每个阶段执行庞大任务的一部分。

​		流水线的每个阶段是并行执行的，每个阶段取决于前一阶段的结果。理想情况下，一个非流水线系统被划分成n个流水线阶段，可以带来n倍的速度提升。性能的提高是使用流水线操作的主要原因。例如，一堆数量庞大的三明治可以被一些分工好的工人快速准备好 —— 一个准备面包，另一个添加肉，另一个添加配料。每个人都将自己的结果传递给下一个人，并立即开始下一个三明治的工作。如果每个人花费20秒来执行他们的任务，则每20秒，每分钟三次，最大速率可以生产一个三明治。尽管流水线是并行执行的，但它们会被拖延直到最慢的阶段完成其任务。例如，假设肉类添加阶段变得更加复杂，需要30秒。现在最好的速度是一分钟两个三明治。在这个特殊的流水线，肉类阶段是瓶颈，因为它决定了整个生产的速度。于是配料阶段在等待肉类阶段的完成时处于饥饿状态（对于顾客也是）。

​		这种管道结构也可以在实时计算机图形的背景下找到。将实时渲染管线粗略划分为四个主要阶段 - **应用，几何处理，光栅化和像素处理** - 如图2.2所示。这种结构是渲染管线的核心在实时计算机图形应用程序中，因此是后续章节中讨论的重要基础。这些阶段通常又是一个管线，这意味着它由几个子阶段组成。我们区分这里显示的功能阶段和它们的实现结构。功能阶段有明确的任务要执行，但没有指定任务在管线中执行的方式。给定的实现可以将两个功能阶段组合成一个单元或者执行使用可编程核心，同时将另一个更耗时的功能阶段划分为多个硬件单元。

![1568994209724](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1568994209724.png)

<font size=2>		图2.2。渲染管道的基本构造，包括四个阶段：应用程序，几何处理，光栅化和像素处理。这些阶段中的每一个本身可以是管线，如几何处理阶段下面所示，或者阶段可以（部分）并行化，如像素处理阶段所示。在此图示中，应用程序阶段是单个进程，但此阶段也可以是流水线或并行化的。注意，光栅化找到图元内的像素，例如三角形。</font>

渲染速度可以以每秒帧数（FPS）表示，即每秒渲染的图像的数量。它也可以用赫兹（Hz）表示，它只是1 /秒的符号，即更新的频率。通常以毫秒（ms）表示渲染图像所需的时间。生成图像的时间通常会有所不同，具体取决于每帧期间执行的计算的复杂程度。每秒帧数用于表示特定帧的速率，或表示某个使用持续时间内的平均性能。赫兹用于硬件，例如显示器，其能被设置为固定速率。

​		顾名思义，应用程序阶段由应用程序驱动，因此通常由在通用CPU上运行的软件实现。这些CPU通常包括多个内核，这些内核能够并行处理多个执行线程。这使CPU可以高效地运行应用程序阶段负责的各种任务。传统上在CPU上执行的某些任务包括碰撞检测，全局加速算法，动画，物理仿真以及许多其他任务，具体取决于应用程序的类型。下一个主要阶段是几何处理，它处理变换，投影和所有其他类型的几何处理。此阶段计算要绘制的内容，应如何绘制以及应在何处绘制。几何阶段通常在包含许多可编程内核以及固定操作硬件的图形处理单元（GPU）上执行。光栅化阶段通常将三个顶点作为输入，形成一个三角形，然后找到该三角形内所有要考虑的像素，然后将其转发到下一个阶段。最后，像素处理阶段为每个像素执行一个程序以确定其颜色，并可以执行深度测试以查看其是否可见。它还可以执行每个像素的操作，例如将新计算的颜色与以前的颜色混合。光栅化和像素处理阶段也完全在GPU上进行处理。所有这些阶段及其内部管道将在接下来的四个部分中讨论。有关GPU如何处理这些阶段的更多详细信息，请参阅第3章。

### 2.2应用程序阶段

​		由于通常在CPU上执行，因此开发人员可以完全控制应用程序阶段发生的事情。因此，开发人员可以完全确定实现，以后可以对其进行修改以提高性能。此处的更改也会影响后续阶段的性能。例如，应用程序阶段算法或设置可以减少要渲染的三角形的数量。
​		综上所述，某些应用程序工作可以由GPU使用称为计算着色器的单独模式来执行。此模式将GPU视为高度并行的通用处理器，而忽略了专门用于渲染图形的特殊功能。在应用程序阶段结束时，要渲染的几何图形被传送到几何阶段。这些是渲染图元（rendering primitives），即点，线和三角形，它们最终可能最终出现在屏幕上（或使用的任何输出设备）。这是应用程序阶段最重要的任务。

​		此阶段基于软件的实现的结果是，它不像几何处理，光栅化和像素处理阶段那样分为子阶段。但是为了提高性能，该阶段通常在多个处理器上并行执行核心。在CPU设计中，这被称为超标量构造，因为它能够在同一阶段同时执行多个进程$$^1$$。第18.5节介绍了使用多个处理器内核的各种方法。

​		<font size =1.5>1.于CPU本身的流水线规模要小得多，因此可以说应用程序阶段可进一步细分为几个流水线阶段，但这与此处无关。</font>

​		在此阶段通常实现的是碰撞检测。在两个物体之间检测到碰撞之后，可以生成响应并将其发送回碰撞的物体以及力反馈设备。在应用程序阶段，还要处理来自其他来源的输入，例如键盘，鼠标或头戴式显示器。根据此输入，可以发生几种不同类型的动作。加速算法，例如特定的剔除算法（第19章），也在这里实现，以及渲染管线其余部分无法处理的其他任何事情。

### 2.3几何阶段

​		GPU上的几何处理阶段负责大部分对每个三角形和每个顶点的操作。该阶段进一步分为以下功能阶段：顶点着色，投影，裁剪和屏幕映射（图2.3）。

![1569161769020](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161769020.png)

​		<font size =2>图2.3几何阶段分为由几个功能阶段组成的管线。</font>

#### 2.3.1顶点着色

​		顶点着色有两个主要任务，即计算一个顶点的位置和评估任何程序员可能希望作为顶点输出数据的东西，例如法线和纹理坐标。在传统意义上，一个对象的大部分光影表现是通过将光线应用于每个顶点的位置和法线和存储在顶点种的颜色来计算的。然后将这些颜色插值到整个三角形上。因此，该可编程顶点处理单元被称为顶点着色器[1049]。随着现代GPU的出现，以及每个像素发生部分或全部着色，此顶点着色阶段变得更加通用，并且可能根本不评估任何着色方程式，具体取决于程序员的意图。现在，顶点着色器是一个更通用的单元，专用于设置与每个顶点关联的数据。例如，顶点着色器可以使用第4.4节和第4.5节中的方法对对象进行动画处理。

​		我们首先描述如何计算顶点位置，这始终需要的一组坐标。在它进入屏幕的过程中，模型被转换为几个不同的空间或坐标系。最初，模型在其自己的模型空间中，这仅表示该模型根本没有进行转换。每个模型都可以与一个模型变换关联，以便可以定位和定向。可能有多个模型变换与单个模型相关联。这允许同一模型的多个副本（称为实例(instances)）在同一场景中具有不同的位置，方向和大小，而无需复制基本几何图形。

​		模型变换变换的是模型的顶点和法线。对象(object)（这里指模型）自己坐标称为模型坐标，并且在将模型变换应用于这些坐标之后，可以说模型位于世界坐标或世界空间中。世界空间是唯一的，在对模型进行了各自的模型变换后，所有模型都存在于同一空间中。

​		如前所述，仅被摄像机（或观察者）所看到的模型被渲染。摄像机在世界空间中具有特定方向来校准摄像机视角和在特定的位置来放置摄像机。为了便于投影和裁剪操作，使用视图变换对摄像机和所有模型进行变换。视图变换的目的是将摄影机放置在原点并将其对准目标，使其沿负z轴方向看，y轴指向上方，x轴指向右侧。我们使用-z轴约定；有些文字更喜欢看向+ z轴。区别主要是语义上的，因为彼此之间的转换很简单。应用视图变换后的实际位置和方向取决于基础应用程序编程接口（API）。如此划定的空间称为相机空间(camera space)，或更普遍地称为视野空间(view space)或眼睛空间。视图转换影响相机和模型的方式示例如图2.4所示。模型变换和视图变换都可以使用4×4矩阵实现，这是第4章的主题。但是，重要的是要认识到顶点的位置和法线都可以被程序员喜欢的任何方式来计算。

![1569161848796](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161848796.png)

​		<font size=2>图2.4。在左图中，自上而下的视图显示了在+ z轴朝上的世界中，按用户期望的方式定位和定向的相机。视图变换可重新定向世界，以使相机位于其原点，沿其负z轴看，而相机的+ y轴朝上，如右图所示。这样做是为了使剪切和投影操作更简单，更快捷。浅蓝色区域是视图体积。在此，假定透视图，因为视图体积为平截头体。类似的技术适用于任何类型的投影。</font>

​		接下来，我们描述顶点着色的第二种输出类型。要产生逼真的场景，仅渲染对象的形状和位置是不够的，但是还必须对它们的外观进行建模。此说明包括每个对象的材质，以及任何照在该对象上的光源的效果。材质和灯光可以采用多种方式建模，从简单的颜色表示到详尽的物理描述。

​		确定光线对材质的影响的这种操作称为着色(shading)。它涉及计算模型对象上各个点的着色方程式。通常，其中一些对模型顶点的计算是在的几何图形处理期间执行的，而其他一些计算可能是在逐像素处理期间执行的。每个顶点可以存储各种材质数据，例如点的位置，法线，颜色或任何评估着色方程式所需的其他数字信息。然后将顶点着色的结果（可以是颜色，矢量，纹理坐标以及任何其他种类的着色数据）发送到光栅化和像素处理阶段以进行插值，并用于计算表面的着色。
​		在本书中，尤其将更深入地讨论GPU顶点着色器的顶点着色形式，在第3章和第5章中。

​		作为顶点着色的一部分，渲染系统先进行投影然后进行裁剪操作，这会将视图体积转换为单位立方体，其顶点位于（-1，-1，-1）和（1、1、1）。并且可以使用定义相同体积但不同范围单位立方体，例如0≤z≤1。单位立方称为规范视图体积。进行投影操作，通常在GPU上由顶点着色器完成。有两种常用的投影方法，即正交投影（也称为平行投影）和透视投影。参见图2.5。实际上，正交投影只是平行投影的一种类型。特别是在建筑领域，还有其他一些用途，例如斜投影和轴测投影。旧的街机游戏Zaxxon从后者命名。

![1569161883414](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161883414.png)

<font size=2>		  图2.5 左侧是正交投影或平行投影；右边是透视图。</font>

​		请注意，投影操作表示为矩阵（第4.7节），因此有时可以将其与其余的几何变换连接在一起。

​		正交视图的视图体积通常是一个矩形框，而正交投影会将此视图体积转换为单位立方体。正交投影的主要特征是，平行线在变换后保持平行，此转换是平移和缩放的组合。

​		透视投影有点复杂。在这种类型的投影中，物体离相机越远，投影后出现的越小。此外，平行线可能会聚在地平线上。因此，透视变换模仿了我们感知物体尺寸的方式。从几何学上讲，视场称为视锥，是具有矩形底面的截顶金字塔。视锥也将转换为单位立方体。正交变换和透视变换都可以使用4×4矩阵构造（第4章），并且在进行任何变换之后，都将模型称为裁剪坐标。这些实际上是齐次坐标，将在第4章中进行讨论，因此，这发生在被w除之前。 GPU的顶点着色器必须始终输出此类型的坐标，以使下一个功能阶段（裁剪）正常工作。

​		尽管这些矩阵将一个体积转换为另一个体积，但它们被称为投影，因为在显示之后，z坐标不存储在生成的图像中，而是存储在z缓冲区中，如2.5节所述。这样，模型可以从三个维度投影到两个维度。

#### 2.3.2可选的顶点处理

​		每个管道都有刚刚描述的顶点处理。完成此处理后，GPU上将按照以下顺序进行几个可选阶段：曲面细分(tessellation)，几何着色( geometry shading)和流输出(stream output)。它们的使用取决于硬件的功能（并非所有GPU都具有）以及程序员的需求。它们彼此独立，并且通常不常用。在第3章中将对每个进行更多说明。

​		第一个可选阶段是细分。假设您有一个弹跳的球物体。如果用一组三角形表示它，则可能会遇到质量或性能问题。您的球从5米远处看起来可能不错，但近距离可以看到各个三角形，尤其是沿着轮廓的三角形。如果用更多的三角形制作球以提高质量，则当球太远且仅覆盖屏幕上的几个像素时，可能会浪费大量的处理时间和内存。通过细分，可以生成具有适当数量的三角形的曲面。

​		我们已经讨论了一些三角形，但是到目前为止，我们只处理了顶点。这些可用于表示点，线，三角形或其他对象。顶点可用于描述曲面，例如球。这样的表面可以由一组面片指定，每个面片由一组顶点组成。细分阶段本身包含一系列阶段（外壳着色器，细分和域着色器），这些阶段将这些面片顶点集转换为（通常）更大的顶点集，然后用于创建新的三角形集。场景的摄像头可用于确定生成了多少个三角形：靠近时会生成许多三角形，而远离时会生成很少的三角形。

​		下一个可选阶段是几何着色器。该着色器早出现于曲面细分着色器，因此在GPU上更常见。就像曲面细分着色器一样，它可以吸收各种图元并可以产生新的顶点。这是一个非常简单的阶段，因为此创建的范围受到限制，输出基元的类型受到更多的限制。几何着色器有多种用途，其中最流行的一种是粒子生成。想象一下模拟烟花爆炸。每个火球都可以由一个点，单个顶点表示。几何着色器可以获取每个点并将其变成面向观察者并覆盖多个像素的正方形（由两个三角形组成），从而为我们提供了更具说服力的图元进行着色。

​		最后一个可选阶段称为流输出。在此阶段，我们可以将GPU用作几何引擎。此时，我们可以选择将其输出到数组以进行进一步处理，而不是将处理后的顶点向下发送到要渲染到屏幕的剩余管线中。这些数据可以在以后的过程中由CPU或GPU本身使用。此阶段通常用于粒子模拟，例如我们的烟花示例。
​		这三个阶段按此顺序执行（细分，几何体着色和流输出），并且每个阶段都是可选的。不管使用哪个（如果有）选项，如果我们继续沿管线移动，我们都有一组具有齐次坐标的顶点，不论如何都可以在相机视图中查看它们。

#### 2.3.3裁剪

​		只需要将全部或部分视锥体内的图元传递到光栅化阶段（以及随后的像素处理阶段），然后将其绘制在屏幕上。完全位于视锥体内的图元将原样传递到下一个阶段。完全不在视图体积之外的基元不会进一步传递，因为它们不会被渲染。只是部分在视锥体内的图元需要被裁剪。例如，有一条直线有一个顶点在视锥体内另一个顶点在视锥体外那么这条直线需要被视锥体裁剪，将外部顶点替换为位于该线和视图体积的交点处的新顶点。投影矩阵的使用意味着将变换后的图元剪裁在单位立方体上。在裁剪之前执行视图转换和投影的优点是使裁剪问题一致。图元总是被裁剪在单位立方体上。

​		裁剪过程如图2.6所示。除了单位立方体的六个剪切平面之外，用户还可以定义其他剪切平面以可视方式剪切对象。在第818页的图19.1中显示了显示这种类型的可视化效果的图像，称为切片

​		裁剪步骤使用投影产生的4值齐次坐标执行裁剪。在透视空间中，值通常不会跨三角形线性内插。需要第四个坐标，以便在使用透视投影时正确地插入和剪切数据。最后，执行透视划分，将所得三角形的位置放入三维归一化的设备坐标中。如前所述，此视图的体积范围是（-1，-1，-1）到（1,1,1）。几何阶段的最后一步是从该空间转换为窗口坐标

![1569161909685](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161909685.png)

​		<font size=2>图2.6。投影变换后，仅将单位立方体内的图元（对应于视锥中的图元）进行后续处理。因此，完全位于单位立方体外的图元将被丢弃，并完全保留完全位于单位立方体内的图元。与单位立方体相交的图元被裁剪到单位立方体上，从而生成新的顶点，而旧的顶点被丢弃。</font>

#### 2.3.4屏幕映射

​		只有视图体积内的（剪切后）图元传递到屏幕映射阶段，进入该阶段时坐标仍然是三维的。每个图元的x坐标和y坐标都将转换为屏幕坐标。屏幕坐标和z坐标也称为窗口坐标。假定场景应渲染到窗口中，最小角在（x1，y1）处，最大角在（x2，y2），其中x1 <x2并且y1 <y2。然后，屏幕映射是平移，随后是缩放操作。新的x和y坐标称为屏幕坐标。 z坐标（对于OpenGL为[−1，+1]，对于DirectX为[0，1]）也映射到[z1，z2]，其中z1 = 0和z2 = 1为默认值。但是，可以使用API进行更改。窗口坐标以及此重新映射的z值将传递到光栅化器阶段。屏幕映射过程如图2.7所示。

![1569161927375](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161927375.png)

​		<font size =2>图2.7。投影变换后，图元位于单位立方体中，并且屏幕映射过程会在屏幕上查找坐标。</font>

​		接下来，我们描述整数和浮点值与像素（和纹理坐标）的关系。给定水平像素数组并使用笛卡尔坐标，最左像素的左边界在浮点坐标中为0.0。 OpenGL一直使用此方案，DirectX 10及其后续版本使用它。该像素的中心为0.5。因此，像素[0，9]的范围覆盖了[0.0，10.0）的范围。转换很简单
$$
d=floot(c)\qquad\qquad\qquad (2.1)
\\
c=d+0.5\qquad\quad\quad\qquad (2.2)
$$
其中d是像素的离散（整数）索引，c是像素内的连续（浮点）值。

​		尽管所有API的像素位置值都从左到右增加，但在某些情况下OpenGL和DirectX之间的上下边界零位置不一致。$$^2$$OpenGL始终偏爱笛卡尔系统，将左下角视为值最低的元素，而DirectX有时会根据上下文将左上角定义为此元素。每种都有逻辑，在不同之处没有正确答案。例如，（0，0）位于OpenGL中图像的左下角，而在DirectX中位于左上角。从一个API迁移到另一个API时，必须考虑到这一差异。

​		<font size=1>2.“ Direct3D”是DirectX的三维图形API组件。 DirectX包括其他API元素，例如输入和音频控件。除了在指定特定版本时编写“ DirectX”和在讨论该特定API时编写“ Direct3D”之间，我们没有区别，而是通篇编写“ DirectX”来遵循常用用法。</font>

### 2.4光栅化

​		给定经过变换操作和投影操作的顶点及其关联的着色数据（全部来自几何阶段），下一阶段的目标是查找要渲染的图元（例如三角形）内的所有像素（图片元素的简称）。我们称这种过程为光栅化，它分为两个功能子阶段：三角形设置（也称为图元装配）和三角形遍历。这些显示在图2.8的左侧。注意，它们也可以处理点和线，但是由于三角形是最常见的，因此子阶段的名称中带有“三角形”。光栅化，也称为扫描转换，是从屏幕空间中的二维顶点（每个顶点具有z值（深度值）以及与每个顶点相关的各种阴影信息）到屏幕上的像素的转换。光栅化也可以被视为几何处理阶段和像素处理阶段之间的同步点，因为在这里，三角形是由三个顶点形成的，并最终传递到像素处理阶段。

​		三角形是否被视为与像素重叠取决于您如何设置GPU管线。例如，您可以使用点采样来确定“内部”。最简单的情况是在每个像素的中心使用一个点采样，因此，如果该中心点在三角形内部，则相应的像素也被认为在三角形内部。您还可以使用超采样或多采样抗锯齿技术对每个像素使用一个以上的采样（第5.4.2节）。还有一种方法是使用保守光栅化，其定义是，如果像素的至少一部分与三角形重叠，则该像素“位于三角形内”（第23.1.2节）。

![1569244367703](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569244367703.png)

​		<font size=2>图2.8。左：光栅化分为两个功能阶段，称为三角形建立和三角形遍历。右图：像素处理分为两个功能阶段，即像素处理和合并。</font>

#### 2.4.1三角形建立

​		在这一阶段，计算三角形的微分，边方程和其他数据。这些数据可用于三角形遍历（第2.4.2节），以及用于插值几何阶段产生的各种着色数据。这部分的任务通常由硬件完成。

#### 2.4.2三角形遍历

​		在这里检查每个中心（或样本）被三角形覆盖的像素，并为与三角形重叠的像素部分生成一个片段。更多详细的采样方法可以在第5.4节中找到。查找哪些像素在三角形内通常被称为三角形遍历。每个三角形片段的属性都是使用在三个三角形顶点之间插值的数据生成的（第5章）。这些属性包括片段的深度，以及来自几何阶段的任何着色数据。 McCormack. [1162]提供了更多关于三角形遍历的信息。在这里，也可以在三角形上执行透视校正插值[694]（第23.1.1节）。然后将图元内部的所有像素（或样本）发送到像素处理阶段，如下所述。

### 2.5像素处理

​		在这一点上，由于所有先前阶段组合的结果，已经找到了在三角形或其他图元内部考虑的所有像素。像素处理阶段分为像素着色和合并，如图2.8右侧所示。像素处理是对一个图元内部的像素或样本执行计算和操作的阶段。

#### 2.5.1像素着色

​		使用经过插值的着色数据作为输入，此阶段可以执行任何每个像素的着色计算。最终结果是一种或多种颜色将传递到下一个阶段。与通常由硬件执行的三角形设置和遍历阶段不同，像素着色阶段由可编程GPU内核执行。为此，程序员为像素着色器（或片段着色器，在OpenGL中众所周知）提供了一段程序，该程序可以包含任何所需的计算。此阶段可以使用多种技术，其中最重要的一种是纹理化。在第6章中将更详细地讨论纹理化。简单地说，对一个对象进行纹理化意味着出于各种目的将一个或多个图像“粘合”到该对象上。此过程的一个简单示例如图2.9所示。图像可以是一维，二维或三维图像，其中二维图像是最常见的。最简单的说，最终产品是每个片段的颜色值，并将它们传递到下一个子阶段。

![1569244499368](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569244499368.png)

​		<font size=2>图2.9左上方显示了没有纹理的龙模型。图片中的碎片，将纹理“粘合”到龙上，结果显示在左下方。</font>

#### 2.5.2合并

​		每个像素的信息都存储在颜色缓冲区中，颜色缓冲区是颜色的矩形阵列（每种颜色的红色，绿色和蓝色分量）。合并阶段负责将像素着色阶段产生的片段颜色与当前存储在缓冲区中的颜色进行组合。此阶段也称为ROP，代表“光栅操作（管道）”或“渲染输出单元”。与像素着色阶段不同，执行此阶段的GPU子单元通常是不可完全可编程的。但是它是高度可配置的，可实现各种效果。

​		此阶段还负责解决可见性。这意味着在渲染整个场景后，颜色缓冲区应包含场景中从相机的角度可见的图元的颜色。对于大多数甚至所有图形硬件，这都是通过z缓冲区（也称为深度缓冲区）算法[238]完成的。 Z缓冲区的大小和结构与颜色缓冲区相同，并且对于每个像素，Z缓冲区将z值存储到当前最接近的图元。这意味着，当将图元渲染到某个具体的像素时，该图元在该像素处的z值将被计算并与同一像素处z缓冲区的内容进行比较。如果新的z值小于z缓冲区中的z值，则正在渲染的图元比之前在那个像素处最接近相机的图元更接近相机。因此，该像素的z值和颜色将使用所绘制图元的z值和颜色进行更新。如果计算的z值大于z缓冲区中的z值，则保持颜色缓冲区和z缓冲区不变。 z缓冲区算法很简单，具有O（n）收敛（其中n是要渲染的图元的数量），作用于任何z值能通过和其相关的像素被计算的图元。还要注意，该算法允许大多数图元以任何顺序呈现，这是其普及的另一个原因。但是，z缓冲区仅在屏幕上的每个点存储一个深度，因此不能用于部分透明的图元。透明图元必须在所有不透明基元之后渲染，以从后到前的顺序或使用其他顺序的算法（第5.5节）呈现这些内容。透明是z缓冲区的主要弱点之一。

​		我们已经提到了颜色缓冲区用于存储颜色，而z缓冲区用于存储每个像素的z值。但是，还有其他通道和缓冲区可用于筛选和捕获片段信息。 Alpha通道与颜色缓冲区关联，并为每个像素存储相关的不透明度值（第5.5节）。在较早的API中，alpha通道还用于通过alpha测试功能选择性地丢弃像素。如今，可以将丢弃操作插入到像素着色器程序中，并且可以使用任何类型的计算来触发丢弃。可以使用这种类型的测试来确保完全透明的片段不会影响z缓冲区（第6.6节）。

​		模板缓冲区是一个屏幕外缓冲区，用于记录渲染图元的位置。通常每个像素包含8位。可以使用各种方法将图元渲染到模板缓冲区中，然后可以使用模板缓冲区的内容来控制渲染到颜色缓冲区和z缓冲区。例如，假设已将填充圆绘制到模板缓冲区中。允许以填充圆作为父物体的后续图元和填充圆组合渲染到颜色缓冲区中。模板缓冲区可以是生成某些特殊效果的强大工具。流水线末端的所有这些功能都称为光栅操作（ROP）或混合操作。可以将当前颜色缓冲区中的颜色与三角形内要处理的像素的颜色混合。这可以实现诸如透明度或颜色采样累积的效果。如前所述，混合通常可以使用API进行配置，而不是完全可编程的。但是，某些API支持光栅顺序视图，也称为像素着色器顺序，允许可编程混合功能。

​		帧缓冲区通常由系统上的所有缓冲区组成。
​		当图元到达并通过光栅化阶段时，从相机的角度可见的图元将显示在屏幕上。屏幕显示颜色缓冲区的内容。为了避免让人类观看者在对其进行栅格化并将其发送到屏幕时看到它们，使用了双重缓冲。这意味着场景的渲染发生在屏幕后方的缓冲区中。将场景渲染到后缓冲区中后，后缓冲区的内容将与先前在屏幕上显示的前缓冲区的内容交换。交换通常发生在垂直回扫过程中，这是安全的时间。
​		有关不同缓冲区和缓冲方法的更多信息，请参见第5.4.2、23.6和23.7节

### 2.6纵观渲染管线

​		点，线和三角形是用于构建模型或对象的渲染图元。假设该应用程序是交互式计算机辅助设计（CAD）应用程序，并且用户正在检查华夫饼制作机的设计。在这里，我们将在整个图形渲染管道中使用此模型，包括四个主要阶段：应用程序，几何，光栅化和像素处理。通过透视投影将场景渲染到屏幕上的窗口中。在这个简单的示例中，华夫饼制作机模型同时包含线（以显示零件的边缘）和三角形（以显示表面）。华夫饼制作机的盖子可以打开。一些三角形是由带有制造商徽标的二维图像制成的。对于此示例，除了在光栅化阶段发生的纹理应用之外，表面着色是在几何阶段完全计算出来的。

应用程序阶段

​		CAD应用程序允许用户选择和移动模型的各个部分。例如，用户可以选择盖子，然后移动鼠标将其打开。应用阶段必须将鼠标移动转换为相应的旋转矩阵，然后确认呈现该矩阵时已将其正确应用于盖子。另一个示例：播放动画，使动画沿预定路径移动，以从不同的角度显示华夫饼制作机。然后必须由应用程序根据时间更新相机参数，例如位置和视图方向。对于要渲染的每个帧，应用程序阶段将相机的位置，照明和模型的图元传入管线中的下一个主要阶段-几何阶段。

几何阶段

​		对于透视图，我们在此假定应用程序已提供了投影矩阵。同样，对于每个对象，应用程序都已计算出一个矩阵，该矩阵描述了视图变换以及对象本身的位置和方向。在我们的示例中，华夫饼制造商的底座将具有一个矩阵，而盖子则具有另一个矩阵。在几何阶段，使用此矩阵转换对象的顶点和法线，从而将对象变化到视图空间。然后，可以使用材质和光源属性来计算顶点处的阴影或其他计算。然后使用单独的用户提供的投影矩阵执行投影，将对象转换为代表眼睛所见的单位立方体的空间。单位立方体外部的所有图元都将被丢弃。将与该单位立方体相交的所有图元都裁剪到该单位立方体上，以便获得一组完全位于单位立方体内的图元。然后将这些顶点映射到屏幕上的窗口中。在完成所有这些按三角形和按顶点进行的操作之后，将所得数据传递到光栅化阶段。

光栅化

​		然后光栅化所有在上一阶段幸存下来的图元，这意味着找到了图元内部的所有像素，并将它们进一步发送到管线以进行像素处理。

像素处理

​		此处的目标是计算每个可见图元的每个像素的颜色。那些与任何纹理（图像）相关联的三角形将根据需要应用这些图像进行渲染。可见性通过z缓冲区算法以及可选的丢弃和模板测试来解决。依次处理每个对象，然后将最终图像显示在屏幕上。

### 结语

​		渲染管线源于针对实时渲染应用程序的数十年的API和图形硬件演变。重要的是要注意，这不是唯一的渲染管线。离线渲染管道经历了不同的进化路径。电影制作的渲染通常是通过微多边形管线完成的[289，1734]，但是光线追踪和路径追踪近来已取而代之。 11.2.2节中介绍的这些技术，这些技术也可以用于建筑和设计的预可视化。

​		多年来，应用程序开发人员使用此处描述的过程的唯一方法是通过使用中的图形API定义的固定功能管道。固定功能管道之所以如此命名，是因为实现它的图形硬件包含无法灵活编程的元素。主要的固定功能机器的最后一个例子是2006年推出的Nintendo的Wii。另一方面，可编程GPU使得可以确切确定在整个生产流程的各个子阶段中应用了哪些操作。对于本书的第四版，我们假设所有开发都是使用可编程GPU完成的。

### 进一步阅读和资源

​		布林的著作《A Trip Down the Graphics Pipeline 》 [165]是一本关于从头开始编写软件渲染器的旧书。它是学习实现渲染管线的一些精妙之处，解释关键算法（例如裁剪和透视插值）的好资源。古老的（至今仍经常更新）《 OpenGL编程指南》（又称“红皮书”）[885]提供了图形管道的完整描述以及与其使用相关的算法。本书的网站realtimerendering.com提供了指向各种管线图，渲染引擎实现等的链接。















## 3.GPU

​		从历史上看，图形加速始于与三角形重叠的每个像素扫描线上的颜色插值，然后显示这些值。包括访问图像数据的能力，它可以将纹理应用于表面。添加用于插值和和内置在可见性检查时的z深度测试的硬件。由于它们经常频繁使用，因此将此类处理过程由于专用硬件提供以提高性能。在后续几代中添加了渲染管线的更多部分，以及给予每个部分的更多功能。专用图形硬件相对于CPU的唯一计算优势是速度，但速度至关重要

​		在过去的二十年中，图形硬件经历了不可思议的转变。 1999年交付的第一款包含硬件顶点处理的消费类图形芯片（NVIDIA的GeForce256）。NVIDIA创造了图形处理单元（GPU）一词，以将GeForce 256与以前仅可光栅化的芯片区分开来，并且从那时延续至今。在接下来的几年中，GPU从复杂的可配置固定功能管线发展到高度可编程的状态，开发人员可以在其中实现自己的算法。各种可编程着色器是控制使用GPU的主要方法。为了提高效率，流水线的某些部分仍然是可配置的，而不是可编程的，但是趋势是朝着可编程性和灵活性的方向发展[175]。

​		GPU通过专注于一组高度可并行化的任务以获得高速。他们拥有专用于实现z缓冲区，快速访问纹理图像和其他缓冲区以及查找被三角形覆盖的像素的定制芯片。这些元素如何执行其功能将在第23章中介绍。现在优先需要知道的是GPU如何实现其可编程着色器的并行性。

​		3.3节介绍了着色器的功能。目前，您需要知道的是着色器核心是一个可以执行一些相对隔离的任务的小型处理器，例如将顶点从其在世界坐标上的位置转换为屏幕坐标，或者计算被一个被三角形覆盖的像素的颜色。每帧会有成千上万个三角形发送到屏幕，每秒可能有数十亿次着色器调用，运行着色器程序的地方被称之为单独实例。

​		首先，延迟是所有处理器都面临的问题。访问数据需要花费一些时间。考虑延迟的一种基本方法是，信息离处理器越远，等待时间就越长。第23.3节会详细介绍延迟。访问存储在内存中的信息将比访问本地寄存器中的信息花费更长的时间。 18.4.1节将更深入地讨论内存访问。关键是等待数据检索时意味着处理器处于停滞状态，这将h会降低性能。

### 3.1并行数据架构

​		不同的处理器架构使用不同的策略来避免停滞。CPU针对处理各种数据结构和大型代码库进行了优化。 CPU可以具有多个处理器，但是每个处理器通常都以串行方式运行代码，有限的SIMD矢量处理是个例外。为了最大程度地减少延迟带来的影响，CPU中的许多芯片都由快速本地缓存组成，这些内存中填充了接下来可能需要使用的数据。 CPU还通过使用诸如分支预测，指令重新排序，寄存器重命名和缓存预取之类的巧妙技术来避免停滞。[715]

​		GPU则采用不同的方法避免停滞。 GPU的大部分芯片区域由大量的称之为着色器核心的处理器组成，数量通常多达数千个。 GPU是流处理器，它依次处理相似数据的有序集合。由于这种相似性（例如，一组顶点或像素），GPU可以大规模并行地处理这些数据。另一个重要的因素是这些调用尽可能地独立，因此它们不需要来自相邻调用的信息，并且不共享可写的本地存储。但有时会破坏该规则以允许新的有用功能，但是此类异常的代价是潜在的延迟，因为一个处理器可能会等待直到另一个处理器完成其工作。
​		GPU针对吞吐量进行了优化，吞吐量定义为可以处理数据的最大速率。但是这种快速处理是具有成本的。由于专用于高速缓存和控制逻辑的芯片面积较小，因此每个着色器内核的等待时间通常比CPU处理器遇到的等待时间长得多[462]。

​		假设网格已光栅化，并且两千个像素具有要处理的片段；像素着色器程序将被调用2000次。想象那儿只有一个着色器处理器，使用世界上最差的GPU。它开始为2000片段中的第一个片段执行着色器程序。着色器处理器对寄存器中的值执行一些算术运算。寄存器是本地的，可以快速访问，因此不会发生停顿。然后，着色器处理器会执行一条指令，例如访问纹理；例如，对于给定的表面坐标，程序需要知道应用于这点的网格的图像的像素颜色。纹理是一个完全独立的资源，而不是像素程序本地存储的一部分，并且纹理访问可能会涉及到一定程度。内存提取可能需要数百到数千个时钟周期，在此期间GPU处理器不执行任何操作。此时，着色器处理器将停止运行，等待纹理的颜色值返回

​		为了使这个糟糕的GPU变得更好，为每个片段提供一些存储空间在本地寄存器上。现在，允许着色器处理器切换并处理另一个片段，即两千个片段中的第二个片段，而不是停止纹理获取。此切换速度非常快，除了需要注意第一片段正在执行哪条指令之外，第一个片段和第二个片段中的内容均不受影响。现在执行第二个片段。与第一个相同，执行一些算术函数，然后再次遇到获取纹理。着色器核心现在切换到另一个片段，即第三个片段。最终，所有两千个片段都以这种方式处理。此时，着色器处理器将返回片段编号1。此时，纹理颜色已被获取并且可以使用，因此着色器程序可以继续执行。处理器以相同的方式进行处理，直到遇到另一个已知会暂停执行的指令，或者程序完成。与着色器处理器始终专注于一个片段相比，执行单个片段所需的时间更长，但是整个片段的总体执行时间将大大减少。

​		在这种架构中，通过切换到另一个片段使GPU保持忙碌来隐藏延迟。 GPU通过将逻辑指令的执行与数据分离开来，使该设计更进一步。这种设计称为单指令多数据（SIMD），这种设计可以在固定数量的着色器程序上以锁定步骤的方式保证执行同一命令。 SIMD的优点是，与使用单独的逻辑和调度单元去运行每个程序相比，用于处理数据和交换的硅（和电量）要少得多。将我们的2000个片段示例转换成现代的GPU术语，每个片段的像素着色器调用都称为线程。这种类型的线程与CPU线程不同。它由作为着色器的输入值的一点内存以及任何着色器执行所需的寄存器空间组成。使用相同着色器程序的线程被分为一组，被NVIDIA称为warp，被AMD称为wavefronts。warp/wavefont被8到64之间的任意数量的GPU着色器内核计划去执行SIMD处理。每个线程都被映射到SIMD通道。

​		假设我们有两千个线程要执行。 NVIDIA GPU的warp包含32个线程。这将产生2000/32 = 62.5个warp，这意味着分配了63个warp，其中一个warp一半为空。warp的执行类似于我们的单个GPU处理器示例。着色器程序在所有32个处理器上以锁定步骤的方式执行。遇到对内存进行提取时，所有线程都会同时遇到它，因为所有线程执行相同的指令。提取操作导致warp中的线程将停止，所有线程都在等待它们的（不同的）结果。为了取代停顿，而将warp换成另一个由32个线程的组成的warp，然后由32个内核继续执行。这种交换的速度与我们的单处理器系统一样快，因为在将warp换入或换出时，每个线程内的数据都不会被触及。每个线程都有自己的寄存器，每个warp都跟踪其正在执行的指令。交换新warp只是将一组核心指向另一组要执行的线程即可。没有其他开销。warp执行或换出，直到全部完成。参见图3.1。

​		在我们的简单示例中，从内存获取纹理的等待时间可能导致swap交换，因为交换成本非常低，所以在真实的情况下将wrap换出将产生较短的延迟。还有其他几种用于优化执行的技术[945]，但warp交换是所有GPU使用的主要延迟隐藏机制。此过程的效率涉及多个因素。例如，如果线程很少，那么只会创建很少的warp，从而使延迟隐藏成为问题。

​		着色器程序的结构是影响效率的重要因素。一个主要因素是每个线程使用的寄存器数量。在我们的示例中，我们假设一次可以将2000个线程全部驻留在GPU上。与每个线程相关联的着色器程序所需的寄存器越多，则线程越少，因此wrap也就越少，进而驻留在GPU中的warp也越少。wrap的不足意味着无法通过交换来减轻停滞。处于驻留状态的warp被称为“in flight”，这个数字称为占用率。高占用率意味着有许多可用于处理的warp，因此出现空闲处理器的可能性较小。低占用率通常会导致性能不佳。从内存提取的频率也影响多少延迟需要隐藏。 Lauritzen [993]概述了着色器使用的寄存器数量和共享内存如何影响占用率。 Wronski [1911，1914]讨论了理想的占用率如何根据着色器执行的操作类型而变化。

​		影响整体效率的另一个因素是由“ if”语句和循环引起的动态分支。假设在着色器程序中遇到“ if”语句。如果所有线程求值并采用同一分支，则warp可以继续进行而不必担心其他分支。但是，如果某些线程甚至一个线程采用了替代路径，那么warp必须执行两个分支，然后丢弃每个线程不需要的结果[530，945]。这个问题称为线程发散，其中一些线程可能需要执行循环迭代或执行“ if”路径，而warp中的其他线程则不这样做，从而使它们在此期间处于空闲状态。

​		所有GPU都实现了这些架构思想，从而导致系统具有严格的限制，但每瓦的计算能力却很大。了解该系统的运行方式将有助于您作为程序员充分利用其提供的功能。在以下各节中，我们讨论GPU如何实现渲染管线，可编程着色器如何运行以及每个GPU阶段的演变和功能。

![1569425237916](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425237916.png)

​		<font size=2>图3.1。简化的着色器执行示例。三角形的片段（称为线程）被集合成warp。每个warp显示为四个线程，但实际上有32个线程。要执行的着色器程序长五个指令。四个GPU着色器处理器的集合处理第一个warp时执行这些指令，直到在“ txr”命令上检测到停顿条件为止，这需要时间来获取其数据。交换第二个wrap，并对其应用着色器程序的前三个指令，直到再次检测到停顿为止。交换第三个wrap并使其停止后，通过交换第一个wrap并继续执行，继续执行。如果此时尚未返回其“ txr”命令的数据，则执行将真正停止，直到这些数据可用为止。每个wrap依次完成</font>

![1569425269701](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425269701.png)

​		<font size=2>图3.2。渲染管线的GPU实现。这些阶段根据用户对其操作的控制程度进行颜色编码。绿色阶段是完全可编程的。虚线表示可选阶段。黄色阶段是可配置的，但不是可编程的，例如，可以为合并阶段设置各种混合模式。蓝色阶段的功能完全固定。</font>

### 3.2GPU管线概述

​		GPU实现了第2章中描述的几何处理，光栅化和像素处理管线这些阶段。这些阶段又可以分为具有不同程度的的几个硬件子阶段。图3.2根据各个子阶段的可编程性或可配置性显示不同的颜色和框线。请注意，这些划分出的物理阶段与第二章中介绍的4个功能阶段不同。

​		这里描述GPU的逻辑模型，它是通过API展示给程序员。正如第18和23章所讨论的那样，此逻辑管线（物理模型）的实现取决于硬件供应商。为了在GPU上执行此逻辑模型中固定功能的阶段，可以通过将命令添加到固定功能阶段相邻的可编程阶段。管线中的单个程序可以通过相互独立的子单元划分为多个元素来执行，也可以由完整的方式执行。此逻辑模型可以帮助您推断出哪些因素会影响性能，但不要弄错GPU实际实现的管线。

​		顶点着色器是用于实现几何处理阶段的一个完全可编程的子阶段。几何着色器是一个完全可编程的阶段，负责一个图元的顶点（点，线或三角形）的处理。它可用于执行每个图元的着色操作，销毁图元或创建新的图元。曲面细分阶段和几何着色器都是可选的，并非所有GPU都支持它们，尤其是在移动设备上。

​		裁剪，三角形设置和三角形遍历阶段由硬件实现的固定功能。屏幕映射受窗口和视口设置的影响，在内部形成简单的比例尺并重新定位。像素着色器阶段是完全可编程的。尽管合并阶段不是可编程的，但是它是高度可配置的，并可以设置执行多种操作。它实现了“合并”阶段的功能，负责修改颜色，z缓冲区，混合，模板和任何其他与输出相关的缓冲区。像素着色器的执行与合并阶段一起构成了第2章中介绍的像素处理阶段。

​		随着时间的流逝，GPU管线已从硬编码操作演变为增加灵活性和控制能力。可编程着色器阶段的引入是这一发展过程中最重要的一步。下一节描述了各个可编程阶段的通用特征

### 3.3可编程着色器阶段

​		现代着色器程序使用统一的着色器设计标准。这意味着与顶点，像素，几何和曲面细分相关联的着色器共享一个公共的编程模型。在各自的着色器内部，它们具有相同的指令集结构（ISA）。实现此模型的处理器在DirectX中称为“通用着色器核心”，具有此类核心的GPU称为具有统一的着色器结构。这种结构背后的想法是，着色器处理器可以在各种角色中使用，GPU可以根据需要分配它们。例如，与由两个三角形组成的大正方形相比，一组带有小三角形的网格将需要更多的顶点着色器处理。GPU使用单独的顶点着色器核心池和像素着色器核心池意味着理想工作状态下的使所有核心保持忙碌的分配规则是预先严格定义好的。而使用统一的着色器核心，GPU可以决定如何平衡此负载。

​		描述整个着色器编程模型已经超出了本书的范围，并且已经有许多文档，书籍和网站。着色器使用类C的着色语言进行编程，例如DirectX的高级着色语言（HLSL）和OpenGL着色语言（GLSL）。 DirectX的HLSL可以编译为虚拟机字节码，也称为中间语言（IL或DXIL），以提供硬件独立性。中间表示还可以允许着色器程序被编译和离线存储。驱动程序将此中间语言转换为特定GPU的ISA。控制台编程通常避免中间语言步骤，因为那时系统只有一个ISA。

​		基本数据类型是32位单精度浮点标量和向量，尽管向量只是着色器代码的一部分，并且如上所述在硬件中不受支持。在现代GPU上还支持32位整形和64位浮点数。浮点向量通常包含位置（xyzw），法线，矩阵行，颜色（rgba）或纹理坐标（uvwq）等数据。整形最常用于表示计数器，索引或位掩码。还支持聚合数据类型，例如结构，数组和矩阵。

​		一个draw call调用图形API来绘制一组图元，从而使图形管线执行并运行其着色器。每个可编程着色器阶段都有两种类型的输入：统一输入（uniform inputs），其值在整个draw call期间保持不变（但可以在多个draw call之间进行更改），以及变化的输入（varying inputs），即来自三角形顶点或光栅化的数据。例如，像素着色器可以将光源的颜色作为一个uniform值。并且三角形表面的位置每像素都会变化，因此是个varying值。纹理是一种特殊的uniform inputs，它总是应用于表面的色彩图像，但现在可以认为是任何大型数据的数组。

​		底层虚拟机为不同类型的输入和输出提供特殊的寄存器。用于uniform的可用常数寄存器的数量比用于varying的输入或输出的可用寄存器的数量大得多。发生这种情况是因为需要为每个以varying 值输入或者输出的顶点或像素分配额外的存储，因此对于需要多少个输入存在限制。uniform inputs只存储一次，并且在draw call时所有顶点或像素数据会被重复使用。虚拟机还具有用于暂存空间的通用临时寄存器。可以在临时寄存器中用整形值以数组方式对所有类型的寄存器进行索引。着色器虚拟机的输入和输出如图3.3所示。

![1569425303277](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425303277.png)

​		<font size=2>图3.3。 Shader Model 4.0下的统一虚拟机结构和寄存器布局。每个资源旁边都会显示最大可用数量。用斜杠分隔的三个数字表示顶点，几何和像素着色器的限制（从左到右）。</font>

​		图形计算中常见的操作可在现代GPU上高效执行。着色语言通过*和+等运算符实现了这些运算中最常见的运算（例如加法和乘法）。其余的通过内置函数实现，例如atan（），sqrt（），log（）以及许多针对GPU优化的其他函数。也存在执行更复杂的操作的函数，例如矢量归一化和反射，叉积，矩阵转置和行列式计算。

​		术语流控制是指使用分支指令来更改代码执行流。与流控制相关的指令用于实现高级语言构造，例如“ if”和“ case”语句，以及各种类型的循环。着色器支持两种类型的流控制。静态流控制分支基于uniform inputs的输入值。这意味着代码流在draw call期间中是恒定的。静态流控制的主要好处是允许将相同的着色器用于各种不同的情况（例如，不同数量的灯光）。由于所有调用都采用相同的代码路径，因此没有线程差异。动态流控制基于uniform inputs的输入值，这意味着每个片段可以执行不同的代码。这比静态流控制强大得多，但会降低性能，尤其是在着色器调用之间发生代码流的不规则变化。

### 3.4可编程着色器和API的演变

​		可编程着色框架的构想可以追溯到1984年，当时库克（Cook）的阴影树[287]。一个简单的着色器及其相应的着色树如图3.4所示。 RenderMan着色语言[63，1804]是在1980年代后期从这个想法发展而来的。如今，它与其他不断发展的规范（例如开放着色语言（OSL）项目[608]）一起用于电影制作渲染。

​		消费级图形硬件是3dfx Interactive于1996年10月1日首次成功引入的。有关今年的时间表，请参见图3.5。他们的Voodoo图形卡能够以高品质和性能渲染《 Quake》游戏，因此很快就被采用。该硬件实现了全部由固定功能的组成的管线。在GPU支持可编程着色器之前，曾多次尝试通过多次渲染来实现可编程着色操作。 Quake III：Arena脚本语言是1999年在该领域的首个成功广泛商业化。如本章开头所述，NVIDIA的GeForce256是第一个被称为GPU的硬件，尽管它是不可编程的，但是它是可配置的。

![1569425341790](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425341790.png)

​		<font size=2>图3.4。一个简单的铜着色器的着色树及其相应的着色器语言程序。 （在库克[287]之后。）</font>

![1569425360463](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425360463.png)

​		<font size=2>图3.5。一些API和图形硬件版本的时间表。</font>

​		在2001年初，NVIDIA的GeForce 3是第一个支持可编程顶点着色器[1049]的GPU，该着色器通过DirectX 8.0和OpenGL扩展公开。这些着色器以一种类似于汇编的语言进行编程，该语言被驱动程序即时转换为微代码。像素着色器也包含在DirectX 8.0中，但是像素着色器没有达到实际的可编程性-驱动程序将受支持的有限“程序”转换为纹理混合状态，然后将其连接到硬件“寄存器组合器”。这些“程序”是不仅限于长度（不超过12条指令），而且缺少重要的功能。 Peercy等人确定了相关的纹理读取和浮点数据。 [1363]对于真正的可编程性至关重要，来自他们对RenderMan的研究。

​		着色器此时不允许进行流控制（分支），因此必须通过计算两个项以及在结果之间进行选择或差值来模拟条件。 DirectX定义了着色器模型（Shader Model，SM）的概念，以区分具有不同着色器功能的硬件。 2002年，包括Shader Model 2.0在内的DirectX 9.0发行了，该版本具有真正可编程的顶点和像素着色器。在OpenGL下，使用各种扩展也出现了类似的功能。添加了对任意依赖的纹理读取的支持以及16位浮点值的存储，最终完成了Peercy等人确定的一组要求。诸如指令，纹理和寄存器之类的着色器资源的限制增加了，因此着色器变得能够实现更复杂的效果。还增加了对流量控制的支持。着色器的长度和复杂性不断增长，使得汇编编程模型变得越来越麻烦。幸运的是，DirectX 9.0还包含HLSL。这种着色语言是由Microsoft与NVIDIA合作开发的。大约在同一时间，OpenGL ARB（架构审查委员会）发布了GLSL，一种与OpenGL非常相似的语言[885]。这些语言在很大程度上受到C编程语言的语法和设计理念的影响，其中还包括来自RenderMan着色语言的元素。

​		Shader Model 3.0于2004年推出，并添加了动态流控制，使着色器功能更加强大。它还将可选功能转变为需求，进一步增加了资源限制，并增加了对顶点着色器中纹理读取的有限支持。当在2005年末（微软的Xbox 360）和2006年末（索尼计算机娱乐公司的PLAYSTATION 3系统）推出新一代游戏机时，它们配备了Shader Model 3.0级GPU。任天堂的Wii控制台是最后一批著名的固定管线的GPU之一，该GPU最初于2006年末交付。纯固定管线在这一点上早已一去不复返了。着色器语言已经发展到可以使用各种工具来创建和管理它们的地步。图3.6显示了使用库克（Cook）的阴影树概念的一种此类工具的屏幕截图。

​		可编程性的下一个重大步骤也是在2006年底左右。DirectX 10.0 [175]中包含的Shader Model 4.0引入了几个主要功能，例如几何着色器和流输出。 Shader Model 4.0包括适用于所有着色器（顶点，像素和几何图形）的统一编程模型，这是先前描述的统一着色器设计。资源限制进一步增加，并且增加了对整形数据类型（包括按位运算）的支持。 OpenGL 3.3中GLSL 3.30的引入提供了类似的着色器模型。

![1569425383020](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425383020.png)

​		<font size=2>图3.6。用于着色器设计的可视着色器图形系统。各种操作封装在功能框中，可在左侧选择。选中后，每个功能框都有可调参数，如右图所示。每个功能框的输入和输出相互链接以形成最终结果，如中间框架的右下方所示。 （摘自“心理磨坊”，mental images inc。）</font>

​		2009年发布了DirectX 11和Shader Model 5.0，添加了细分阶段着色器和计算着色器，也称为DirectCompute。该版本还专注于更有效地支持CPU多处理，这是第18.5节中讨论的主题。 OpenGL在4.0版中添加了曲面细分着色器，在4.3版中添加了计算着色器。 DirectX和OpenGL的发展不同。两者都设置了特定版本发行所需的一定级别的硬件支持。 Microsoft控制DirectX API，因此直接与独立硬件供应商（IHV）（例如AMD，NVIDIA和Intel）以及游戏开发商和计算机辅助设计软件公司合作，以确定要发布的功能。 OpenGL由非营利组织Khronos Group管理的硬件和软件供应商联盟开发。由于涉及的公司数量众多，API功能通常在DirectX中引入之后的一段时间内OpenGL就会出现。但是，OpenGL允许扩展不论是特定供应商的或更广泛的受众提供的，这些最新的GPU扩展功能在官方发行版正式支持之前使用。

​		API的下一个重大变化是由AMD在2013年推出了MantleAPI。Mantle与视频游戏开发商DICE合作开发的，其目的是消除大部分图形驱动程序的开销，并将此控制直接交给开发人员。除了这种重构之外，还进一步支持有效的CPU多处理器。这类新的API专注于大大减少CPU在驱动程序中花费的时间，以及更有效的CPU多处理器支持（第18章）。在Mantle中开创的创意被Microsoft采纳，并在2015年以DirectX 12的形式发布。请注意，DirectX 12并不专注于公开新的GPU功能-DirectX 11.3公开了相同的硬件功能。这两个API均可用于将图形发送到虚拟现实系统，例如Oculus Rift和HTC Vive。但是，DirectX 12是对API的彻底重新设计，可以更好地映射到现代GPU架构。低开销的驱动程序对于以下应用程序很有用：CPU驱动程序成本引起瓶颈，或者使用更多CPU处理器进行图形处理可能会提高性能[946]。从较早的API移植可能很困难，并且天真的实现可能会导致性能降低[249、699、1438]。

​		苹果在2014年发布了自己的低开销API（称为Metal）。Metal首次在iPhone 5S和iPad Air等移动设备上可用，一年后，可通过OS X El Capitan访问较新的Macing。除效率外，减少CPU使用率还可以节省功耗，这是移动设备上的重要因素。该API具有自己的着色语言，适用于图形和GPU计算程序。

​		AMD将其Mantle工作捐赠给了Khronos Group，后者于2016年初发布了自己的新API，名为Vulkan。与OpenGL一样，Vulkan可在多种操作系统上工作。 Vulkan使用一种称为SPIR-V的新高级中间语言，该语言可用于着色器表示和通用GPU计算。预编译的着色器是可移植的，因此可以在任何GPU支持的所需功能上使用[885]。 Vulkan也可以用于非图形GPU计算，因为它不需要显示窗口[946]。 Vulkan与其他低开销驱动程序的显着区别是，它旨在与多种系统一起使用，从工作站到移动设备。

​		在移动设备上，规范是使用OpenGL ES。 “ ES”代表嵌入式系统，因为该API是为移动设备而开发的。当时的标准OpenGL在其某些调用结构中相当庞大且缓慢，并且需要支持很少使用的功能。 OpenGL ES 1.0于2003年发布，是OpenGL 1.3的简化版本，是固定管线。虽然DirectX的发布与支持它们的图形硬件的发布是同步的，但是开发针对移动设备的图形支持的方式却并不相同。例如，2010年发布的第一台iPad实施了OpenGL ES 1.1。 OpenGL ES 2.0规范于2007年发布，提供了可编程着色。它基于OpenGL 2.0，但没有固定功能组件，因此与OpenGL ES 1.1不向后兼容。 OpenGL ES 3.0于2012年发布，提供了多个渲染目标，纹理压缩，变换反馈，实例化，更广泛的纹理格式和模型以及着色器语言改进等功能。 OpenGL ES 3.1添加了计算着色器，而3.2添加了几何和曲面细分着色器，以及其他功能。第23章将更详细地讨论移动设备架构。

​		OpenGL ES的一个分支是基于浏览器的API WebGL，可通过JavaScript调用。该API的第一版于2011年发布，可在大多数移动设备上使用，因为它的功能等效于OpenGL ES 2.0。与OpenGL一样，扩展允许访问更高级的GPU功能。 WebGL 2假定支持OpenGL ES 3.0。

​		WebGL特别适合在教室中试用功能或使用：

* 它是跨平台的，可在所有个人计算机和几乎所有移动设备上使用。
* 驱动程序批准由浏览器处理。即使一个浏览器不支持特定的GPU或扩展，通常另一个浏览器也支持。
* 代码被解释而不是编译，并且仅需要文本编辑器即可进行开发。
* 大多数浏览器都内置了调试器，可以检查在任何网站上运行的代码。
* 可以通过将程序上传到网站或Github来进行部署。

​		更高级别的场景图形和效果库（例如three.js [218]）使您可以轻松访问代码，以获取各种更复杂的效果，例如阴影算法，后处理效果，基于物理的着色和延迟渲染。

### 3.5顶点着色器

​		顶点着色器是图3.2所示功能管线中的第一阶段。虽然这是程序员直接控制的第一个阶段，但值得注意的是，一些数据操作在此阶段之前已经发生。在DirectX所谓的输入汇编器（input assembler）[175、530、1208]中，几个数据流编织在一起，以形成沿管道发送的顶点集合和图元。例如，一个对象可以由一个位置数组和一个颜色数组表示。输入汇编器将通过创建具有位置和颜色信息的顶点来创建此对象的三角形（线或点）。另一个对象可以使用相同的位置数组（以及不同的模型转换矩阵）和不同的颜色数组表示。数据表示将在16.4.5节中详细讨论。输入汇编器中也支持执行实例化。这允许一个对象被绘制多次，每个实例具有一些不同的数据，所有这些都可以通过一个绘制调用进行。第18.4.2节介绍了实例化的使用。

​		三角形网格由一组顶点集合表示，每个顶点与模型表面上的特定位置相关联。除了位置之外，每个顶点还有其他可选属性，例如颜色或纹理坐标。表面法线也定义在网格顶点上，这似乎是一个奇怪的选择。从数学上讲，每个三角形都有一个定义明确的表面法线，直接将三角形的法线用于着色似乎更有意义。但是，渲染时，通常使用三角形网格来表示基础曲面，而使用顶点法线来表示该表面的方向，而不是三角形网格本身的方向。 16.3.4节将讨论计算顶点法线的方法。图3.7显示了两个三角形网格的侧视图，这些三角形网格代表曲面，一个是平滑的，另一个是带有锐利褶皱的三角形。

​		顶点着色器是处理三角形网格的第一阶段。顶点着色器无法获得形成什么样的三角形数据。顾名思义，它专门处理传入的顶点。顶点着色器提供了一种修改，创建或忽略与每个三角形的顶点关联的值的方法，例如其颜色，法线，纹理坐标和位置。通常，顶点着色器程序会将顶点从模型空间转换为齐次裁剪空间（第4.7节）。顶点着色器至少必须始终输出此位置。

![1569425413580](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425413580.png)

​		<font size=2>图3.7。三角形网格（黑色的，以及顶点法线）侧视图代表的曲面（红色）。在左侧，平滑的顶点法线用于表示平滑表面。在右侧，中间顶点已被复制并指定了两个法线，表示折痕。</font>

​		顶点着色器与前面描述的统一着色器几乎相同。传入的每个顶点都由顶点着色器程序处理，该程序然后输出一些经过在三角形或直线上插值后的值。顶点着色器既不能创建也不能破坏顶点，并且一个顶点生成的结果不能传递到另一个顶点。由于每个顶点都是独立处理的，因此可以将GPU上任意数量的着色处理器并行的应用于传入的顶点流。

​		输入汇编通常表示为在执行顶点着色器之前发生的过程。这是一个物理模型通常与逻辑模型不同的示例。从物理上讲，获取数据以创建顶点的操作可能发生在顶点着色器中，并且驱动程序将默默地在每个着色器开始运行之前添加适当的指令，这些指令对于程序员是不可见的。

​		接下来的章节介绍了几种顶点着色器效果，例如用于动画关节的顶点混合和轮廓渲染。顶点着色器的其他用途包括：

  * 对象生成，通过仅创建一次网格并使其通过顶点着色器变形。

  * 使用蒙皮和渐变技术对角色的身体和面部进行动画处理。

  * 程序变形，例如旗帜，布料或水的移动[802，943]。

  * 通过沿管线发送衰落的（无区域）网格生成粒子，根据需要为这些粒子提供一个区域。。

  * 通过将整个帧缓冲区的内容用作经过程序变形的屏幕对齐网格上的纹理，可以使镜头变形，热雾，水波纹，页面卷曲和其他效果。

  * 通过使用顶点纹理获取[40，1227]应用地形高度场。


​		使用顶点着色器完成的一些变形如图3.8所示。

​		可以通过几种不同的方式使用顶点着色器的输出。通常的是方式是生成和光栅化每个实例的图元（例如三角形），生成的各个像素片段将发送到像素着色器程序以进行继续处理。在某些GPU上，数据也可以发送到曲面细分阶段或几何着色器或存储在内存中。这些可选阶段将在以下各节中讨论。

![1569425434435](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425434435.png)

​		<font size=2>图3.8。左边是一个普通的茶壶。由顶点着色器程序执行的简单剪切操作将生成中间图像。在右侧，噪声函数会创建一个使模型扭曲的领域。 （图像由FX Composer 2制作，由NVIDIA Corporation提供。）</font>

### 3.6曲面细分阶段

​		曲面细分阶段允许我们渲染曲面。 GPU的任务是获取每个表面描述，并将其变成一组代表性的三角形。此阶段是可选的GPU功能，该功能首先在DirectX 11中可用（并且是DirectX 11所必需的）。OpenGL4.0和OpenGL ES 3.2也支持该功能。

​		使用曲面细分阶段有几个优点。曲面描述通常比提供相应的三角形本身更紧紧密。除了节省内存外，此功能还可以防止CPU和GPU之间的总线成为形状每一帧改变的动画角色或对象的瓶颈。表面可以更有效率地渲染通过在给定视角的情况下生成适当数量的三角形。例如，如果一个球远离相机，则仅需要几个三角形。近距离观察时，最好用数千个三角形来表示。这种控制细节水平的能力还可以允许应用程序控制其性能，例如，在较弱的GPU上使用较低质量的网格以保持帧速率。模型通常平坦表面表示的可以转换为三角形的细网格，然后根据需要进行变形[1493]，或者可以对其进行细分，以便不频繁地执行昂贵的作色计算[225]。

​		细分阶段始终由三个元素组成。使用DirectX的术语，它们是外壳着色器，细分和域着色器。在OpenGL中，外壳着色器是曲面细分控制着色器，而域着色器是曲面细分评估着色器，虽然较为冗长，但更具描述性。固定功能细分器在OpenGL中称为图元生成器，并且可以看到，确实是它的功能。

​		在第17章中详细讨论了如何指定和细分曲面和曲线。在此，我们简要概述了每个细分阶段的目的。首先，外壳着色器的输入是一个特殊的面片图元。它由一些控制点组成，这些控制点定义了再细分的表面，贝赛尔面片或其他类型的弯曲元素。外壳着色器具有两个功能。首先，它告诉细分器应生成多少个三角形以及采用哪种配置。其次，它对每个控制点执行处理。同样，可选地，外壳着色器可以修改传入的面片说明，根据需要添加或删除控制点。外壳着色器将其控制点的集合以及细分控制数据输出到域着色器。参见图3.9。

![1569425459428](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425459428.png)

​		<font size=2>图3.9。细分阶段。外壳着色器采用由控制点定义的面片。它将细分因子（TF）和类型发送给固定功能细分器。控制点集合由外壳着色器根据需要进行转换，并与TF和相关的面片常量一起发送到域着色器。细分器将创建一组顶点及其重心坐标。然后由域着色器对其进行处理，从而生成三角形网格（显示控制点以供参考）。</font>

​		细分器是管线中的固定功能阶段，仅与曲面细分着色器一起使用。它的任务是为域着色器添加多个新顶点以进行处理。外壳着色器向细分器发送所需的细分曲面类型的信息：三角形，四边形或等值线。等值线是线条带的集合，有时用于毛发渲染[1954]。外壳着色器所发送的其他重要值是细分因子（OpenGL中的细分级别）。它们有两种类型：内边缘和外边缘。两个内部边缘因子决定了三角形或四边形内部发生了多少细分。外部边缘因子决定每个外部边缘被分割多少（第17.6节）。图3.10显示了增加细分因子的示例。通过允许使用单独的控制，我们可以使相邻曲面的边缘在细分中匹配，而无论内部如何细分。匹配边缘可避免在面片相遇之处出现裂缝或其他着色瑕疵。顶点被分配了重心坐标（第22.8节），这些值指定了所需表面上每个点的各自位置。

​		外壳着色器始终输出面片，一组控制点位置。但是，它可以通过向细分器发送超出细分等级的值零或更低（或非数字，NaN）来发出信号，表示将要丢弃面片。否则，细分器将生成网格并将其发送到域着色器。域着色器的每次调用都使用来自外壳着色器的曲面控制点，以计算每个顶点的输出值。域着色器具有类似于顶点着色器的数据流模式，来自细分器的每个输入顶点都经过处理并生成相应的输出顶点。然后将形成的三角形沿管线向下传递。

![1569425478635](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425478635.png)

​		<font size=2>图3.10。改变细分因子的效果。犹他州茶壶由32个面片组成。从左到右的内部和外部细分因子分别为1、2、4和8（Rideout和Van Gelder [1493]通过演示生成的图像。）</font>

​		尽管此系统听起来很复杂，但为提高效率而采用这种结构，每个着色器可能都非常简单。传递到外壳着色器中的面片通常很少或根本不做修改。该着色器还可以使用面片的估计距离或屏幕大小来动态计算细分因子，就像地形渲染一样[466]。或者，外壳着色器可以简单地为应用程序计算和提供的所有面片传递一组固定的值。细分器执行一个涉及固定功能的过程，生成顶点，指定其位置并指定它们形成的三角形或直线。此数据扩展步骤是在着色器外部执行的，以提高计算效率[530]。域着色器采用为每个点生成的重心坐标，并在面片的评估方程式中使用这些坐标，以生成位置，法线，纹理坐标以及所需的其他顶点信息。有关示例，请参见图3.11。

![1569425494925](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425494925.png)

​		<font size=2>图3.11。左侧是大约6000个三角形的基础网格。在右侧，每个三角形被细分并进行置换使用PN三角形细分。 （图像由NVIDIA公司提供，来自NVIDIA SDK 11 [1301]的示例，由4A Games提供的Metro 2033型号。）</font>

![1569425512835](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425512835.png)

​		<font size=2>图3.12。几何着色器程序的几何着色器输入为某些单一类型：点，线段，三角形。最右边的两个图元包括与直线和三角形对象相邻的顶点。更精细的面片类型是可能的。</font>

### 3.7几何着色器

​		几何着色器可以将图元转换为其他图元，这是曲面细分阶段无法做到的。例如，可以通过让每个三角形创建线边缘，将三角形网格转换为线框视图。或者可以将这些线替换为面向观察者的四边形，从而使线框渲染的边缘更粗[1492]。几何着色器是在2006年底随DirectX 10发行版添加到硬件加速的图形管道中的。它位于管线中的细分着色器之后，并且可以选择使用。虽然是Shader Model 4.0的必需部分，但在较早的着色器模型中未使用它。 OpenGL 3.2和OpenGL ES 3.2也支持这种类型的着色器。

​		几何着色器的输入是单个对象及其关联的顶点。对象通常由带状三角形，线段或单个点组成。扩展的图元可以由几何着色器定义和处理。特别是，可以传入三角形外部的三个附加顶点，并且可以使用折线上的两个相邻顶点。参见图3.12。使用DirectX 11和Shader Model 5.0，您可以传入多达32个控制点的更精细的补丁程序。也就是说，细分阶段对于补丁生成更有效[175]。

​		几何着色器处理该图元并输出零个或多个顶点，这些顶点被视为点，折线或三角形条带。请注意，几何着色器可以不生成任何输出。通过这种方式，可以通过编辑顶点，添加新图元以及删除其他图元来选择性地修改网格。

​		几何着色器设计用于修改传入的数据或制作有限数量的副本。例如，一种用途是生成六个转换后的数据副本，以同时渲染立方体贴图的六个面；参见第10.4.3节。它也可以用来有效地创建级联的阴影贴图，以生成高质量的阴影。利用几何着色器的其他算法包括从点数据创建尺寸可变的粒子，沿着轮廓拉伸鳍以进行毛发渲染，以及为阴影算法找到对象边缘。有关更多示例，请参见图3.13。这些和其他用途将在本书的其余部分中讨论。

​		DirectX 11增加了几何着色器使用实例化的功能，其中几何着色器可以在任何给定的图元上运行设定好的次数[530，1971]。在OpenGL 4.0中，这是通过调用计数指定的。几何着色器最多也可以输出四个流。流可以被发送到渲染管道上以进行进一步处理。所有这些流都是可以选择的发送到流输出渲染目标。

![1569425554991](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425554991.png)

​		<font size=2>图3.13。几何着色器（GS）的某些用途。在左侧，使用GS快速进行球面等值面细分。在中间，使用GS和流输出完成线段的分形细分，而GS生成广告牌以显示闪电。在右侧，通过使用流输出的顶点和几何着色器执行布料模拟。 （图片来自NVIDIA SDK 10 [1300]示例，由NVIDIA Corporation提供。）</font>

​		几何着色器保证图元的输出结果顺序和图元的输入顺序一致。这会影响性能，因为如果多个着色器内核并行运行，结果则必须被保存和排序。此因素和其他因素不利于几何着色器在单个调用中被用于复制或创建大量几何图形的[175，530]。

​		发出绘制调用后，管线中只有三个位置是创建在GPU上工作的：光栅化，细分阶段和几何着色器。其中，考虑到所需的资源和内存，几何着色器的行为是最不可预测的，因为它是完全可编程的。实际上，几何着色器通常很少用，因为它无法很好地映射GPU的优势。在某些移动设备上，它是通过软件实现的，因此在此积极地建议不要使用它[69]。

#### 3.7.1流输出

​		GPU管道的标准用法是通过顶点着色器发送数据，然后光栅化生成的三角形并在像素着色器中进行处理。过去，总是通过管道传递数据，而中间结果无法访问。流输出的想法是在Shader Model 4.0中引入的。在顶点着色器（以及可选的细分和几何着色器）处理了顶点之后，除了可以发送到光栅化阶段之外，还可以将它们输出到流（即有序数组）中。实际上，光栅化可以完全关闭，然后将流水线纯粹用作非图形流处理器。通过这种方式处理的数据可以通过管道发送回去，从而允许进行迭代处理。如第13.8节所述，这种类型的操作可用于模拟流水或其他粒子效果。它也可以用于为模型蒙皮，然后使这些顶点可重复使用（第4.4节）。

​		流输出仅以浮点数的形式返回数据，因此可能会产生明显的内存开销。流输出作用于图元上，而不是直接作用在顶点上。如果将网格沿管道发送，则每个三角形将生成自己的三个输出顶点集合。任何原始网格中共享的顶点都将丢失。因此，更典型的用法是仅将通过管道的顶点作为点集合的图元。在OpenGL中，流输出阶段称为变换反馈，因为它的大部分使用重点是变换顶点并将其返回以进行进一步处理。图元被确保按输入顺序发送到流输出目标，这意味着顶点顺序将被维持[530]。

### 3.8像素着色器

​		如上一章所述，顶点，曲面细分和几何着色器执行完操作后，便会裁剪并设置图元以进行光栅化。管线的这一部分在其处理步骤中是相对固定的，即不可编程的，但有些是可配置的。遍历每个三角形以确定其覆盖哪些像素。光栅化器还可以粗略计算出三角形覆盖每个像素的像元区域的数量（第5.4.2节）。这片块状区域由部分或完全与三角形重叠的像素组成称为片段。

​		三角形顶点的值（包括z缓冲区中使用的z值）将在三角形表面上的每个像素插值。这些值将传递到像素着色器，然后由该着色器处理片段。在OpenGL中，像素着色器称为片段着色器，这也许是一个更好的名称。为了保证一致性，我们在本书中始终使用“像素着色器”。沿管线发送的点和线图元也会为所覆盖的像素创建片段。

​		跨整个三角形执行的插值类型由像素着色器程序指定。通常，我们使用透视校正内插法，以使像素表面位置之间的世界空间距离随着对象后退距离的增加而增加。一个示例是渲染延伸到地平线的铁轨。铁轨在铁轨较远的地方间距更近，因为每个接近地平线的连续像素行进的距离都更大。其他插值类型也可选，例如屏幕空间插值（其不考虑透视投影）。 DirectX 11给予进一步控制何时以及如何执行插值[530]。

​		用编程术语来说，顶点着色器程序的输出（在三角形（或线）上的插值）实际上成为像素着色器程序的输入。随着GPU的发展，其他输入也已开放。例如，片段的屏幕位置可用于Shader Model 3.0及更高版本中的像素着色器中。同样，三角形的哪一侧可见是一种输入标志。该属性对渲染正面和背面不同的材质的三角形的非常重要在单次的渲染中。

![1569425576993](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425576993.png)

​		<font size=2>图3.14。用户定义的剪切平面。在左侧，单个水平裁剪平面将对象切片。在中间，嵌套球被三个平面修剪。在右侧，仅当球体的曲面在所有三个剪切平面的外部时，才对其进行剪切。 （来自Three.js示例中的webgl剪切和webgl剪切交集[218]。）</font>

​		随着输入的进行，通常像素着色器会计算并输出片段的颜色。它还可能会产生不透明度值，并可以选择修改其z深度值。在合并期间，这些值用于修改存储在像素处的内容。光栅化阶段生成的深度值也可以由像素着色器修改。模板缓冲区值通常是不可修改的，而是传递到合并阶段。 DirectX 11.3允许着色器更改此值。雾计算和Alpha测试等操作已从合并操作转换到在像素着色器中计算在SM 4.0中[175]。

​		像素着色器还具有丢弃传入片段（即不产生任何输出）的独特功能。图3.14显示了如何使用片段丢弃的一个示例。剪切平面功能以前是固定功能管道中的可配置元素，后来在顶点着色器中指定。随着片段丢弃功能的可用，裁剪平面功能就可以在像素着色器中用任何所需的方式来实现，例如确定剪切量应进行“与”运算还是“或”运算。

​		最初，像素着色器只能输出到合并阶段，以进行最终显示。随着时间的推移，像素着色器可以执行的指令数量已大大增加。这种增加引起了多个渲染目标（MRT）的想法。不仅可以将像素着色器程序的结果仅发送到颜色和z缓冲区，还可以为每个片段生成多组值并将其保存到不同的缓冲区，每个缓冲区称为渲染目标。渲染目标通常具有相同的x和y维度；一些API允许使用不同的大小，但是渲染区域将是其中最小的。一些架构要求渲染目标必须具有相同的位深，甚至可能具有相同的数据格式。取决于GPU，可用的渲染目标数量为四个或八个。

​		尽管有这些限制，MRT功能还是能有力的辅助更有效地执行渲染算法。一次渲染过程可以在一个目标中生成色彩图像，在另一个目标中生成对象标识符，在第三个目标中生成世界空间距离。此功能还引起了另一种类型的渲染管道，称为延迟着色，其中可见性和着色是在单独的pass中完成的。第一次pass存储有关每个像素处对象位置和材质的数据，然后以后连续的pass可以有效地施加照明和其他效果。此类渲染方法在第20.1节中进行了描述。

​		像素着色器的局限性在于，它通常写入的渲染目标只有在传递给它的片段位置上，而不能从相邻像素读取当前结果。也就是说，执行像素着色器程序时，它无法将其输出直接发送到相邻像素，也无法访问其他人的最新更改。而是，它计算仅影响其自身像素的结果。但是，此限制并不像听起来那样严重。一次pass中创建的输出图像可以让像素着色器在后续的pass中访问其任何数据。可以使用第12.1节中所述的图像处理技术来处理相邻像素。

​		像素着色器无法了解或影响相邻像素的结果的规则是有例外的。一种是像素着色器可以在计算梯度或导数信息时立即访问相邻片段的信息（尽管是间接的）。像素着色器具有沿x和y屏幕轴每个像素的任何插值变化的量。这些值可用于各种计算和纹理寻址。这些梯度对于诸如纹理过滤（第6.2.2节）之类的操作尤为重要，因为我们想知道多少图像覆盖了一个像素。所有现代GPU都通过以2×2的组处理片段（称为四边形）来实现此功能。当像素着色器请求梯度值时，将返回相邻片段之间的差异。参见图3.15。统一核心具有访问相邻数据（保留在同一warp中的不同线程中）的功能，因此可以计算用于像素着色器的梯度。作为此实现的一个结果，梯度信息无法被某些受动态流控制影响的着色器访问（例如，带有迭代变量的循环“ if”或循环语句）中访问渐变信息。组中的所有片段都必须使用相同的指令集进行处理，以便所有四个像素的结果对于计算梯度都是有意义的。这是一个基本限制，即使在离线渲染系统中也存在[64]。

​		DirectX 11引入了一种缓冲区类型，该类型允许对任何位置（unordered access view（UAV））的进行写访问。最初仅适用于像素和计算着色器，对UAV的访问已扩展到所有着色器在DirectX 11.1中[146]。 OpenGL 4.3将此称为着色器存储缓冲区对象（SSBO）。这两个名称以其自己的方式进行描述。像素着色器以任意顺序并行运行，并且此存储缓冲区在它们之间共享。

​		通常需要某种机制来避免数据竞争情况（也称为数据危险），在这种情况下，两个着色器程序都在“竞相”以影响相同的值，从而可能导致任意结果。例如，如果两次调用像素着色器试图在大约同一时间将其结果添加到相同的检索值中，则可能会发生错误。两者都将检索原始值，都将在本地对其进行修改，但是，无论哪个调用最后写入其结果，都将抹去另一个调用的作用，只会发生一次添加。 GPU通过使用着色器可以访问的专用原子单元来避免此问题[530]。但是，原子意味着某些着色器可能在等待访问另一个着色器进行读/修改/写操作的存储位置时停滞。

![1569425601443](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425601443.png)

​		<font size=2>图3.15。在左侧，将三角形栅格化为四边形，每组2×2像素。然后，在右侧显示了带有黑点标记的像素的梯度计算。针对四边形中四个像素位置的每一个，显示了v的值。请注意，三角形中没有覆盖三个像素，但是GPU仍对其进行处理，以便可以找到渐变。通过使用左下像素的两个四边形邻居，可以计算出x和y屏幕方向上的渐变。</font>

​		尽管原子避免了数据危害，但许多算法都需要特定的执行顺序。例如，您可能需要绘制一个更远的透明蓝色三角形，然后再用红色透明三角形覆盖它，将红色混合在蓝色上面。这可能对一个像素进行两次像素着色器调用，每个三角形调用一次，以这样一种方式执行：红色三角形的着色器先于蓝色着色器完成。在标准管线中，片段结果将在合并阶段进行排序，然后再进行处理。在DirectX 11.3中引入了光栅化顺序视图（ROV）以强制执行顺序。这些就像UAV。着色器可以以相同的方式读取和写入它们。关键区别在于ROV保证以正确的顺序访问数据。这大大增加了这些着色器可访问缓冲区的有用性[327、328]。例如，ROV使像素着色器可以编写自己的混合方法，因为它可以直接访问和写入ROV中的任何位置，因此不需要合并阶段[176]。代价是，如果检测到乱序访问，像素着色器调用可能会停顿，直到处理了先前绘制的三角形。

### 3.9合并阶段

​		如第2.5.2节所述，合并阶段是将各个片段（在像素着色器中生成）的深度和颜色与帧缓冲区组合在一起。 DirectX将此阶段称为输出合并； OpenGL将其称为逐样本的操作。在大多数传统管线图（包括我们自己的管线图）上，此阶段是模板缓冲区和z缓冲区操作发生的地方。对于可见的片段，则此阶段中发生的另一种操作是颜色混合。对于不透明的表面，不涉及真正的混合，因为片段的颜色会简单地替换以前存储的颜色。片段和所存储颜色的实际混合通常用于透明度和合成操作（第5.5节）。

​		想象一下，通过光栅化生成的片段通过像素着色器，然后在应用z缓冲区时被某些先前渲染的片段隐藏。这样就不需要在像素着色器中进行所有处理。为了避免这种浪费，许多GPU在执行像素着色器之前执行一些合并测试[530]。片段的z深度（以及其他正在使用的东西，例如模板缓冲区或剪刀）用于测试可见性。如果隐藏该片段，则将其剔除。此功能称为Early-z [1220，1542]。像素着色器具有更改片段的z深度或完全丢弃片段的能力。如果发现像素着色器程序中存在这两种类型的操作，则通常无法使用Early-Z，然后通常将其关闭，这通常会使管线效率降低。 DirectX 11和OpenGL 4.2允许像素着色器强制进行Early-Z测试，尽管有很多限制[530]。有关早期z和其他z缓冲区优化的更多信息，请参见第23.7节。有效使用Early-z会对性能产生很大影响，这将在18.4.5节中详细讨论。

​		合并阶段占据了固定功能阶段（例如三角形设置）和完全可编程着色器阶段之间的中间地带。尽管它不是可编程的，但它的操作是高度可配置的。可以将颜色混合设置为执行大量不同的操作。最常见的是涉及颜色和Alpha值的乘法，加法和减法的组合，但是其他操作（例如最小值和最大值）以及按位逻辑运算也是可能的。 DirectX 10添加了将来自像素着色器与帧缓冲区的两种颜色混合的功能。此功能称为双源颜色混合，不能与多个渲染目标（MRT）一起使用。 否则的话MRT支持混合，DirectX 10.1引入了在每个单独的缓冲区上执行不同混合操作的功能。

​		如上一节末尾所述，DirectX 11.3提供了一种通过ROV将混合可编程化的方法，尽管这是以性能为代价的。 ROV和合并阶段都保证了绘制顺序，也就是输出不变性。不管像素着色器生成结果的顺序如何，API要求都按照结果的输入顺序（对象接对象，三角形接三角形）对结果进行排序分类并将其发送到合并阶段。

### 3.10计算着色器

​		GPU除了实现传统的图形管线外还可以用于其他用途。在非图形领域，例如计算领域，用于计算股票期权的估计价值和训练用于深度学习的神经网络。这种方式使用硬件的方式称为GPU计算。诸如CUDA和OpenCL之类的平台可以将GPU可作为大型并行处理器来控制GPU，而无需访问特定的图形功能。这些框架通常使用带有扩展功能的C或C ++等语言以及为GPU制作的库。

​		DirectX 11中引入了计算着色器，它是GPU计算的一种形式，因为它是一种未锁定在图形管线中的位置的着色器。由于它被图形API所调用，所以与渲染过程紧密相关。它与顶点，像素和其他着色器一起被使用。它同样使用在管线中使用的统一着色器处理器池。与其他着色器一样，它是着色器，因为它具有一组输入数据，并且可以访问缓冲区（例如纹理）以进行输入和输出。warp和线程在计算着色器中更明显。例如，每个调用都会获取一个可以访问的线程索引。还有一个线程组的概念，它在DirectX 11中由1到1024个线程组成。这些线程组由x，y和z坐标指定，主要是为了简化在着色器代码中的使用。每个线程组都有少量在线程之间共享的内存，等于32 kB在DirectX 11中。计算着色器由线程组执行，以此确保该组中的所有线程可以同时运行[1971]。

​		计算着色器的一个重要优点是它们可以访问在GPU上生成的数据。从GPU向CPU发送数据会产生延迟，因此如果可以将处理和结果保留在GPU上，则可以提高性能[1403]。后期处理（以某种方式修改了渲染的图像）是计算着色器的常见用法。共享内存意味着来自采样图像像素的中间结果可以与相邻线程共享。例如，已经发现使用计算着色器确定图像的分布或平均亮度的运行速度是在像素着色器上执行此操作的两倍[530]。

​		计算着色器还可用于粒子系统，网格处理（例如面部动画[134]，剔除[1883、1884]，图像过滤[1102、1710]，提高深度精度[991]，阴影[865]，景深[ 764]，以及任何其他可以通过一组GPU处理器承担的任务。 Wihlidal [1884]讨论了计算着色器如何比曲面细分外壳着色器更有效。其他用途请参见图3.16。

​		到此，通过GPU实现的渲染管线的旅途结束了。有多种方法可以使用和组合GPU功能来执行各种与渲染相关的过程。调整以利用这些功能的相关理论和算法是本书的重点。现在，我们将重点放在变换和着色上。

![1569425627411](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425627411.png)

​		<font size=2>图3.16。计算着色器示例。左侧是计算着色器，用于模拟受风影响的头发，并使用细分阶段渲染头发本身。在中间，计算着色器执行快速模糊操作。在右侧，模拟了海浪。 （图像来自NVIDIA SDK 11 [1301]示例，由NVIDIA Corporation提供。）</font>

### 进一步阅读和资源

​		吉森（Giesen）的图形管道之旅[530]详细讨论了GPU的许多方面，并解释了元素为何以它们的方式工作。 Fatahalian和Bryant的课程[462]在一系列详细的讲义幻灯片集中讨论了GPU并行性。尽管着眼于使用CUDA进行GPU计算，但Kirk和Hwa的书[903]的介绍部分讨论了GPU的发展和设计理念。

​		要学习着色器编程的形式方面，需要花费一些工作。诸如OpenGL Superbible [1606]和OpenGL Programming Guide [885]之类的书都包含有关着色器编程的材料。旧书OpenGL Shading Language [1512]没有涵盖较新的着色器阶段，例如几何和细分着色器，但确实专注于与着色器相关的算法。有关最新和推荐的图书，请参见本书的网站realtimerendering.com。





​		



​			

​							

​    

​    

​    

## 4.变换

​		变换是一种操作，它接受点，向量或颜色等实体，并以某种方式对其进行转换。对于计算机图形从业者来说，掌握转换极为重要。使用它们，您可以定位，重塑形状和设置对象，灯光和照相机的动画。您还可以确保所有计算都在同一坐标系中进行，并将对象以不同的方式投影到平面上。这些只是少数可以通过变换执行的操作，但是它们足以说明变换在实时图形或任何形式的计算机图形中的重要性。

​		线性变换是保留矢量加法和标量乘法的变换。特别，

​		
$$
f(x)+f(y)=f(x+y)\qquad\qquad\qquad\quad(4.1)\\
kf(x)=f(kx)\qquad\qquad\qquad\qquad\qquad(4.2)
$$
​		例如，f（x）= 5x是一个采用向量并将每个元素乘以5的变换。为了证明这是线性的，需要满足两个条件（公式4.1和4.2）。第一个条件成立，因为任何两个向量乘以五然后相加将与将向量相加然后相乘相同。标量乘法条件（方程式4.2）已明确满足。此功能称为缩放变换，因为它可以更改对象的缩放比例（大小）。旋转变换是另一个线性变换，使向量围绕原点旋转。比例变换和旋转变换，实际上是三元素矢量的所有线性变换，都可以使用3×3矩阵表示。

​		但是，矩阵的大小通常不够大。三元素向量x的函数（例如f（x）= x +（7，3，2））不是线性的。在两个单独的向量上执行此函数将把（7，3，2）的每个值相加两次以形成结果。将一个定值的向量添加到另一个向量会执行变换，例如，它将所有位置移动相同的数量。这是一种有用的变换类型，我们想结合各种变换，例如，将对象缩放到一半大小，然后将其移动到其他位置。到目前为止，将函数保持在简单的形式上很难使它们轻松组合。

​		可以使用仿射变换将线性变换和平移结合起来，通常以4×4矩阵形式存储。仿射变换是先执行线性变换然后执行平移的变换。为了表示四个元素的向量，我们使用齐次记法，以相同的方式表示点和方向（使用粗体小写字母）。方向向量表示为$$v =（v_x v_y v_z 0）^T$$，点表示为$$v =（v_x v_y v_z 1）^T$$。在本章中，我们将广泛使用在realtimerendering.com上可下载的线性代数附录中解释的术语和运算。

​		所有平移，旋转，缩放，反射和剪切矩阵都是仿射的。仿射矩阵的主要特征是它保留了线的平行性，但不一定保留长度和角度。仿射变换也可以是各个仿射变换的串联的任何序列。

​		本章将从最基本的基本仿射变换开始。本部分可以看作是简单转换的“参考手册”。然后描述了更特殊的矩阵，随后对四元数（一种强大的转换工具）进行了讨论和描述。然后是顶点融合和变形，这是两种表达网格动画的简单但有效的方法。最后，描述了投影矩阵。这些转换中的大多数，它们的符号，功能和特性总结在表4.1中，其中正交矩阵其逆矩阵是其转置矩阵。

​		变换是用于操纵几何的基本工具。大多数图形应用程序编程接口允许用户设置任意矩阵，有时库可能使用了许多实现了本章讨论的转换的矩阵运算。但是，仍然有必要了解函数调用背后的实际矩阵及其相互作用。知道这样的函数调用之后矩阵的功能是一个开始，但是了解矩阵本身的属性将使您更进一步。例如，这种理解使您处理正交矩阵时（其逆矩阵是其转置矩阵），从而可以更快地进行矩阵求逆。这样的知识可以加速代码运行效率。

​		



### 4.1基础变换

​		本节介绍最基本的变换，例如平移，旋转，缩放，切边，变换级联，刚体变换，法线变换（不是正常的）和逆计算。对于有经验的读者，可以将其用作简单转换的参考手册，对于新手，则可以作为本主题的入门。本材料是本章其余部分和本书其他各章的必要背景。我们从最简单的变换开始-平移。

|                 符号                  |     名字     |                             行为                             |
| :-----------------------------------: | :----------: | :----------------------------------------------------------: |
|      $$\textbf{T}(\textbf{t})$$       |   变换矩阵   |                       平移一个点，仿射                       |
|        $$\textbf{R}_x(\rho)$$         |   旋转矩阵   |     绕x轴旋转ρ弧度。 y轴和z轴的表示法相似。 正交和仿射。     |
|            $$\mathbf{R}$$             |   旋转矩阵   |                   任意旋转矩阵，正交，仿射                   |
|           $$\mathbf{S}(s)$$           |   缩放矩阵   |                   根据s同时缩放xyz轴，仿射                   |
|        $$\mathbf{H}_{ij}(s)$$         |   切变矩阵   |  相对于分量j，将分量i根据因子s切变。i，j∈{x，y，z}。 仿射。  |
|       $$\mathbf{E}(h,\rho,r)$$        |   欧拉变换   | 欧拉角给出的取向矩阵，head（yaw），pitch，roll 。 正交和仿射。 |
|          $$\mathbf{P}_o(s)$$          |   正交投影   |               平行投影到某一片面或者体积，仿射               |
|          $$\mathbf{P}_p(s)$$          |   透视投影   |                  透视投影到某一片面或者体积                  |
| $$\text{slerp}{(\hat{q},\hat{r},t)}$$ | 球面线性插值 |          生成关于四元数q和r以及参数t的插值四元数。           |

​		<font size=2>表4.1。本章讨论的大多数转换的摘要。</font>

#### 4.1.1平移变换

​		从一个位置到另一个位置的变化由平移矩阵$$\mathbf{T}$$表示。此矩阵通过向量$$\mathbf{t}$$ =（$$t_x，t_y，t_z$$）平移实体。 $$\mathbf{T}$$由下面的公式4.3给出：
$$
\textbf{T}(\textbf{t})=
\textbf{T}(t_x,t_y,t_z)=
\begin{gather*}
\begin{pmatrix}
1 & 0& 0 & t_x \\
0 & 1& 0 & t_y \\
0 & 0& 1 & t_z \\
0 & 0& 0 & 1
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.3)
$$
​		图4.1显示了平移变换效果的示例。容易证明，将点p =（$$p_x，p_y，p_z，1$$）与$$\mathbf{T}$$（t）相乘会产生一个新的点p'=（$$p_x + t_x，p_y + t_y，p_z + t_z，1$$），很显然是平移。 注意向量v =（$$v_x，v_y，v_z，0$$）不受与矩阵T乘法的影响，因为方向向量无法平移。相反，其余的仿射变换都会影响点和向量。平移矩阵的逆是$$\mathbf{T}^{-1}（t）=\mathbf{T}(-t)$$，即向量$$\mathbf{t} $$取反。

​	![image-20191118213722377](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191118213722377.png)

​		<font size=2>图4.1。左侧的正方形通过平移矩阵T（5，2，0）进行变换，从而使正方形向右移动5个距离单位，向上移动2个距离单位。</font>

​		在这一点上，我们应该提到的是，有时在计算机图形学中也可以看到的另一种有效的符号方案是使用矩阵和行向量。例如，DirectX使用这种形式。在该方案中，矩阵的顺序将被颠倒，即，应用的顺序将从左到右读取。因为向量是行，所以用这种表示法表示的矢量和矩阵都是行形式。在本书中，我们使用列形式。无论使用哪种方式，这纯粹是一种符号上的差异。当矩阵存储在内存中时，十六个值的最后四个值是三个转换值，跟上一个1。

#### 4.1.2旋转变换

​		旋转变换将向量（位置或方向）绕经过原点的给定轴旋转给定角度。像平移矩阵一样，它是一个刚体变换，即它保留了变换后的点之间的距离，并保留了惯用性（即它从不导致左右两侧互换）。在计算机图形学中，这两种类型的转换对于定位和定向对象非常有用。方位矩阵是与摄像机视图或对象相关联的旋转矩阵，它定义了其在空间中的方位，即其向上和向前的方向。

​		在二维中，旋转矩阵很容易得出。假设我们有一个向量$$\mathbf{v}=(v_x,v_y)$$，我们将其参数化为$$\mathbf{v}=(v_x,v_y)=（r\cos\theta,r\sin\theta）$$。如果我们将向量旋转$$\phi$$弧度（逆时针），则将得到$$\mathbf{u}=(r\cos(\theta+\phi),r\sin(\theta+\phi))$$。这可以重写为

​		
$$
\begin{gather*}
\textbf{u}=
\begin{pmatrix}
r cos(\theta+\phi) \\
r sin(\theta+\phi) \\
\end{pmatrix}=
\begin{pmatrix}
r(cos\theta\cos\phi-sin\theta\sin\phi) \\
r(sin\theta\cos\phi+cos\theta\sin\phi) \\
\end{pmatrix}\\
=
\underbrace {
\begin{pmatrix}
cos\theta\qquad-sin\phi \\
sin\theta\qquad cos\phi
\end{pmatrix}}_{\textbf{R}(\phi)}
\underbrace {
\begin{pmatrix}
rcos\theta\\
rsin\theta
\end{pmatrix}}_{\textbf{v}}
=\textbf{R}(\phi)\textbf{v}
\end{gather*}
\qquad\qquad(4.4)
$$
​		这里我们使用角度和关系来展开$$r\cos(\theta+\phi)$$和$$r\sin(\theta+\phi)$$。在三维上，常用的旋转矩阵是$$\mathbf{R}_x(\phi),\mathbf{R}_y(\phi),\mathbf{R}_z(\phi)$$，它们分别绕x，y和z轴旋转$$\phi $$弧度。它们由公式4.5–4.7给出：

​		
$$
\textbf{R}_{x}(\phi)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1 & 0& 0 & 0\\
0& cos\phi&-\sin\phi& 0 \\
0 &sin\phi&\cos\phi& 0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.5)
$$

$$
\textbf{R}_{y}(\phi)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
cos\phi & 0& sin\phi & 0\\
0& 1&0& 0 \\
-sin\phi &0&\cos\phi& 0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.6)
$$

$$
\textbf{R}_{z}(\phi)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
cos\phi&sin\phi&0 & 0\\
sin\phi&\cos\phi&0& 0 \\
0 & 0&1&0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.7)
$$

​		如果从4×4矩阵中删除最底行和最右列，则将获得3×3矩阵。对于绕任意轴旋转$$\phi$$弧度的每3×3旋转矩阵R，迹线（矩阵中对角元素的总和）与轴无关，是恒定的，计算公式为[997]：

​		
$$
tr(\textbf{R})=1+2cos\phi\qquad\qquad(4.8)
$$
​		旋转矩阵的效果可以在第65页的图4.4中看到。旋转矩阵$$\mathbf{R}_i(\phi)$$的特点除了它绕着轴i旋转$$\phi $$弧度外，还在于它将旋转轴i上的所有点保持不变。注意，$$\mathbf{R} $$也将用于表示围绕任何轴的旋转矩阵。上面给出的轴旋转矩阵可以在一系列三个变换(分解为x,y,z轴3个分量)中使用，以执行绕任意轴旋转。该过程在第4.2.1节中讨论。第4.2.4节介绍了直接绕任意轴旋转。

​		所有旋转矩阵的行列式均为1，并且是正交的。这对于任何数量的旋转变换的串联也成立。还有另一种求逆的方法：$$\mathbf{R}_i^{-1}(\phi)=\mathbf{R}_i(-\phi)$$，即绕同一轴线沿相反方向旋转。

​		示例：绕点旋转。假设我们要围绕z轴旋转一个对象$$\phi $$弧度，并且旋转中心为某个确定点$$\mathbf{P}$$。如何转换？图4.2中描述了这种情况。由于绕点旋转的特点在于该点本身不受旋转的影响，因此变换首先通过平移对象使$$\mathbf{P}$$点与原点重合开始，这是通过$$\mathbf{T}(\mathbf{-p})$$完成的。此后跟随实际旋转：$$\mathbf{R}_z(\mathbf{\phi})$$。最后，必须使用$$\mathbf{T}(\mathbf{p})$$将对象平移回其原始位置。然后，得到的变换$$\mathbf{X}$$由下式给出

​		
$$
\textbf{X}=\textbf{T}(\textbf{p})\textbf{R}_{z}(\phi)\textbf{T}(-\textbf{p})
\qquad\qquad(4.9)
$$
​		注意上面矩阵的顺序。

![image-20191118213802325](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191118213802325.png)

​		<font size=2>图4.2。围绕特定点p旋转的示例。</font>

#### 4.1.3缩放变换

​		缩放矩阵$$\mathbf{S}(\mathbf{s})=\mathbf{S}(s_x,s_y,s_z)$$分别沿x，y和z方向缩放因子为$$s_x,s_y$$和$$s_z$$的实体。这意味着可以使用缩放矩阵来放大或缩小对象。$$s_i,i\in\{x,y,z\}$$越大，则实体在该方向上缩放越大。将s的任何分量设置为1自然可以避免该方向缩放的更改。公式4.10显示S：

​		
$$
\textbf{S}(s)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
S_{x}&0&0 & 0\\
0&S_{y}&0& 0 \\
0 & 0&S_{z}&0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.10)
$$
​		<font size=2>第65页上的图4.4说明了缩放矩阵的作用。如果$s_x=s_y=s_z$，则缩放操作称为均匀操作，否则称为非均匀操作。有时，使用等向性和各向异性缩放来代替均匀和非均匀性。逆运算是$S^{-1}（s）= S（1 / s_x，1 / s_y，1 / s_z）$。</font>

​		使用齐次坐标，创建统一缩放矩阵的另一种有效方法是通过操作位置（3,3）处的矩阵元素，即右下角的元素。该值会影响齐次坐标的w分量，因此会缩放矩阵变换后的点（而非表示方向的向量）的每个坐标分量。例如，要均匀地缩放5倍，可以将缩放矩阵中（0，0），（1、1）和（2，2）的元素设置为5，或将（3， 3）可以设置为1/5。执行此操作的两种不同矩阵如下所示：

​		
$$
\textbf{S}(s)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
5&0&0 & 0\\
0&5&0& 0 \\
0 & 0&5&0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix},
\qquad\qquad
\textbf{S}^{'}=
\begin{pmatrix}
\begin{matrix}
1&0&0 & 0\\
0&1&0& 0 \\
0 & 0&1&0 \\
0 & 0& 0 & 1/5
\end{matrix}
\end{pmatrix}.
\end{gather*}
\qquad \qquad (4.11)
$$
​		与使用$$\mathbf{S}$$进行均匀缩放相反，使用$$\mathbf{S'}$$必须始终在之后进行归一化。这可能是低效的，因为它涉及归一化过程中的除法。如果右下角的元素（位置（3，3））为1，则不需要除法。当然，如果系统总是在不进行1测试的情况下进行除法，则不会产生任何额外费用。

​		$$\mathbf{S}$$的一个或三个分量上的负值给出一种反射矩阵，也称为镜像矩阵。如果只有两个比例因子为-1，那么我们将旋转π弧度。应当注意，与反射矩阵连接的旋转矩阵也是反射矩阵。因此，以下是反射矩阵：

​		
$$
\begin{gather*}
\underbrace {
\begin{pmatrix}
cos(\pi/2)&sin(\pi/2) \\
-sin(\pi/2)&cos(\pi/2) \\
\end{pmatrix}}_{旋转}
\underbrace {
\begin{pmatrix}
1&0\\0&1
\end{pmatrix}}_{反射}=
\begin{pmatrix}
0&-1\\-1&0
\end{pmatrix}.
\end{gather*}
\qquad\qquad(4.12)
$$
​		通常反射矩阵在检测到时需要特殊处理。例如，当三角形的具有逆时针顺序的顶点经过反射矩阵转换后，其顶点将获得顺时针顺序。此顺序更改可能导致不正确的照明和背面剔除。要检测给定矩阵是否以某种方式反射，请计算矩阵左上3×3个元素的行列式。如果该值为负，则矩阵是反射性的。例如，公式4.12中矩阵的行列式为0·0 −（-1）·（-1）= -1。

​		示例：沿特定方向缩放。缩放矩阵$$\mathbf{S}$$仅沿x轴，y轴和z轴缩放。如果应在其他方向执行缩放，则需要复合转换。假设缩放沿着正交的轴进行，右向向量$$\mathbf{f}^x,\mathbf{f}^y$$和$$\mathbf{f}^z$$。首先，构造矩阵$$\mathbf{F}$$，以更改基底，如下所示：

​		
$$
\textbf{F}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\textbf{f}^x&\textbf{f}^y&\textbf{f}^z& 0\\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad \qquad (4.13)
$$
​		想法是使给定的坐标系的三个轴与标准轴重合，然后使用标准缩放矩阵，然后变换回去。第一步是通过乘以$$\mathbf{F}$$的转置即它的逆来进行的。然后完成实际的缩放，然后再变换回去。转换如公式4.14所示：

​		
$$
\textbf{X}=
\textbf{FS}(\textbf{s})
\textbf{F}^{T}.
\qquad \qquad (4.13)
$$

#### 4.1.4切变变换

​		另一类变换是其切变矩阵集。例如，这些可以用于游戏中以扭曲整个场景，以产生迷幻效果或扭曲模型的外观。有六个基本切变矩阵，分别表示为$$\mathbf{H}_{xy}(s)，\mathbf{H}_{xz}(s)，\mathbf{H}_{yx}(s)，\mathbf{H}_{yz}(s)，\mathbf{H}_{zx}(s)）$$和$$\mathbf{H}_{zy}(s)$$。第一个下标用于表示切变矩阵更改哪个坐标轴分量，而第二个下标表示使用哪个坐标轴分量进行剪切的。剪切矩阵$$\mathbf{H}_{xz}(s)$$的示例如公式4.15所示。注意，下标可用于在下面的矩阵中找到参数s的位置； x（其数字索引为0）标识第零行，而z（其数字索引为2）标识第二列，因此s位于此处：

​		
$$
\textbf{H}_{xz}(s)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&s & 0\\
0&1&0& 0 \\
0 & 0&1&0 \\
0 & 0& 0 & 1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.15)
\end{gather*}
$$
​		![image-20191118231628089](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191118231628089.png)

​		<font size=2>图4.3。用Hxz剪切单位正方形的效果。 y值和z值都不受转换的影响，而x值是旧x值和s乘以z值的总和，从而导致平方倾斜。这种变换是保留区域的，这可以通过虚线区域相同来看出。</font>

​		将该矩阵与点p相乘会产生一个点：$$(p_x+sp_z\quad p_y\quad p_z)^{T}$$。图4.3中以单位正方形的形式显示了这一点。$$\mathbf{H}_{ij}(s) $$的逆运算（根据第j个坐标轴剪切第i个坐标轴，其中i$$ \neq $$ j）是通过沿相反方向切变而生成的，即，$$\mathbf{H}_{ij}^{-1}(s)=\mathbf{H}_{ij}(-s)$$。

​		你还可以使用略有不同的一种切变矩阵：
$$
\textbf{H}^{'}_{xz}(s,t)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1 & 0 & s & 0\\
0 & 1 & t & 0 \\
0 & 0 & 1 & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.16)
\end{gather*}
$$
​		但是此处，两个下标均用于表示这些坐标轴将被第三坐标轴剪切。这两种不同类型的描述之间的联系是$$\mathbf{H}_{ij}'(s,t)=\mathbf{H}_{ij}(s)\mathbf{H}_{ij}(t)$$，其中k用作第三坐标轴的索引。使用的矩阵取决于个人。最后，应该注意的是，由于任何切变矩阵的行列式| H | = 1，这是一个保留体积的变换，如图4.3所示。

#### 4.1.5变换的级联

​		由于矩阵上乘法运算的不可交换性，因此矩阵出现的顺序很重要。因此，变换的级联被认为是与顺序相关的。

​		作为顺序依赖性的示例，请考虑两个矩阵$$\mathbf{S} $$和$$ \mathbf{R}$$。$$\mathbf{S}(2,0.5,1)$$将x分量缩放为两倍，将y分量缩放为0.5。 $$\mathbf{R}_z(\pi/6)$$绕z轴逆时针旋转π/ 6弧度（右手坐标系从本书的页面指向向外）。这些矩阵可以用两种方法相乘，结果完全不同。这两种情况如图4.4所示。

![image-20191118234057271](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191118234057271.png)

​		<font size=2>图4.4。这说明了矩阵相乘时的顺序依赖性。在第一行中，应用旋转矩阵$R_z（π/ 6）$，然后缩放$S(s)$，其中$s$ =（2，0.5，1）。这样，合成矩阵为$S(s)R_z（π/ 6）$。在底行中，以相反的顺序应用矩阵，得出$R_z（π/ 6）S(s)$。结果明显不同。对于任意矩阵M和N，一般认为MN $\neq$ NM。</font>

​		将一系列矩阵连接为单个矩阵的明显原因是为了提高效率。例如，假设您的游戏场景具有数百万个顶点，并且场景中的所有对象都必须缩放，旋转并最终平移。现在，不是将所有顶点与这三个矩阵中的每一个相乘，而是将这三个矩阵连接到一个矩阵中。然后将此矩阵应用于顶点。该复合矩阵为$$\mathbf{C=TRS}$$。注意这里的顺序。缩放矩阵$$\mathbf{S} $$应该首先应用于顶点，因此在合成中显示在右侧。该排序意味着$$\mathbf{TRSp =(T(R(Sp)))}$$，其中p是要转换的点。顺便说一句，$$\mathbf{TRS}$$是场景图系统常用的顺序。

​		值得注意的是，虽然矩阵级联是依赖于顺序的，但是矩阵可以根据需要进行组合。例如，假设您要使用$$\mathbf{TRSp}$$计算一次刚体变换$$\mathbf{TR}$$。将这两个矩阵$$(\mathbf{TR})(\mathbf{Sp})$$组合在一起并用中间结果替换原先的$$\mathbf{TRSp} $$是有效的。因此，矩阵的级联满足结合律的。

#### 4.1.6刚体变换

​		当一个人抓住一个坚固的物体时，例如从桌子上将笔移动到另一个位置，也许移动到衬衫的口袋里，只有物体的方向和位置会发生变化，而物体的形状通常不会受到影响。这种仅由平移和旋转的串联组成的变换称为刚体变换。它具有保留长度，角度和惯用性的特性。

​		可以将任何刚体矩阵$$\mathbf{X} $$表示为平移矩阵$$\mathbf{T}(\mathbf{t})$$和旋转矩阵$$ \mathbf{R} $$的串联。因此，矩阵$$\mathbf{X} $$在公式4.17中具有的形式：

​		
$$
\textbf{X}=\textbf{T}(\textbf{t)}\textbf{R}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
r_{00} & r_{01} & r_{02} & t_{x}\\
r_{10} & r_{11} & r_{12} & t_{y} \\
r_{20} & r_{21} & r_{22} & t_{z} \\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.17)
\end{gather*}
$$
​		$$\mathbf{X} $$的逆计算为$$\mathbf{X}^{-1}=(\mathbf{T}(\mathbf{t})\mathbf{R})^{-1}=\mathbf{R}^{-1}\mathbf{T}(\mathbf{t})^{-1}=\mathbf{R}^T\mathbf{T}(-\mathbf{t})$$。因此，为了计算逆矩阵，对矩阵$$\mathbf{R}$$的左上3×3矩阵进行转置，并且矩阵$$\mathbf{T}$$的平移值$$\mathbf{t}$$改变符号。将这两个新矩阵以相反的顺序相乘以获得逆矩阵。计算$$\textbf{X}$$的逆的另一种方法是考虑$$\mathbf{R}$$（使$$\mathbf{R}$$出现为3×3矩阵）和$$\mathbf{X}$$的符号如下（符号在第6页的公式1.2中描述）：

​		
$$
\mathbf{\bar{R}}=(\textbf{r}_{,0}\quad\textbf{r}_{,1}\quad\textbf{r}_{,2})=
\begin{pmatrix}
\begin{matrix}
\textbf{r}^{T}_{0,}\\
\textbf{r}^{T}_{1,}\\
\textbf{r}^{T}_{2,}\\
\end{matrix}
\end{pmatrix},
\\
\textbf{X}=
\begin{pmatrix}
\begin{matrix}
\overset{\Longrightarrow}{\mathbf{\bar{R}}}&\textbf{t}\\
\mathbf{0}^{T}&\textbf{1}\\
\end{matrix}
\end{pmatrix}.
\qquad \qquad(4.18)
$$
​		其中$$r_{，0}$$表示旋转矩阵的第一列（即逗号表示从0到2的任何值，同时第二个下标为0），而$$r_0^T$$是该列矩阵的第一行。注意，$$\text{0}$$是内部为零的3×1列向量。经过一些计算得出逆运算的表达式如公式4.19中所示：

​		
$$
\textbf{X}^{-1}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\textbf{r}_{0,} & \textbf{r}_{1,} & \textbf{r}_{2,} & -\mathbf{\bar{R}}^{T}t\\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.19)
\end{gather*}
$$
​		![image-20191119224954611](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191119224954611.png)

​		<font size=2>图4.5。涉及计算转换的几何形状，该转换将相机定位在c处，矢量为u'向上，以查看点l。为此，我们需要计算r，u和v。</font>

​		示例：调整相机的方向。图形中的常见任务是调整相机的方向，使其对准特定位置。在这里，我们将介绍gluLookAt（）（来自OpenGL Utility Library，简称GLU）的作用。即使现在很少使用此函数调用，该任务仍然很常见。假设摄像机位于$$\textbf c$$处，我们希望摄像机看着目标$$\textbf l$$，并且给定的摄像机向上的方向为$$\mathbf{u}'$$，如图4.5所示。我们要计算一个由三个向量$$\{\textbf{r,u,v}\}$$组成的基底。我们从计算视点向量$$\mathbf{v}=(\mathbf{c}-\mathbf{l})/||\mathbf{c}-\mathbf{l}||$$开始，即从目标到摄像机位置的归一化向量。然后向右看的向量可以计算为$$\mathbf{r}=-(\mathbf{v}-\mathbf{u}')/||\mathbf{v}-\mathbf{u}'||$$。通常不能保证$$\mathbf{u}'$$向量指向正上方，因此最终的向上向量是另一个叉积，$$\mathbf{u}=\mathbf{v}\times\mathbf{r}$$，由于$$\mathbf{v}$$和$$\mathbf{r}$$都通过构造进行了归一化和相互垂直处理，因此可以保证对其进行归一化。在我们将构建的相机变换矩阵$$\mathbf{M}$$中，其思想是首先转换所有内容，使相机位置位于原点（0，0，0），然后更改基底，使$$\mathbf{r}$$与（1 ，0，0），$$\mathbf{u}$$与（0、1、0）和$$\mathbf{v}$$与（0、0、-1）对齐。这是通过

​		
$$
\begin{gather*}
\textbf{M}=
\underbrace {
\begin{pmatrix}
\begin{matrix}
r_{x} & r_{y} & r_{z} & 0\\
u_{x} & u_{y} & u_{z} & 0 \\
-v_{x} & -v_{y} & -v_{z} & 0 \\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}}_{基底变换}
\underbrace {
\begin{pmatrix}
\begin{matrix}
1 & 0 & 0 & -t_{x}\\
0 & 1 & 0 & -t_{y} \\
0 & 0 & 1 & -t_{z} \\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}}_{平移变换}=
\begin{pmatrix}
\begin{matrix}
r_{x} & r_{y} & r_{z} & -\mathbf{t\cdot r} \\
u_{x} & u_{y} & u_{z} & -\mathbf{t\cdot u} \\
-v_{x} & -v_{y} & -v_{z} & \mathbf{t\cdot v} \\
0 & 0 & 0 & 1
\end{matrix}
\end{pmatrix}
\end{gather*}
\qquad\qquad(4.20)
$$
​		注意，当将转换矩阵与基本矩阵的变化连接在一起时，转换$$\mathbf{-t}$$在右边，因为应该首先应用它。记住将$$\mathbf{r}$$，$$\mathbf{u}$$和$$\mathbf{v}$$的分量放在哪里的一种方法如下。我们希望$$\mathbf{r}$$变成（1，0，0），所以当将基础矩阵的变化乘以（1，0，0）时，我们可以看到矩阵的第一行必须是$$\mathbf{r}$$的元素，因为$$\mathbf{r}\cdot\mathbf{r}=1$$。此外，第二行和第三行必须由与$$\mathbf{r}$$垂直的向量组成，即$$\mathbf{r}\cdot\mathbf{x}=0$$。应用相同的思维对$$\mathbf{u}$$和$$\mathbf{v}$$，我们可以得出基底变换矩阵$$\mathbf{M}$$。

​		

#### 4.1.7法线变换

​		单个矩阵可一致地用于变换点，线，三角形和其他几何形状。相同的矩阵还可以在这些线或在三角形的曲面上变换其切线向量。但是，此矩阵始终不能用于变换一个重要的几何属性，即表面法线（和顶点光照法线）。图4.6显示了如果使用相同的矩阵会发生什么。

![image-20191119225232300](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191119225232300.png)

​		<font size=2>图4.6。左侧是原始几何图形，三角形以及从侧面显示的法线。中间的插图显示了如果模型沿x轴缩放0.5且法线使用相同的矩阵会发生什么。右图显示了法线的正确变换。</font>

​		正确的方法不是乘以矩阵本身，而是使用矩阵的伴随矩阵计算其逆矩阵的转置矩阵[227]。伴随矩阵的计算在我们的在线线性代数附录中进行了描述。伴随矩阵始终保证存在。不能保证经过变换后单位长度依旧具有单位长度，因此通常需要将其归一化。

​		变换法线的传统方法是计算逆矩阵的转置[1794]。此方法通常有效。但是，完全逆矩阵不是必需的，并且有时无法创建。逆矩阵是原始矩阵的行列式除以伴随矩阵。如果该行列式为零，则矩阵是奇异的，并且不存在逆矩阵。

​		即使只计算一个完整的4×4矩阵的伴随矩阵，也可能很昂贵，并且通常没有必要。由于法线是向量，因此平移不会对其产生影响。此外，大多数模型转换都是仿射的。它们不会更改传入的齐次坐标的w分量，即，它们不会执行投影。在这些（常见）情况下，法线变换所需的全部计算是计算左上3×3分量的伴随矩阵。

​		甚至通常不需要计算伴随矩阵。假设我们知道变换矩阵完全由平移，旋转和均匀缩放操作（无拉伸或压缩）的级联组成。平移不影响法线。统一的缩放因子仅改变法线的长度。剩下的就是一系列旋转，总是产生某种形式的旋转，仅此而已。逆矩阵的转置可用于变换法线。事实上旋转矩阵的转置矩阵就是它的逆矩阵。代替以获得正态变换，两个转置（或两个逆）给出原始旋转矩阵。综上所述，原始变换本身这些情况下也可以在直接用于变换法线。

​		最后，并不总是需要重新归一化生成的法线。如果仅平移和旋转连接在一起，则法线在通过矩阵进行变换时不会更改长度，因此不需要重新归一化。如果还连接了统一的缩放比例，则可以使用整体缩放比例因子（如果已知或提取，请参见第4.2.3节）直接对生成的法线进行归一化。例如，如果我们知道应用了一系列缩放，使对象变大了5.2倍，则通过此矩阵转换的法线直接通过将它们除以5.2来重新归一化。另外，要创建一个将产生归一化结果的法线变换矩阵，该比例因子需要除一次原始矩阵的左上3×3部分。

​		请注意，从三角形导出的表面法线（例如，使用三角形边的叉积）经过法线变换后不是一个问题。切向量本质上与法线不同，并且总是可以使用原始矩阵直接转换。

#### 4.1.8逆计算

​		在许多情况下都需要逆计算，例如在坐标系之间来回切换时。根据变换的有关信息，可以使用以下三种方法之一计算逆矩阵的：

  * 如果矩阵是单个变换或是具有给定参数的简单变换序列，则可以通过“反转参数”和矩阵顺序轻松地计算矩阵。例如，如果$$\mathbf{M}＝\mathbf{T}(\mathbf{t})\mathbf{R}(\phi)$$，则$$\mathbf{M}^{-1}＝ \mathbf{R}(-\phi)\mathbf{T}(-\mathbf{t})$$。这很简单，并且保留了转换的准确性，这在渲染巨大世界时很重要[1381]。

  * 如果已知矩阵是正交的，则$$\mathbf{M}^{-1}=\mathbf{M}^{T}$$，即矩阵的转置为逆矩阵。任何顺序的旋转都是旋转，因此是旋转矩阵是正交的。

  * 如果一无所知，则可以使用伴随矩阵方法，克莱默法则，LU分解或高斯消去法来计算逆矩阵。通常最好使用克莱默法则和伴随矩阵方法，因为它们的分支操作较少；在现代体系结构上最好避免使用“如果”测试。请参阅第4.1.7节，了解如何使用伴随矩阵得出逆矩阵进而变换法线。		

​		优化时可以考虑逆计算的目的。例如，如果将逆矩阵用于向量变换，则通常只需要对矩阵的左上3×3部分取反（请参见上一节）。

### 4.2特殊矩阵变换和运算

​		在本节中，将介绍和导出对实时图形必不可少的几种矩阵变换和运算。首先，我们介绍欧拉变换（及其参数提取），这是描述方向的直观方法。然后，我们谈到利用单个矩阵变换一组基底。最终，得出一种绕任意轴旋转实体的方法。

#### 4.2.1欧拉变换

​		这种变换是构造矩阵以将自己（即摄像机）或任何其他的实体定向到某个方向的一种直观方法。它的名字来自伟大的瑞士数学家莱昂哈德·欧拉（Leonhard Euler，1707–1783年）。

​		首先，必须建立某种默认的视图方向。如图4.7所示，它通常沿负z轴放置，头部沿y轴放置。欧拉变换是三个矩阵的乘积，即图中所示的旋转。更正式地说，表示为E的变换由公式4.21给出：

​		
$$
\mathbf{E}(h,p,r)=\mathbf{R}_{z}(r)\mathbf{R}_{x}(p)\mathbf{R}_{y}(h)
\qquad\qquad(4.21)
$$
​		矩阵的顺序可以有24种不同的方式选择[1636]；这可以通过选择矩阵的顺序来实现。我们介绍这种顺序是因为它是常用的。由于$$\mathbf{E}$$是旋转矩阵的级联，因此显然它也是正交的。因此它的逆矩阵可以表示为$$\mathbf{E}^{-1}=\mathbf{E}^{T}=(\mathbf{R}_z\mathbf{R}_x\mathbf{R}_y)^T=\mathbf{R}_y^T\mathbf{R}_x^T\mathbf{R}_z^T$$，所以直接使用$$\mathbf{E} $$的转置矩阵会更容易。

​		欧拉角h，p和r表示按head，pitch和roll的顺序旋转以及绕其各自的轴旋转多少。有时，所有角度都称为“rolls”，例如，我们的“head”为“ y-roll”，我们的“pitch”为“ x-roll”。此外，“head”有时也称为“yaw(偏航)”，例如如在飞行模拟中。

​		这种变换很直观，因此很容易用外行的语言进行讨论。例如，改变head角度会使观察者摇头“不”，改变pitch会使他们点头，而roll则使他们的头向侧面倾斜。而不是谈论围绕x，y和z轴的旋转，我们谈论的是改变head，pitch和roll。请注意，此变换不仅可以定向摄影机，还可以定向任何对象或实体。可以使用世界空间的全局轴或相对于局部参考系执行这些变换。

​		重要的是要注意，一些欧拉角的表示将z轴作为初始向上的方向。这纯粹是一种符号上的差异，尽管可能会造成混淆。在计算机图形学中，在如何看待世界以及如何形成内容方面存在分歧：y向上或z向上。大多数制造工艺（包括3D打印）都认为z方向在世界范围内是向上的。航空和海上交通工具认为-z上升。建筑和GIS通常使用z-up，因为建筑平面图或地图是二维的x和y。与媒体相关的建模系统通常将y方向视为世界坐标上的方向，以匹配我们始终在计算机图形学中描述相机屏幕向上的方向。这两个世界向量选择之间的差异仅相差90°旋转（并且可能是反射），但不知道假定哪个会导致问题。在本书中，除非另有说明，否则我们使用y向上的世界方向。

![image-20191124200627128](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124200627128.png)

​		<font size=2>图4.7。欧拉变换及其与更改头，俯仰和横滚角的方式之间的关系。显示默认视图方向，沿负z轴看，向上方向沿y轴看。</font>

​		我们还想指出，相机在其视图中的向上方向与世界空间的向上方向没有特别关系。转动头，视野就会倾斜，其视图的向上方向与世界空间的向上方向不同。再举一个例子，假设世界使用y-up，而我们的相机则直视下方的地形，鸟瞰视野。此方向表示相机已向前pitch90°，因此其在世界空间中的向上方向为（0,0，−1）。在这种方向上，相机没有y分量，而是认为-z在世界空间中向上，但根据定义，“ y在上方”在视图空间中仍然适用。

​		欧拉角虽然对较小的角度变化或观察者的方向有用，但有一些严重的限制。很难同时使用两组欧拉角。例如，在一组和另一组之间进行插值并不是简单的对每个角度进行插值。实际上，两组不同的欧拉角可以给出相同的方向，因此任何插值都不应旋转对象。这些是本章稍后讨论的使用其他表示方向的形式（例如四元数）的一些原因。使用欧拉角，您还将遇到称为万向锁的东西，这将在4.2.2节中介绍。

#### 4.2.2从欧拉变换中提取参数

​		在某些情况下，从一个正交矩阵中提取欧拉角所需的参数h，p和r很有用。此过程如公式4.22所示：

​		
$$
\textbf{E}(h,p,r)=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
e_{00} & e_{01} & e_{02} \\
e_{10} & e_{11} & e_{12} \\
e_{20} & e_{21} & e_{22} \\
\end{matrix}
\end{pmatrix}=
\mathbf{R}_{z}(r)\mathbf{R}_{x}(p)(h).
\qquad\qquad(4.22)
\end{gather*}
$$
​		在这里，我们放弃了4×4矩阵而使用3×3矩阵，因为后者提供了旋转矩阵的所有必要信息。也就是说，等效的4×4矩阵的其余部分是始终在其右下位置包含一个零或一个1。

​		将方程式4.22中的三个旋转矩阵连接起来

​		
$$
\textbf{E}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\cos r\cos h-\sin r\sin p\sin h & -\sin r\cos p & \cos r\sin h+\sin r\sin p\cos h \\
\sin r\cos h+\cos r\sin p\sin h & \cos r\cos p & \sin r\sin h-\cos r\sin p\cos h  \\
-\cos p\sin h&  \sin  p & \cos  p\cos h \\
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.23)
\end{gather*}
$$
​		由此可见，pitch参数由sin p = e21给出。同样，将e01除以e11，并类似地将e20除以e22，会产生以下用于提取head和roll参数的方程式：

​		
$$
\frac{e_{01}}{e_{11}}=
\frac{-\sin r}{\cos r}=
-\tan r \quad and \quad
\frac{e_{20}}{e_{22}}=
\frac{-\sin h}{\cos h}=
-\tan h
\qquad\qquad(4.24)
$$
​		因此，如方程式4.25所示，使用函数atan2（y，x）（请参阅第1章第8页）从矩阵E提取欧拉参数h（head），p（pitch）和r（roll）：

​		
$$
\begin{align}
h=&\textbf{atan2}(-e_{20},e_{22}),\\
p=&\textbf{arcsin}(e_{21}),\qquad\qquad(4.25)\\
r=&\textbf{atan2}(-e_{01},e_{11}).
\end{align}
$$
​		但是，有一种特殊情况需要处理。如果cos p = 0，则具有万向锁（第4.2.2节），旋转角度r和h将绕同一轴旋转（尽管可能沿不同的方向，这取决于p旋转角度是-π/ 2还是π/ 2），因此仅需要导出一个角度。如果我们任意设置h = 0 [1769]，我们得到

​		
$$
\textbf{E}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\cos r & \sin r\cos p & \sin r\sin p \\
\sin p & \cos r\cos p & -\cos r\sin p \\
0 & \sin p & \cos p \\
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.26)
\end{gather*}
$$
​		由于p不影响第一列中的值，因此当cosp = 0时，我们可以使用sin r / cos r = tan r = e10 / e00，得出r = atan2（e10，e00）。

​		请注意，根据arcsin的定义，-π/ 2≤p≤π/ 2，这意味着，如果使用该间隔之外的p值创建E，则无法提取原始参数。 h，p和r不是唯一的，这意味着可以使用一组以上的欧拉参数来产生相同的变换。有关欧拉角转换的更多信息，请参见Shoemake的1994年文章[1636]。上面概述的简单方法可能会导致数值不稳定的问题，这可以在速度方面会付出一定的代价来避免[1362]。

​		当您使用欧拉变换时，可能会发生万向锁[499，1633]。这发生在旋转时，并失去了一个自由度。例如，假设转换顺序为x / y / z。考虑仅绕y轴旋转π/ 2，即第二次旋转。这样做会旋转局部z轴以使其与原始x轴对齐，因此围绕z的最终旋转是多余的。

​		在数学上，我们已经在公式4.26中看到了万向锁，其中我们假设cos p = 0，即p =±π/ 2 +2πk，其中k是整数。因为这样的p值，我们损失了一个自由度，因为矩阵仅取决于一个角度r + h或r-h（但不能同时取决于两个角度）。

​		虽然在建模系统中通常以x / y / z顺序表示欧拉角，但绕每个局部轴旋转时，其他顺序也是可行的。例如，动画中使用z / x / y，动画和物理学中都使用z / x / z。这些都是指定三个独立旋转的有效方法。最后的z / x / z顺序在某些应用中可能更好，当因为只有当绕x旋转π弧度（半旋转）时才会出现万向锁。没有完美的顺序可以避免万向锁。尽管如此，但通常还是使用欧拉角，因为动画师更喜欢曲线编辑器来指定角度如何随时间变化[499]。

​		示例：约束变换。想象您拿着一把（虚拟的）扳手紧紧地抓住螺栓。为了将螺栓固定到位，您必须绕x轴旋转扳手。现在假设您的输入设备（鼠标，VR手套，空间球等）为扳手的运动提供了旋转矩阵，即旋转。问题在于，将这种变换应用于扳手可能是错误的，扳手应该仅绕x轴旋转。要将输入变换（称为$$\mathbf{p}$$）限制为绕x轴旋转，只需使用本节中介绍的方法提取欧拉角，h，p和r，然后创建一个新矩阵$$\mathbf{R}_x(p)$$ 。然后，这是一种受欢迎的变换，它将使扳手绕x轴旋转（如果$$\mathbf{p}$$现在包含这样的运动）。

#### 4.2.3矩阵分解

​		到目前为止，我们一直在假设我们知道所使用的转换矩阵的起源和历史的情况下进行工作。通常情况并非如此。例如，无非是将级联矩阵与某个变换后的对象相关联。从级联矩阵中取回各种变换的任务称为矩阵分解。

​		取回一组变换的原因很多。用途包括：

* 仅提取对象的缩放因子。
* 查找特定系统所需的转换。 （例如，某些系统可能不允许使用任意4×4矩阵）
* 确定模型是否仅经历了刚体变换。
* 在动画的关键帧之间进行插值，其中对象仅可用矩阵
* 从旋转矩阵上移除切变。

​		我们已经提出了两种分解方法，分别是为刚体变换导出平移和旋转矩阵（第4.1.6节），以及从正交矩阵导出欧拉角（第4.2.2节）。

​		如我们所见，取回平移矩阵很简单，因为我们只需要4×4矩阵的最后一列中的元素。我们还可以通过检查矩阵的行列式是否为负来确定是否发生了反射。要分离出旋转，缩放和剪切，需要花费更多的精力。

​		幸运的是，有几篇关于该主题的文章以及在线提供的代码。托马斯[1769]和戈德曼[552，553]分别针对各种类型的转换提出了一些不同的方法。 Shoemake [1635]改进了其仿射矩阵的技术，因为他的算法与参考系无关，并尝试分解矩阵以获得刚体变换。

#### 4.2.4绕任意轴旋转

​		有时使实体绕任意轴旋转某个角度会很方便。假设旋转轴$$\mathbf{r}$$已归一化，并且创建一个围绕$$\mathbf{r}$$旋转$$\alpha$$弧度的变换。

​		为此，我们首先变换到一个空间，在这个空间中我们要围绕其旋转的轴是x轴。这通过一个称为$$\mathbf{M}$$的旋转矩阵完成。然后执行实际旋转，然后使用$$\mathbf{M}^{-1} $$变换回去[314]。此过程如图4.8所示。

![image-20191124201220274](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124201220274.png)

​		<font size=2>图4.8。 通过找到由r，s和t形成的正交法线，可以实现围绕任意轴r的旋转。 然后，我们将此基准与标准基准对齐，以使r与x轴对齐。 在那里绕着x轴旋转，最后我们变回原样.</font>

​		为了计算$$\mathbf{M}$$，我们需要找到两个相互正交的轴同时分别与$$\mathbf{r}$$正交。我们着重于找到第二个旋转轴$$\mathbf{s}$$，了解第三个旋转轴$$\mathbf{t}$$将是第一根轴和第二根轴的叉积，$$\mathbf{t}=\mathbf{r}\times\mathbf{s}$$。一种稳定的数学方法是找到$$\mathbf{r}$$的最小成分（绝对值），并将其设置为0。交换剩余的两个成分，然后取反它们中的第一个（实际上，两个非零成分都可以被否定）。在数学上，这表示为[784]：

​		
$$ {\}
\begin{align}
\bar s&=
\begin{cases}
(0,-r_{z},r_{y}),\quad if\quad|r_{x}|\le|r_{y}|\quad and \quad|r_{x}|\le|r_{z}|,\\
(-r_{z},0,r_{x}),\quad if\quad|r_{y}|\le|r_{x}|\quad and \quad|r_{y}|\le|r_{z}|,\\
(-r_{y},r_x,0),\quad if\quad|r_{z}|\le|r_{x}|\quad and \quad|r_{z}|\le|r_{y}|.
\qquad\qquad(4.27)\\
\end{cases}
\\s&=\bar s/||\bar s||,
\\\mathbf{t}&=\mathbf{r}\times \mathbf{s}.
\end{align}
$$
​		这保证$$\mathbf{\bar s}$$与$$\mathbf{r}$$正交（垂直），并且$$(\mathbf{r,s,t})$$是正交的基底。 Frisvad [496]提出了一种在代码中没有任何分支的方法，该方法速度更快，但准确性较低。马克斯[1147]和达夫（Duff）等 [388]提高了Frisvad方法的准确性。无论采用哪种技术，都会使用这三个向量来创建旋转矩阵：

​		
$$
\textbf{M}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\mathbf{r}^T \\
\mathbf{s}^T \\
\mathbf{t}^T\\
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.28)
\end{gather*}
$$
​		该矩阵将向量$$\mathbf{r}$$转换为x轴，将$$\mathbf{s}$$转换为y轴，将$$\mathbf{t}$$转换为z轴。因此，然后围绕归一化的向量$$\mathbf{r}$$旋转α弧度的最终变换为

​		
$$
\mathbf{X}=\mathbf{M}^T\mathbf{R}_x(\alpha)\mathbf{M}
\qquad\qquad(4.29)
$$
​		换句话说，这意味着首先我们进行变换，使$$\mathbf{r}$$为x轴（使用$$\mathbf{M}$$），然后围绕该x轴旋转α弧度（使用$$\mathbf{R}_x(\alpha)$$）），然后使用$$\mathbf{M}$$的逆矩阵进行变换，在这里为$$\mathbf{M}^T$$，因为$$\mathbf{M}$$是正交矩阵。

​		高德曼[550]提出了另一种绕任意归一化轴$$\mathbf{r}$$旋转$$\phi$$弧度的方法。在这里，我们只介绍他的变换：

​		
$$
\textbf{R}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\cos\phi+(1+\cos\phi)r_x^2
& (1-\cos\phi)r_xr_y-r_z\sin\phi
&(1-\cos\phi)r_xr_z+r_y\sin\phi
\\
 (1-\cos\phi)r_xr_y+r_z\sin\phi
 & \cos\phi+(1-\cos\phi)r_y^2
 & (1-\cos\phi)r_yr_z-r_x\sin\phi
 \\
 (1-\cos\phi)r_xr_z+r_y\sin\phi
 &(1-\cos\phi)r_yr_z+r_x\sin\phi
 & \cos\phi+(1-\cos\phi)r_z^2
\\
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.30)
\end{gather*}
$$
​		在第4.3.2节中，我们提出了另一种解决此问题的方法使用四元数。在该部分中还有针对相关问题（例如，从一个向量到另一个向量的旋转）的更有效算法。

### 4.3四元数

​		尽管四元数是威廉·罗恩·汉密尔顿爵士于1843年发明的，它是复数的扩展，但直到1985年，Shoemake [1633]才将它们引入计算机图形学领域。四元数用于表示旋转和方向。它们在几个方面都优于欧拉角和矩阵。任何三维定向都可以表示为围绕特定轴的单个旋转。考虑到该轴和角度表示，四元数的平移或从四元数的平移都是简单的，而在这两者对于欧拉角转换都具有挑战性。四元数可用于稳定和恒定的方向插值，而欧拉角无法很好地完成这些操作。

​	复数具有实部和虚部。每个均由两个实数表示，第二个实数乘以$$\sqrt{-1}$$。同样，四元数有四个部分。前三个值与旋转轴密切相关，旋转角影响所有四个部分（有关更多信息，请参见第4.3.2节）。每个四元数由四个实数表示，每个实数与一个不同的部分相关联。由于四元数具有四个分量，因此我们选择将它们表示为向量，但是为了区分它们，我们在它们上加了一个帽子：$$\hat{\textbf{q}}$$。我们从四元数的一些数学背景开始，然后将其用于构建各种有用的转换。

#### 4.3.1数学背景

​		我们从四元数的定义开始。

​		定义。四元数$$\hat{q}$$可以用以下所有等效的方式定义。

​		
$$
\begin{align}
\hat{\mathbf{q}}&=(\mathbf{q}_v,q_w)=iq_x+jq_y+kq_z+q_w=\mathbf{q}_v+q_w,\\
\mathbf{q}_v&=iq_x+jq_y+kq_z=(q_x,q_y,q_y),\qquad\qquad\qquad\qquad(4.31)
\\
i^2&=j^2=k^2=-1,jk=-kj=i,ki=-ik=j,ij=-ji=k
\end{align}
$$
​		变量$$q_w$$被称为四元数$$\hat{\textbf{q}}$$的实部。虚部为$$\mathbf{\mathbf{q}_v}$$，i，j和k称为虚部。

​		对于虚部$$\mathbf{\mathbf{q}_v}$$，我们可以使用所有向量运算，例如加法，缩放，点积，叉积等等。使用四元数的定义，可以得出两个四元数$$\hat{\textbf{q}}$$和$$\hat{\textbf{r}}$$之间的乘法运算，如下所示。注意，虚部的乘法是不可交换的。

​		
$$
\begin{align}
乘法:\mathbf{\hat{q}\hat{r}}&=(iq_x+jq_y+kq_z+q_w)(ir_x+jr_y+kr_z+r_w)\\
&=i(q_yr_z-q_zr_y)+r_wq_x+q_wr_x)
\\&+j(q_zr_x-q_xr_z+r_wq_y+q_wr_y)\qquad\qquad(4.32)
\\&+k(q_xr_y-q_yr_x+r_wq_z+q_wr_z)
\\&+q_wr_w-q_xr_x-q_yr_y-q_zr_z
\\=&(\mathbf{q}_v\times\mathbf{r}_v+r_w\mathbf{q}_v+q_w\mathbf{r}_v,
q_wr_w-\mathbf{q}_v\cdot\mathbf{r}_v).
\end{align}
$$
​		从该方程式可以看出，我们使用叉积和点积来计算两个四元数的乘法。

​		除了四元数的定义外，还需要加法，共轭，归一化和单位四元数的定义：

​		
$$
\begin{align}
&加法:\hat{\mathbf{q}}+\hat{\mathbf{r}}=
(\mathbf{q}_v,q_w)+(\mathbf{r}_v,r_w)=
(\mathbf{q}_v+\mathbf{r}_v,q_w+r_w).\\
&共轭：\mathbf{\hat{q}}^*=(\mathbf{q}_v,q_w)^*=(-\mathbf{q}_v,q_w).\\
&模：n(\mathbf{\hat{q}})=\sqrt{\hat{\mathbf{q}}^*\hat{\mathbf{q}}}
=\sqrt{\hat{\mathbf{q}}\hat{\mathbf{q}}^*}
=\sqrt{\mathbf{q}_v\cdot\mathbf{q}_v+q_w^2}\qquad\qquad(4.33)\\
&\qquad\qquad\quad=\sqrt{q_x^2+q_y^2+q_z^2+q_w^2}.\\
&单位四元数:\mathbf{\hat{i}}=(\textbf 0,1)
\end{align}
$$
​		当简化$$n(\mathbf{\hat{q}})=\sqrt{\hat{\mathbf{q}}^*\hat{\mathbf{q}}}$$时（如上所示），虚部将抵消，仅保留实部。规范有时表示为$$||\hat{\textbf{q}}||=n(\mathbf{\hat{q}})$$[1105]。通过上面的结果，可以得出由$$\hat{\textbf{q}}^{-1}$$表示的乘法逆运算。方程$$\hat{\mathbf{q}}^{-1}\hat{\mathbf{q}}=\hat{\mathbf{q}}\hat{\mathbf{q}}^{-1}=1$$对于逆计算必须成立（对于乘法逆运算来说是常见的）。我们从规范的定义中得出一个公式：

​		
$$
n(\mathbf{\hat{q}})^2=
\mathbf{\hat{q}\hat{q}^*}
\Longleftrightarrow
\frac{\mathbf{\hat{q}\hat{q}^*}}{n(\mathbf{\hat{q}})^2}=1
\qquad\qquad(4.34)
$$
​		这给出了乘法逆运算，如下所示：

​		
$$
逆运算：
\mathbf{\hat{q}}^{-1}=
\frac{1}{n(\mathbf{\hat{q}})^2}\mathbf{\hat{q}}^*.
\qquad\qquad(4.35)
$$
​		逆计算公式使用标量乘法，它是从公式4.31中的乘法得出的：$$s\hat{\textbf{q}}=(\textbf{0},s)(\textbf{q}_v,q_w)=(s\textbf{q}_v,sq_w)$$和$$\hat{\textbf{q}}s=(\textbf{q}_v,q_w)(\text{0},s)=(s\textbf{q}_v,sq_w)$$，这意味着标量乘法是可交换的：$$s\hat{\textbf{q}}=\hat{\textbf{q}}s=(s\hat{\textbf{q}}_v,sq_w)$$。

​		以下规则很容易从定义中得出：

$$
\begin{align}
共轭规则：\qquad
(\hat{\mathbf{q}})^*=&\hat{\mathbf{q}},\\
(\hat{\mathbf{q}}+\hat{\mathbf{r}})^*=&\hat{\mathbf{q}}^*+\hat{\mathbf{r}}^*,
\qquad\qquad(4.36)\\
(\hat{\mathbf{q}}\hat{\mathbf{r}})^*=&\hat{\mathbf{r}}^*\hat{\mathbf{q}}^*.
\end{align}
$$
$$
\begin{align}
模规则：\qquad
n(\hat{\mathbf{q}}^*)=&n(\hat{\mathbf{q}}),\\
n(\hat{\mathbf{q}}\hat{\mathbf{r}})=&n(\hat{\mathbf{q}})n(\hat{\mathbf{r}}).
\qquad\qquad(4.37)
\end{align}
$$

​		乘法定律：
$$
\begin{align}
线性:\qquad
\hat{\mathbf{p}}(s\hat{\mathbf{q}}+t\hat{\mathbf{r}})=&
s\hat{\mathbf{p}}\hat{\mathbf{q}}+t\hat{\mathbf{p}}\hat{\mathbf{r}},
\\
(s\hat{\mathbf{p}}+t\hat{\mathbf{q}})\hat{\mathbf{r}}=&
s\hat{\mathbf{q}}\hat{\mathbf{r}}+t\hat{\mathbf{q}}\hat{\mathbf{r}}.
\qquad\qquad(4.38)
\end{align}
$$

​		
$$
结合律:\qquad
\hat{\mathbf{p}}(\hat{\mathbf{q}}\hat{\mathbf{r}})=
(\hat{\mathbf{p}}\hat{\mathbf{q}})\hat{\mathbf{r}}
$$

​		使得$$n(\hat{\textbf{q}})=1$$的单位四元数$$\hat{\textbf{q}}=(\textbf{q}_v,q_w)$$。由此可以得出$$\hat{\textbf{q}} $$可写为
$$
\hat{\mathbf{q}}=(\sin\phi\mathbf{u}_q,\cos\phi)=
\sin\phi\mathbf{u}_q+\cos\phi,
\qquad\qquad(4.39)
$$

​		对于某些三维向量$$\textbf{u}_q$$，使得$$||\textbf{u}_q||=1$$，因为
$$
\begin{align}
n(\hat{\mathbf{q}})&=n(\sin\phi\mathbf{u}_q,\cos\phi)=
\sqrt{\sin^2\phi(\mathbf{u}_q\cdot\mathbf{u}_q)+\cos^2\phi}\\
&=\sqrt{\sin^2\phi+\cos^2\phi}=1
\qquad\qquad(4.40)
\end{align}
$$

​		当且仅当$$\textbf{u}_q\cdot\textbf{u}_q=1=||\textbf{u}_q||^2$$。 正如在下一节中将看到的，单位四元数非常适合以最有效的方式创建旋转和方向。 但在那之前，需要介绍一些关于单元四元数额外的操作。

​		对于复数，可以将二维单位向量写为$$\cos\phi+i\sin\phi=e^{i\phi}$$。 四元数的等效形式是
$$
\hat{\mathbf{q}}=\sin\phi\mathbf{u}_q+
\cos\phi=e^{\phi\mathbf{u}_q}.
\qquad\qquad(4.41)
$$

​		单位四元数的对数和幂函数来自公式4.41：
$$
\begin{align}
对数函数：
&\log(\hat{\mathbf{q}})=\log(e^{\phi\mathbf{u}_q})=\phi\mathbf{u}_q,
\\
幂函数：
&\hat{\mathbf{q}}^t=(\sin\phi\mathbf{u}_q+\cos\phi)^t=
e^{\phi t\mathbf{u}_q}=\sin(\phi t)\mathbf{u}_q+\cos(\phi t).
\qquad\qquad(4.42)
\end{align}
$$

​			![image-20191124201313125](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124201313125.png)

​	        <font size=2>图4.9。 由单位四元数$\hat{\textbf{q}}=(\sin\phi\textbf{u}_q,\cos\phi)$表示的旋转变换的图示。 变换围绕轴$\textbf{u}_q$旋转$2\phi$弧度。</font>

#### 4.3.2 四元数变换

​		现在，我们将研究四元数集的子类，即单位长度的子类，称为单位四元数。 关于单位四元数的最重要事实是，它们可以表示任何三维旋转，并且这种表示极其紧凑和简单。

​		现在，我们将说明使单元四元数对旋转和定向如此有用的原因。 首先，将点或向量$$\textbf{p}=(p_x,p_y,p_z,p_w)^T$$的四个坐标分量放入四元数$$\hat{\textbf{p}}$$的四个分量中，并假设我们有一个单位四元数$$\hat{\textbf{q}}=(\sin\phi\textbf{u}_q,\cos\phi)$$。 可以证明
$$
\hat{\mathbf{q}}
\hat{\mathbf{p}}\hat{\mathbf{q}}^{-1}
\qquad\qquad(4.43)
$$

绕轴$$\textbf{u}_q$$旋转$$\hat{\textbf{p}}$$（并因此旋转点p）一个角度2$$\phi$$。 注意，由于$$\hat{\textbf{q}}$$是单位四元数，因此$$\hat{\textbf{q}}^{-1}=\hat{\textbf{q}}^*$$ 。 见图4.9。

​		$$\hat{\textbf{q}}$$的任何非零实数倍也表示相同的变换，这意味着$$\hat{\textbf{q}}$$和$$-\hat{\textbf{q}}$$表示相同的旋转。 也就是说，取反轴$$\textbf{u}_q$$和实部$$q_w$$，将创建一个四元数，该四元数的旋转与原始四元数的旋转完全相同。 这也意味着从矩阵中提取四元数可以返回$$\hat{\textbf{q}}$$或$$ -\hat{\textbf{q}}$$。

​		给定两个单位四元数$$\hat{\textbf{q}}$$和$$\hat{\textbf{r}}$$，首先将$$\hat{\textbf{q}}$$然后$$\hat{\textbf{r}}$$应用于四元数$$ \hat{\textbf{p}}$$（可以作为点p被插值）的级联公式由4.44给出：
$$
\hat{\mathbf{r}}(\hat{\mathbf{q}}\hat{\mathbf{p}}\hat{\mathbf{q}}^*)\hat{\mathbf{r}}^*=
(\hat{\mathbf{r}}\hat{\mathbf{q}})\hat{\mathbf{p}}
(\hat{\mathbf{r}}\hat{\mathbf{q}})^*=
\hat{\mathbf{c}}\hat{\mathbf{p}}\hat{\mathbf{c}}^*.
\qquad\qquad(4.44)
$$

​		在此，$$\hat{\textbf{c}}=\hat{\textbf{r}}\hat{\textbf{q}}$$ 是表示单元四元数$$\hat{\textbf{q}}$$和$$ \hat{\textbf{r}}$$的级联的单元四元数。

矩阵转换：

​		由于经常需要组合几种不同的变换，并且大多数变换都是矩阵形式，因此需要一种将公式4.43转换为矩阵的方法。 四元数$$\hat{\textbf{q}}$$可以转换成矩阵$$\textbf{M}^q$$，如公式4.45 [1633，1634]所示：
$$
\textbf{M}^q=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1-s(q_y^2+q_z^2)
& s(q_xq_z+q_wq_z)
&s(q_xq_z+q_wq_y)&0
\\
s(q_xq_y+q_wq_z)
 & 1-s(q_x^2+q_z^2)
 & s(q_yq_z-q_wq_x) &0
 \\
 s(q_xq_z-q_wq_y)
 &s(q_yq_z+q_wq_x)
 & 1-s(q_x^2+q_y^2) &0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.45)
\end{gather*}
$$
​		在此，系数$$s=2/(n(\hat{\text{q}}))^2$$。 对于单元四元数，这简化为
$$
\textbf{M}^q=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1-2(q_y^2+q_z^2)
& 2(q_xq_z+q_wq_z)
&2(q_xq_z+q_wq_y)&0
\\
2(q_xq_y+q_wq_z)
 & 1-2(q_x^2+q_z^2)
 & 2(q_yq_z-q_wq_x) &0
 \\
 2(q_xq_z-q_wq_y)
 &2(q_yq_z+q_wq_x)
 & 1-2(q_x^2+q_y^2) &0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.46)
\end{gather*}
$$
一旦构建了四元数，就无需计算三角函数，因此转换处理实际上是有效率的。

​		从正交矩阵$$ \textbf{M}^q$$到单位四元数$$\hat{\textbf{q}}$$的反向转换要复杂得多。 此过程的关键是公式4.46中的矩阵存在以下差异：
$$
\begin{align}
m_{21}^q-m_{12}^q&=4q_wq_x,\\
m_{02}^q-m_{20}^q&=4q_wq_y,\qquad\qquad(4.47) \\
m_{10}^q-m_{01}^q&=4q_wq_z,\\
\end{align}
$$
​		这些等式的含义是，如果$$q_w$$是已知的，则可以计算向量$$\textbf{v}_q$$的值，从而得出$$\hat{\textbf{q}}$$。 $$ \textbf{M}^q$$的trace由下式计算
$$
\begin{align}
tr(\textbf{M}^q)&=
4-2s(q_x^2+q_y^2+q_z^2)=
\left(1-\frac{q_x^2+q_y^2+q_z^2}{q_x^2+q_y^2+q_z^2+q_w^2}\right)\\
&=\frac{4q_w^2}{q_x^2+q_y^2+q_z^2+q_w^2}=\frac{4q_w^2}{(n(\hat{\text{q}}))^2}
\qquad\qquad(4.48)
\end{align}
$$
​		此结果将对单位四元数产生以下转换：
$$
\begin{align}
q_w &= \frac{1}{2}\sqrt{tr(\textbf{M}^q)},\qquad\qquad
q_x=\frac{m_{21}^q-m_{12}^q}{4q_w},\\
q_y &=\frac{m_{02}^q-m_{20}^q}{4q_w},\qquad\qquad
q_z=\frac{m_{10}^q-m_{01}^q}{4q_w}. \qquad\qquad(4.49)\\
\end{align}
$$
​		为了运行时具有数值稳定[1634]，应避免小数除法。 因此，首先设置$$t=q_w^2-q_x^2-q_y^2-q_z^2$$，由此得出：
$$
\begin{align}
m_{00}&=t+2q_x^2,\\
m_{11}&=t+2q_y^2,\\
m_{22}&=t+2q_z^2,\\
u&=m_{00}+m_{11}+m_{22}=t+2q_w^2,\qquad\qquad(4.50)
\end{align}
$$
​		这又意味着$$m_{00},m_{11},m_{22},u$$中的最大值决定了$$q_x,q_y,q_z,q_w$$中的哪个最大。 如果$$q_w$$最大，则使用公式4.49推导四元数。 否则，我们注意到以下情况成立：
$$
\begin{align}
4q_x^2&=+m{00}-m_{11}-m_{22}+m_{33},\\
4q_y^2&=-m{00}+m_{11}-m_{22}+m_{33},\\
4q_z^2&=-m{00}-m_{11}+m_{22}+m_{33},\\
4q_w^2&=tr(\textbf{M}^q).\qquad\qquad(4.51)
\end{align}
$$
​		然后，使用上述方程式的适当公式来计算$$q_x,q_y,q_z$$中的最大值，然后使用公式4.47计算$$\hat{{\textbf{q}}}$$的其余分量。 舒勒[1588]提出了一种无分支但使用四个平方根的变量。

球面线性插值：

​		球面线性插值是在给定两个单位四元数$$\hat{{\textbf{q}}}$$和$$\hat{{\textbf{r}}}$$以及参数$$t\in[0,1]$$的情况下计算插值四元数的运算。 例如，这对于动画对象很有用。 插值相机方向时，它的用处不大，因为插值时相机的“上”矢量可能会倾斜，通常会产生干扰。

​		此运算的代数形式由复合四元数$$\hat{{\textbf{s}}}$$表示，如下所示：
$$
\hat{\textbf{s}}(\hat{\textbf{q}},\hat{\textbf{r}},t)=
(\hat{\textbf{r}}\hat{\textbf{q}}^{-1})^t\hat{\textbf{q}}
\qquad\qquad(4.52)
$$
​		但是，对于软件实现，以下形式更合适：slerp代表球面线性插值：
$$
\hat{\textbf{s}}(\hat{\textbf{q}},\hat{\textbf{r}},t)=
\text{slerp}(\hat{\textbf{q}},\hat{\textbf{r}},t)=
\frac{\sin(\phi(1-t))}{\sin\phi}\hat{\textbf{q}}+
\frac{\sin(\phi t)}{\sin\phi}\hat{\textbf{r}}.
\qquad\qquad(4.53)
$$
​		为了计算该方程式所需的$$\phi$$，可以使用以下公式：$$\cos\phi=q_xr_x+q_yr_y+q_zr_z+q_wr_w$$ [325]。 对于$$ t\in[0,1]$$，slerp函数（用于计算（当且仅当$$\hat{{\textbf{q}}}$$和$$ \hat{{\textbf{r}}}$$不相反）插值四元数），它们共同构成从$$\hat{{\textbf{q}}}(t=0)$$到$$\hat{{\textbf{r}}}(t=1)$$的四维单位球面上的最短弧。 圆弧位于，由$$ \hat{{\textbf{q}}}$$和$$ \hat{{\textbf{r}}}$$得到平面，与原点，与四维单位球面的交点形成的圆上。 如图4.10所示。 计算出的旋转四元数以固定速度绕固定轴旋转。 这样的曲线，具有恒定的速度，因此加速度为零，称为测地曲线(geodesic curve )[229]。 球体上的大圆是通过原点和球体的平面相交而生成的，这种圆的一部分称为大圆弧。

​		slerp函数非常适合在两个方向之间进行插值，并且表现良好（固定轴，恒定速度）。 使用多个欧拉角插值时则不是这种情况。 在实践中，直接计算slerp是涉及调用三角函数的昂贵操作。 Malyshau [1114]讨论了将四元数集成到渲染管线中的问题。 他指出，如果不使用slerp而是简单地在像素着色器中对四元数进行归一化，则90度角的三角形取向误差最大为4度。 光栅化三角形时，此错误率可以接受。 Li [1039，1040]提供了更快的增量方法来计算不牺牲任何准确性的slerps。 Eberly [406]提出了一种仅使用加法和乘法来计算slerp的技术。

​		当方向大于两个时，说$$ \hat{{\textbf{q}}}_0,\hat{{\textbf{q}}}_1,……\hat{{\textbf{q}}}_{n-1}$$可用，我们想从$$\hat{{\textbf{q}}}_0$$到$$\hat{{\textbf{q}}}_1$$再到$$\hat{{\textbf{q}}}_2$$进行插值，依此类推，直到$$\hat{{\textbf{q}}}_{n-1}$$，slerp直接以简单的方式使用。 现在，当我们说$$\hat{{\textbf{q}}}_i$$时，我们将使用$$\hat{{\textbf{q}}}_{i-1}$$和$$ \hat{{\textbf{q}}}_i$$作为slerp的参数。 通过$$\hat{{\textbf{q}}}_i$$之后，我们将使用$$\hat{{\textbf{q}}}_i$$和$$\hat{{\textbf{q}}}_{i+1}$$作为slerp的参数。 这将导致突然的扭动出现在方向插值中，如图4.10所示。 这类似于点被线性插值时发生的情况。 请参阅第720页的图17.3的右上部分。某些读者在阅读了第17章中的样条后，可能希望重新阅读以下段落。

![image-20191124201353335](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124201353335.png)

​		<font size=2>图4.10。 单位四元数表示为单位球面上的点。 函数slerp用于在四元数之间进行插值，并且插值路径是球面上的大圆弧。 请注意，从$\hat{{\textbf{q}}}_1$到$\hat{{\textbf{q}}}_2$进行插值，以及从$\hat{{\textbf{q}}}_1$到$\hat{{\textbf{q}}}_3$到$\hat{{\textbf{q}}}_2$进行插值，即使它们到达相同的方向，但也不一样。</font>

​		一种更好的插值方法是使用某种样条线。 我们在$$ \hat{{\textbf{q}}}_i$$和$$ \hat{{\textbf{q}}}_{i+1}$$之间引入四元数$$\hat{{\textbf{a}}}_i$$和$$\hat{{\textbf{a}}}_{i+1}$$。 可以在四元数$$ \hat{{\textbf{q}}}_i, \hat{{\textbf{q}}}_{i+1},\hat{{\textbf{a}}}_i,\hat{{\textbf{a}}}_{i+1}$$的集合内定义球形三次插值。 令人惊讶的是，这些额外的四元数的计算如下[404] 3所示：
$$
\hat{\textbf{a}}_i=\hat{\textbf{q}}_i\exp
\left[-\frac{\log(\hat{\textbf{q}}_i^{-1}\hat{\textbf{q}}_{i-1})
+\log(\hat{\textbf{q}}_i^{-1}\hat{\textbf{q}}_{i+1})}
{4}
\right]
.\qquad\qquad(4.54)
$$
​		$$ \hat{{\textbf{q}}}_i$$和$$ \hat{{\textbf{a}}}_i$$将用于使用了平滑三次样条的球面插值四元数，如公式4.55所示：
$$
\begin{align}
\text{squad}(\hat{\textbf{q}}_i,\hat{\textbf{q}}_{i+1},\hat{\textbf{a}}_i,\hat{\textbf{a}}_{i+1},t)&=
\\ \text{slerp}(\text{slerp}(\hat{\textbf{q}}_i,\hat{\textbf{q}}_{i+1},t)&,
\text{slerp}(\hat{\textbf{a}}_i,\hat{\textbf{a}}_{i+1},t),2t(1-t)).
\end{align}
\qquad\qquad(4.55)
$$
​		如上所示，squad 函数是通过使用slerp的重复球面插值法构建的（有关点的重复线性插值，请参见第17.1.1节）。 插值将通过初始方向$$\hat{\textbf{q}}_i,i\in[0,……,n-1]$$，但不是通过$$\hat{{\textbf{a}}}_i$$，这些用来表示初始位置处的切线方向。

从一个向量旋转到另一个向量：

​		常见的操作是通过最短路径从一个方向$\textbf{s}$转换到另一个方向$\textbf{t}$。 四元数数学极大地简化了此过程，并显示了四元数与该表示形式的密切关系。首先，对$\textbf{s}$和$\textbf{t}$进行归一化。 然后计算单位旋转轴$\textbf{u}$，其计算公式为$$\textbf{u}=(\textbf{s}\times\textbf{t})/||\textbf{s}\times\textbf{t}||$$。 接下来，$$e=\textbf{s}\cdot\textbf{t}=\cos(2\phi)$$和$$||\textbf{s}\times\textbf{t}||=\sin(2\phi)$$，其中2$\phi$是$\textbf{s}$和$\textbf{t}$之间的角度。 那么表示从$\textbf{s}$到$\textbf{t}$旋转的四元数为$$\hat{\textbf{q}}=(\sin\phi\textbf{u},\cos\phi)$$。 实际上，使用半角关系和三角恒等式化简得到$$\hat{\textbf{q}}=(\frac{\sin\phi}{\sin2\phi}(\textbf{s}\times\textbf{t}),\cos\phi)$$[1197]
$$
\hat{\textbf{q}}=(\textbf{q}_v,q_w)=
\left(
\frac{1}{\sqrt{2(1+e)}}(\textbf{s}\times\textbf{t}),\frac{\sqrt{2(1+e)}}{2}
\right).\qquad\qquad(4.56)
$$
​		当$\textbf{s}$和$\textbf{t}$指向几乎相同的方向时，以这种方式直接生成四元数（相对于$$\textbf{s}\times\textbf{t}$$的叉乘结果的归一化）可以避免数值不稳定[1197]。 当$\textbf{s}$和$\textbf{t}$指向相反的方向时，这两种方法都会出现稳定性问题，因为它们会除以零。 当检测到这种特殊情况时，可以使用任何垂直于$\textbf{s}$的旋转轴旋转到$\textbf{t}$。

​		有时我们需要从$\textbf{s}$到$ \textbf{t}$旋转的矩阵表示。 在对公式4.46进行一些代数和三角数学简化之后，旋转矩阵变为[1233]
$$
\textbf{R}(\textbf{s},\textbf{t})=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
e+hv_x^2
& hv_xv_y-v_z
&hv_xv_z+v_y&0
\\
hv_xv_y+v_z
 & e+hv_y^2
 & hv_yv_z-v_x &0
 \\
 hv_xv_z-v_y
 &hy_zv_z-v_x
 & e+hv_z^2 &0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.57)
\end{gather*}
$$
​		在此方程式中，我们使用了以下中间计算：
$$
\begin{align}
\textbf{v}&=\textbf{s}\times\textbf{t},\\
e&=\cos(2\phi)=\textbf{s}\cdot\textbf{t},\\
h&=\frac{1-\cos(2\phi)}{\sin^2(2\phi)}=\frac{1-e}{\textbf{v}\cdot\textbf{v}}=
\frac{1}{1+e}.
\qquad\qquad(4.58)
\end{align}
$$
​		可以看出，由于简化，所有平方根和三角函数都消失了，因此这是创建矩阵的有效方法。 请注意，公式4.57的结构类似于公式4.30的结构，并请注意，后一种形式不需要三角函数。

​		注意，当$\textbf{s}$和$ \textbf{t}$平行或接近平行时必须小心，因为$$||\textbf{s}\times\textbf{t}||\approx0$$。如果$$\phi \approx0$$，那么我们可以返回单位矩阵。 但是，如果$$2\phi\approx\pi$$，那么我们可以绕任何轴旋转π弧度。 该轴可以使用$\textbf{s}$与不平行于$ \textbf{s}$的任何其他向量之间的叉积找到（第4.2.4节）。 Moller和Hughes使用Householder矩阵以不同的方式处理这种特殊情况[1233]。

### 4.4顶点混合

​		想象一下，数字角色的手臂使用前臂和上臂两部分进行动画处理，如图4.11左侧所示。 该模型可以使用刚体变换进行动画处理（第4.1.6节）。 但是，这两个部分之间的接头将不会像真正的肘部。 这是因为使用了两个单独的对象，因此，关节由来自这两个单独的对象的重叠部分组成。 显然，最好只使用一个对象。 但是，静态模型零件无法解决使关节具有柔性的问题。

​		顶点混合是解决此问题的一种流行方法[1037，1903]。 该技术还有其他几个名称，例如线性混合蒙皮，骨架子空间网格变形。 虽然此处介绍的算法的起源尚不清楚，但定义骨骼并让皮肤对变化做出反应是计算机动画中的一个古老概念[1100]。 在最简单的形式中，前臂和上臂像和以前一样分别进行动画处理，但是在关节处，这两个部分通过一个弹性的“皮肤”相连。因此，该弹性部分将具有两组顶点，一组顶点由前臂矩阵进行变换，另一组顶点由上臂矩阵进行变换。 与每个三角形使用单个矩阵相比，这将导致三角形的顶点可以通过不同的矩阵进行变换。 见图4.11。

![image-20191124201419581](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124201419581.png)

​		<font size=2>图4.11。 手臂由前臂和上臂组成，两个独立的对象进行动画处理使用刚体变换，在左侧。 肘部没有真实的出现。 在右侧，对一个对象使用顶点混合。 最右边的手臂说明了当单一的皮肤将两个部分直接覆盖以覆盖肘部时发生的情况。 最右边的手臂说明了使用顶点混合时发生的情况，并且某些顶点以不同的权重进行了混合：（2/3，1/3），表示顶点从上臂的变换获得的权重为2/3，从前臂获得的变换权重为1/3。 该图在最右边的插图中还显示了顶点混合的缺点。 在这里，可以看到肘部内部的折叠。 使用更多的骨骼和更精心选择重量可以达到更好的效果。</font>

​		进一步执行这一步骤，使单个顶点通过几种不同的矩阵进行变换，并将得到的位置加权并混合在一起。 这是通过为动画对象设置骨骼骨架来完成的，其中每个骨骼的变换可能会通过用户定义的权重影响每个顶点。 由于整个手臂可能是“弹性的”，即所有顶点可能受到不仅一个以上矩阵的影响，因此整个网格通常被称为皮肤（在骨骼上）。 见图4.12。 许多商业建模系统具有相同类型的骨骼骨架建模功能。 尽管名称如此，骨骼并不一定必须是刚性的。 例如，Mohr和Gleicher [1230]提出了添加附加关节以实现诸如肌肉膨胀等效果的想法。 James和Twigg [813]讨论了使用可以挤压和拉伸的骨骼动画蒙皮。

![image-20191124231139634](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124231139634.png)

​		<font size=2>图4.12。 顶点融合的真实示例。 左上方的图像显示了处于伸展位置的手臂的两根骨骼。 在右上角显示了网格，并用颜色表示骨骼拥有的每个顶点。 底部：手臂的阴影网格在稍有不同的位置。 （图片由Je Lander [968]提供。）</font>

​		在数学上，这用公式4.59表示，其中$$\textbf{p}$$是原始顶点，$$\textbf{u}(t)$$是变换的顶点，其位置取决于时间t：
$$
\textbf{u}(t)=
\sum^{n-1}_{i=0}w_i\textbf{B}_i(t)\textbf{M}_i^{-1}\textbf{p},
\quad where \sum^{n-1}_{i=0}w_i=1,
\quad w_i\geq0.
\qquad\qquad(4.59)
$$
​		有n个骨骼会影响$$\textbf{p} $$的位置，这表示在世界坐标中。 顶点$$\textbf{p} $$的骨骼$$i$$的权重是值$$w_i$$。 矩阵$$\mathbf{M}_i$$变换初始骨骼的坐标系转换到世界坐标。 通常，骨骼的控制关节位于其坐标系的原点。 例如，前臂骨骼将其肘关节移动到原点，而动画旋转矩阵将手臂的这一部分绕关节移动。 矩阵$$\mathbf{B}_i(t)$$是第i个骨骼的世界变换，会随时间变化对对象进行动画处理，并且通常是多个矩阵的级联，例如之前的骨骼变换的层次结构和局部动画矩阵。

​		Woodland [1903]深入讨论了一种维护和更新$$\mathbf{B}_i(t)$$矩阵动画函数的方法。 每个骨骼都将一个顶点转换到相对于其自身参照系的位置，而且最终位置是从一组计算点插值得到。 矩阵$$\mathbf{M}_i$$在某些蒙皮讨论中未明确表示，而是被视为$$\mathbf{B}_i(t)$$矩阵的一部分。 我们在这里介绍它是因为它是有用的矩阵，而且总是矩阵级联结构的一部分。

​		在实践中，对于动画的每一帧，每个骨骼连接矩阵$$\mathbf{B}_i(t)$$和$$\mathbf{M}_i^{-1}$$，并且每一个结果矩阵都用于变换顶点。 顶点$$\textbf{p} $$由不同骨骼的级联矩阵变换，然后使用权重$$w_i$$进行混合，因此称为顶点混合。 权重是非负的并且总和为1，因此发生的事情是将顶点转换到几个位置，然后在其中进行插值。 这样，对于所有$$i=0...n-1$$（固定），变换后的点$$\mathbf{u}$$将位于点集$$\mathbf{B}_i(t)\mathbf{M}_i^{-1}\mathbf{p}$$的凸包中。 通常使用公式4.59转换法线。 根据所使用的变换（例如，如果骨骼被拉伸或挤压得相当大），如第4.1.7节所述，可能需要$$\mathbf{B}_i(t)\mathbf{M}_i^{-1}$$逆矩阵的转置。

​		顶点混合非常适合在GPU上使用。 网格中的顶点集可以放置在静态缓冲区中，该缓冲区一次发送到GPU并被重新使用。 在每帧中，只有骨骼矩阵会发生变化，而顶点着色器会计算它们对存储的网格的影响。 这样，可以最大程度地减少在CPU上处理和从CPU传输的数据量，从而使GPU高效地渲染网格。 如果模型的整个骨骼矩阵可以一起使用，则是最简单的。 否则，必须拆分模型并复制一些骨骼。 或者，可以将骨骼变换存储在顶点访问的纹理中，从而避免达到寄存器存储限制。每个变换可以仅存储在两个纹理中，通过使用四元数表示旋转[1639]。 如果可用，无序访问视图存储将允许重新使用蒙皮结果[146]。

​		可以指定超出[0,1]范围或不等于1的权重集。 但是，这仅在使用某些其他混合算法（例如渐变目标（4.5节））时才有意义。

​		基本顶点融合的一个缺点是可能会发生不必要的折叠，扭曲和自交[1037]。见图4.13。更好的解决方案是使用双四元数[872，873]。这种执行蒙皮的技术有助于保持原始变换的刚性，因此避免了四肢的“糖果包裹”扭曲。计算成本不到线性蒙皮混合的成本的1.5倍，并且效果很好，这导致该技术的快速被采用。但是，双四元数蒙皮会导致鼓起效果，Le 和 Hodgins [1001]提出了旋转中心蒙皮作为更好的选择。他们基于这样的假设：局部变换应该是刚体，并且具有相似权重$$\mathbf{M}_i$$的顶点应该具有相似的变换。预先为每个顶点计算旋转中心，同时施加正交（刚体）约束以防止肘关节塌陷和糖果包装纸扭曲的现象。在运行时，该算法类似于线性混合蒙皮，因为GPU在旋转中心执行执行线性混合蒙皮，随后执行四元数混合步骤。

![image-20191124230557239](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124230557239.png)

![image-20191124230616070](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191124230616070.png)

​		<font size=2>图4.13。 左侧显示了使用线性混合蒙皮时关节处的问题。 在右侧，使用双四元数混合可以改善外观。 （图片由Ladislav Kavan等人提供，Paul Steed [1693]为其模型。）</font>

### 4.5渐变

​		在播放动画时，把一个三维模型渐变到另一个三维模型通常会很有用[28、883、1000、1005]。 假设一个模型在时间$t_0$显示，我们希望它在时间$t_1$渐变到另一种模型。 对于所有介于$t_0$和$t_1$之间的时间，都可以使用某种插值方法获得连续的“混合”模型。 渐变的一个例子如图4.14所示。

![image-20191125224157334](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191125224157334.png)

​		<font size=2>图4.14。 顶点渐变。 每个顶点都定义了两个位置和法线。 在每帧中，中间时刻的位置和法线由顶点着色器线性插值得到。 （图片由NVIDIA Corporation提供。）</font>

​		渐变涉及解决两个主要问题，即顶点对应问题和插值问题。 给定两个任意模型，这些模型可能具有不同的拓扑，不同的顶点数量和不同的网格连接性，通常必须从建立这些顶点对应关系开始。 这是一个困难的问题，并且在该领域已经进行了很多研究。 我们推荐感兴趣的读者阅读Alexa的调查[28]。

​		但是，如果两个模型之间已经存在一对一的顶点对应关系，则可以在基于每个顶点进行插值。 也就是说，对于第一个模型中的每个顶点，在第二个模型中必须仅存在一个顶点与之对应，反之亦然。 这使插值变得容易。 例如，线性插值可以直接在顶点上使用（有关插值的其他方法，请参见第17.1节）。 为了计算时间$t_1\in[t_0,t_1]$的变形顶点，我们首先计算$s=(t-t_0)/(t_1-t_0)$），然后线性顶点混合，
$$
\textbf{m}=(1-s)\textbf{p}_0+s\textbf{p}_1,
\qquad\qquad(4.60)
$$
其中$p_0$和$p_1$对应于相同的顶点，但在不同的时间$t_0$和$t_1$。

​		渐变的变种，其让用户拥有更直观控制被称为渐变目标或混合形状[907]。 基本思想可以使用图4.15进行解释。

![image-20191125224306960](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191125224306960.png)

​		<font size=2>图4.15。 给定两个嘴部姿势，计算一组差异向量的集合以控制插值，甚至控制外推。 在渐变目标中，差异向量用于将运动“添加”到中性脸部上。 对差向量使用正权重时，我们会露出笑容，而负权重会产生相反的效果。</font>

​		我们从一个中性模型开始，在这种情况下，它是一张脸。 让我们用N表示该模型。此外，我们还有一组不同的脸部姿势。 在此处的说明中，只有一个脸部姿势，一张笑脸。 通常，我们可以允许k≥1个不同的姿势，表示为$P_i,i\in[1,...,k]$。 作为预处理，“不同的脸”的计算公式为：$D_i=P_i-N$，即，从每个脸部姿势中减去中性模型。

​		在这一点上，我们有一个中立模型N和一组差异姿势$D_i$。 然后可以使用以下公式获得变形模型M：
$$
M = N + \sum_{i=1}^{k}w_iD_i. (4.61)
$$
​		对于这个中性模型，最重要的是，我们使用权重$w_i$添加所需的不同姿势的特征。 对于图4.15，设置$w_i=1$可使我们恰好位于插图中间。 使用$w_i=0.5$给我们一个半张微笑的脸，依此类推。 也可以使用负权重，也可以使用大于一的权重。

​		对于这个简单的脸部模型，我们可以添加表示“悲伤”眉毛。 负权重的眉毛会产生“快乐”的表情。 由于眉毛的位移是附加的，因此该眉毛姿势可与笑脸姿势一起使用。

​		渐变目标是一种强大的技术，可为动画师提供很多控制，因为模型的不同特征可以相互独立地进行操纵。 Lewis等 [1037]介绍了姿势空间渐变，它结合了顶点融合和顶点渐变目标。 Senior [1608]使用预先计算的顶点纹理来存储和检索目标姿势之间的替换。 支持流输出的硬件和每个顶点的ID允许在单个模型中使用更多目标，并且效果可以在GPU上专门计算[841，1074]。 使用低分辨率网格然后通过曲面细分阶段和替换映射生成高分辨率网格，可以避免在高度详细的模型中为每个顶点蒙皮的成本[1971]。

​		图4.16显示了同时使用蒙皮和渐变的真实示例。 Weronko和Andreason [1872]在《 The Order：1886》中使用了蒙皮和渐变。

![image-20191125224340010](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191125224340010.png)

​		<font size=2>图4.16。 Delsin角色在臭名昭著的Second Son中的脸部使用混合形状进行了动画处理。 所有这些拍摄都使用相同的静止姿势面孔，然后修改不同的权重以使面孔看起来有所不同。 （图片由Naughty Dog LLC提供。Infamous Second Son 2014年索尼互动娱乐LLC。InfamousSecond Son是Sony Interactive Entertainment LLC的商标。由Sucker Punch Productions LLC开发。）</font>

### 4.6几何缓存回放

​		在剪辑场景中，可能希望使用极高质量的动画，例如，对于无法使用上述任何方法表示的运动。 天真的方法是存储所有帧的所有顶点，从磁盘读取它们并更新网格。 但是，一个有30,000个顶点的简单模型在一个短动画中，这可能达到50 MB / s。 Gneiting [545]提出了几种将内存成本降低到大约10％的方法。

​		首先，使用量化。例如，位置和纹理坐标使用16位整数存储对于它们自身的坐标。这一步骤是有损的，在执行压缩后无法恢复原始数据的。为了进一步减少数据，进行了空间和时间预测，并对差异进行了编码。对于空间压缩，可以使用平行四边形预测[800]。对于三角形带，下一个顶点的预测位置就是当前三角形在其边周围的三角形平面中反射的当前三角形，从而形成平行四边形。与这个新位置的差异随后被编码。有了良好的预测，大多数值将接近零，这对于许多常用的压缩方案是理想的。与MPEG压缩类似，在时间维度上也进行预测。即，每n帧执行一次空间压缩。在这两者之间，将在时间维度上进行预测，例如，如果某个顶点通过增量向量从帧n-1移动到帧n，则很可能以相似的移动量到帧n + 1。这些技术减少了存储量足以使该系统可用于实时流数据。

### 4.7投影

​		在实际渲染场景之前，必须将场景中的所有相关对象投影到某种平面或某种简单体积上。 之后，将执行裁剪和渲染（第2.3节）。

​		本章到目前为止所看到的变换不影响第四个坐标（w分量）。 也就是说，点和向量在转换后仍保留其类型。 同样在4×4矩阵中，最底行始终为（0 0 0 1）。 透视投影矩阵是这两个属性的例外：最底行包含矢量和点操作数，并且经常需要归一化操作。 也就是说，w通常不是1，因此需要除以w才能获得非齐次点。 在本节中首先处理一种更简单也很常用的投影类型：正交投影。 它不会影响w分量。

​		在本部分中，假设观察者沿着相机的负z轴观看，y轴指向上方，x轴指向右侧。 这是一个右手坐标系。 某些文本和软件（例如DirectX）使用的是惯用左手的系统，在该系统中，观看者沿着相机的正Z轴看。 两种系统都是同等有效的，最后达到相同的效果。		

#### 4.7.1正交投影

​		正交投影的特征是平行线在投影之后保持平行。 当使用正交投影观看场景时，无论与相机的距离如何，对象都保持相同的大小。 矩阵$\mathbf{P}_o$，如下所示，是一个简单的正投影投影矩阵，它使一个点的x轴和y轴分量保持不变，而将z轴分量设置为零，即正交投影在平面z = 0上：
$$
\textbf{P}_o=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&0&0
\\
0&1&0&0
 \\
0&0&0&0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.62)
\end{gather*}
$$
​		图4.17说明了这种投影的效果。 显然矩阵$\mathbf{P}_o$是不可逆的，因为其行列式$|\mathbf{P}_o|=0$。换句话说，变换从三维降为二维，并且无法检索丢失的维度。 使用这种正交投影进行查看的问题在于，它将正值z点和负z值点都投影到投影平面上。 通常将z值（以及x和y值）限制为一定的范围是很有用的，例如从n（近平面）到f（远平面）。近平面也被称为 front plane 或者 hither; 远平面也被称为back plane 或者 yon。这种限制是平行投影的目的。

![image-20191126225539056](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191126225539056.png)

​		<font size=2>图4.17。 由公式4.62生成的简单正交投影的三种不同视图。 当观看者沿着负z轴看时，可以看到此投影，这意味着该投影仅跳过（或设置为零）z坐标，同时保持x和y坐标。 请注意，z = 0两侧的对象都投影到投影平面上。</font>

​		进行正交投影的更常见矩阵由六元组（l， r， b， t， n， f）表示，分别表示左侧，右侧，底部，顶部，近侧和远侧平面。 将由这些平面形成的与轴对齐的包围盒（AABB；请参见第22.2节中的定义）转换为以原点为中心的与轴对齐的立方体。 AABB的最小角为（l， b， n），最大角为（r， t， f）。 重要的是要认识到n> f，因为我们正朝着该空间体积的负z轴方向看。 我们的常识是，接近值应该比远端值低，因此可以让用户按原样提供它们，然后在内部取反它们。

​		在OpenGL中，与轴对齐的立方体的最小角为（-1，-1，-1），最大角为（1，1， 1）; 在DirectX中，范围是（-1，-1， 0）至（1，1， 1）。 该立方体称为规范视图体积，而该体积中的坐标称为规范化设备坐标。 转换过程如图4.18所示。 转换为规范视图体积的原因是裁剪能更有效地执行在该体积中。

​		转换为规范视图体积后，将要渲染的几何图形的顶点剪切到该立方体上。 不在立方体之外的几何图形最终被渲染通过将剩余的单位正方形映射到屏幕来。 此正交变换如下所示
$$
\textbf{P}_o=\textbf{S}(\textbf{s})\textbf{T}(\textbf{t})=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2}{r-l}&0&0&0
\\
0&\frac{2}{t-b}&0&0
 \\
0&0&\frac{2}{f-n}&0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}
\begin{pmatrix}
\begin{matrix}
1&0&0&-\frac{l+r}{2}
\\
0&1&0&-\frac{t+b}{2}
 \\
0&0&1&-\frac{f+n}{2}
\\
0&0&0&1
\end{matrix}
\end{pmatrix}\\=
\begin{pmatrix}
\begin{matrix}
\frac{2}{r-l}&0&0&-\frac{r+l}{r-l}
\\
0&\frac{2}{t-b}&0&-\frac{t+b}{t-b}
 \\
0&0&\frac{2}{f-n}&-\frac{f+n}{f-n}
\\
0&0&0&1
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.63)
\end{gather*}
$$
​		正如这个等式如建议的，$\mathbf{P}_o$可以被写作变换的级联，平移变换$\mathbf{T}(\mathbf{t})$然后接着缩放矩阵$\mathbf{S}(\mathbf{s})$其中$\mathbf{s}=(2(r-l),2(t-b),2(f-n)),\mathbf{t}=(-(r+l)/2,-(t+b)/2,-(f+n)/2)$这个矩阵是可逆的（当且仅当$n\neq f,l\neq r,t\neq b$否者不存在逆矩阵）。即$\mathbf{P}_o^{-1}=\mathbf{T}(-\mathbf{t})\mathbf{S}((r-l)/2,(t-b)/2,(f-n)/2)$

​		在计算机图形学中，投影后最常使用左侧坐标系，即，对于视口，x轴向右，y轴向上，而z轴进入视口。 因为按照我们定义AABB的方式，远值小于近值，所以正交变换将始终包含一个镜像变换。 对于这一点，可以说原始的AABB尺寸与目标尺寸相同，即都是标准视图体积。 然后AABB的坐标分量对于（l， b， n）是（-1，-1， 1），对于（r， t， f）是（1， 1，-1）。 将其应用于方程式4.63可得出
$$
\textbf{P}_o=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&0&0
\\
0&1&0&0
 \\
0&0&-1&0
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.64)
\end{gather*}
$$
​		这是一个镜像矩阵。 这种镜像将右手观察坐标系（从负z轴向下看）转换为左手归一化设备坐标系。

​		DirectX将z深度值映射到[0， 1]而不是OpenGL的[1， 1]。 这可以通过在正交矩阵之后应用简单的缩放和平移矩阵来完成，即

​		
$$
\textbf{M}_{st}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&0&0
\\
0&1&0&0
 \\
0&0&0.5&0.5
\\
0&0&0&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.65)
\end{gather*}
$$
​		所以在DirectX中使用的正交矩阵为

​		
$$
\mathbf{P}_{o[0,1]}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2}{r-l}&0&0&-\frac{r+l}{r-l}
\\
0&\frac{2}{t-b}&0&-\frac{t+b}{t-b}
 \\
0&0&\frac{1}{f-n}&-\frac{n}{f-n}
\\
0&0&0&1
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.66)
\end{gather*}
$$
​		由于DirectX使用行优先格式编写矩阵，因此这通常以转置形式出现。

#### 4.7.2平行投影

​		透视投影是比正交投影更复杂的变换，它通常在大多数计算机图形应用程序中使用。 在此平行线在投影之后通常不平行；当然，在极远处它们可能会收敛到一个点。透视更紧密地匹配我们如何感知世界，即更远的物体更小。

​	   首先，我们将提供有益的推导对投影到平面$z=d,d>0$上的透视投影矩阵。我们从世界空间中推导，以简化对世界到视图变换的理解。 此推导之后是更常规使用的矩阵，例如OpenGL [885]。

![image-20191128224313546](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191128224313546.png)

​		<font size=2>图4.19。 用于导出透视投影矩阵的符号。 将点$\mathbf{p}$投影到平面$z=d,d>0$，得出投影点$\mathbf{q}$。 投影是从摄影机位置的角度进行的，在本例中为原点。 右侧的$x$分量显示了推导中使用的相似三角形。</font>

​		假设摄像机（视点）位于原点，并且我们要将一个点$\mathbf{p}$投影到平面$z=d,d>0$，从而产生一个新点$\mathbf{q}=(q_x,q_y,-d)$  。 图4.19描绘了这种情况。 从该图所示的相似三角形中，以下推导得出$\mathbf{q} $的$x$分量的：
$$
\frac{q_x}{p_z}=\frac{-d}{p_z}\Leftrightarrow
q_x=-d\frac{p_x}{p_z}.
\qquad\quad(4.67)
$$
​		$\mathbf{q}$的其他分量的表达式为$q_y=-dp_y/p_z$（类似于$q_x$获得），$q_z=d$。 与上面的公式一起，它们给出了透视投影矩阵$\mathbf{P}_p$，如下所示：
$$
\textbf{P}_{p}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&0&0
\\
0&1&0&0
 \\
0&0&1&0
\\
0&0&-1/d&1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.68)
\end{gather*}
$$
​		该矩阵可产生正确的透视投影，可通过以下方式确认
$$
\textbf{q}=\mathbf{P}_p{\mathbf{p}}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
1&0&0&0
\\
0&1&0&0
 \\
0&0&1&0
\\
0&0&-1/d&0
\end{matrix}
\end{pmatrix}
\begin{pmatrix}
\begin{matrix}
p_x
\\
p_y
 \\
p_z
\\
1
\end{matrix}
\end{pmatrix}=
\begin{pmatrix}
\begin{matrix}
p_x
\\
p_y
 \\
p_z
\\
-p_z/d
\end{matrix}
\end{pmatrix}\Rightarrow
\begin{pmatrix}
\begin{matrix}
-dp_x/p_z
\\
-dp_y/p_z
 \\
-dp_z/p_z
\\
1
\end{matrix}
\end{pmatrix}.
\qquad\qquad(4.69)
\end{gather*}
$$
​		最后一步来自以下事实：整个矢量除以$w$分量（在这种情况下为$-p_z/d$），最后得到1。由于我们要投影到该平面上，因此所得的$z$值始终为$-d$。

​		从直觉上讲，很容易理解为什么齐次坐标允许投影。齐次过程的一种几何解释是将点$(p_x,p_y,p_z)$投影到平面$w=1$上。

​		与正交变换一样，还有一个透视变换，而不是实际投影到平面（不可逆）上，而是将视锥从视锥变换为前述的规范视图体积。此处，视锥假定从$z=n$ 开始，结束在$z=f,0>n>f$。 $z=n$处的矩形在$(l,b,n)$处具有最小角，在$(r,t,n)$处具有最大角。如图4.20所示。

![image-20191128225854408](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191128225854408.png)

​		<font size=2>图4.20。 矩阵$\mathbf{P}_p$将视锥转换为单位立方体，也被称为规范视图体积。</font>

​		参数$(l,r,b,t,n,f)$确定摄像机的视锥。水平视野由视锥的左右平面（由$l$和$r$决定）之间的角度确定。以相同的方式，垂直视野由顶平面和底平面之间的角度（由$t$和$b$确定）确定。视野越大，相机“看得越多”。可以通过$r\neq-l$或$t\neq-b$来创建不对称的截头视锥。例如，不对称的截头视锥可用于立体观看和虚拟现实（第21.2.3节）。

​		视野是提供场景感的重要因素。与计算机屏幕相比，眼睛本身具有物理视野。这种关系是
$$
\phi=2\arctan(w/(2d)),\qquad\qquad (4.70)
$$
​		$\phi$是视场，$w$是垂直于视线的物体的宽度，$d$是到物体的距离。例如，一个25英寸的显示器大约为22英寸宽。在12英寸远处，水平视场为85度；在20英寸处为58度；在30英寸处为40度，可以使用相同的公式将摄像机镜头的尺寸转换为视场，例如，对于35mm摄像机的标准50mm镜头（镜框尺寸为36mm），其$\phi=2\arctan(36/(2\cdot50))=39.6$ = 39.6度。

​		与物理设置相比，使用更窄的视野将减少透视效果，因为观看者将放大场景。设置较宽的视野将使对象看起来失真（例如使用广角摄像机镜头），尤其是在屏幕边缘附近，并且会放大附近对象的比例。然而，较宽的视野使观看者感觉到物体更大并且更令人印象深刻，并且具有向用户提供有关周围环境的更多信息的优点。

​		公式4.71给出了将视锥转化为单位立方体的透视变换矩阵：
$$
\mathbf{P}_{p}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2n}{r-l}&0&-\frac{r+l}{r-l}&0
\\
0&\frac{2n}{t-b}&-\frac{t+b}{t-b}&0
 \\
0&0&\frac{f+n}{f-n}&-\frac{2fn}{f-n}
\\
0&0&1&0
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.71)
\end{gather*}
$$
​		将转换应用到一个点后，我们将得到另一个点$\mathbf{q}=(q_x,q_y,q_z,q_w)^T$。此时的$w$分量$q_w$（通常）将为非零且不等于1。要获得投影点$\mathbf{p}$，我们需要除以$q_w$，即
$$
\mathbf{p}=(q_w/q_w,q_y/q_w,q_z/q_w,1).
\qquad\qquad(4.72)
$$
​		矩阵$\mathbf{P}_p$总是能看到$z=f$映射到+1和$z=n$映射到-1。

​		远平面以外的对象将被剪切，因此不会出现在场景中。透视投影可以处理取到无穷远的远平面，这使公式4.71变为
$$
\mathbf{P}_{p}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2n}{r-l}&0&-\frac{r+l}{r-l}&0
\\
0&\frac{2n}{t-b}&-\frac{t+b}{t-b}&0
 \\
0&0&1&-2n
\\
0&0&1&0
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.73)
\end{gather*}
$$
​		综上所述，应用透视变换（以任何形式）$\mathbf{P}_p$，然后进行裁剪和齐次化（除以$w$），从而得到标准化的设备坐标。

​		要获得在OpenGL中使用的透视变换，出于与正交变换相同的原因，首先将其与$\textbf{S}(1,1,-1,1)$相乘。这仅会使等式4.71第三列中的值取反。在应用此镜像变换之后，将近值和远值作为正值输入，其中$0<n'<f'$，如传统上将它们呈现给用户一样。但是，它们仍然代表沿世界负z轴（即视线方向）的距离。出于参考目的，这是OpenGL方程：
$$
\mathbf{P}_{OpenGL}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2n'}{r-l}&0&\frac{r+l}{r-l}&0
\\
0&\frac{2n'}{t-b}&\frac{t+b}{t-b}&0
 \\
0&0&-\frac{f'+n'}{f'-n'}&-\frac{2f'n'}{f'-n'}
\\
0&0&-1&0
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.74)
\end{gather*}
$$
​		一个更简单的设置是仅提供垂直视场$\phi$，长宽比$a=w/h$（其中$w×h$是屏幕分辨率），$n'$和$f'$。 这导致
$$
\mathbf{P}_{OpenGL}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
c/a&0&0&0
\\
0&c&0&0
 \\
0&0&-\frac{f'+n'}{f'-n'}&-\frac{2f'n'}{f'-n'}
\\
0&0&-1&0
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.75)
\end{gather*}
$$
​		其中$c = 1.0 / \tan（\phi/ 2）$。 该矩阵的作用与旧的gluPerspective（）完全一样，后者是OpenGL Utility Library（GLU）的一部分。

​		某些API（例如DirectX）将近平面映射到$z = 0$（而不是$z = -1$），而将远平面映射到$z =1$。此外，DirectX使用左手坐标系来定义其投影矩阵。 这意味着DirectX沿z轴正方向看，并以正数表示近和远值。 这是DirectX公式：
$$
\mathbf{P}_{p[0,1]}=
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
\frac{2n'}{r-l}&0&-\frac{r+l}{r-l}&0
\\
0&\frac{2n'}{t-b}&-\frac{t+b}{t-b}&0
 \\
0&0&\frac{f'}{f'-n'}&-\frac{f'n'}{f'-n'}
\\
0&0&1&0
\end{matrix}
\end{pmatrix}
\qquad\qquad(4.76)
\end{gather*}
$$
​		DirectX在其文档中使用行优先形式，因此此矩阵通常以转置形式表示。

​		使用透视变换的一种效果是，计算出的深度值不会随输入pz值线性变化。 使用公式4.74–4.76中的任何一个乘以点$\mathbf{p}$，我们可以看到
$$
\mathbf{v}=\mathbf{P}_{\mathbf{p}}=
\begin{pmatrix}
\begin{matrix}
...
\\
...
 \\
dp_z+e
\\
\pm p_z
\end{matrix}
\end{pmatrix},
\qquad\qquad(4,77)
$$
​		其中省略了$v_x$和$v_y$的详细信息，并且常数$d$和$f$取决于所选矩阵。 例如，如果我们使用公式4.74，则$d =-（f'+ n'）/（f'-n'），e = -2f'n'/（f'-n'）$和$v_x = -p_z$ 。 要获得归一化设备坐标（**NDC**）中的深度，我们需要除以$w$分量，结果是
$$
z_{\textbf{DNC}}=\frac{dp_z+e}{-p_z}=d-\frac{e}{p_z},
\qquad\qquad(4.78)
$$
​		其中$zNDC∈[−1，+1]$对于OpenGL投影。 可以看出，输出深度$zNDC$与输入深度$p_z$成反比。

​		例如，如果$n'= 10$且$f'= 110$（使用OpenGL术语），则当$p_z$在负z轴（即中点）下沿60个单位时，归一化设备坐标深度值为0.833，而不是0。 图4.21显示了改变近平面到原点的距离的产生的影响。 近平面和远平面的放置会影响z缓冲区的精度。 第23.7节将进一步讨论这种影响。

![image-20191128233147337](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191128233147337.png)

​		<font size=2>图4.21。 改变近平面到原点的距离的效果。 距离$f'-n'$保持恒定为100。随着近平面变得更靠近原点，更接近远平面的点使用的归一化设备坐标（**NDC**）深度空间的范围更小。 这会使z缓冲区在较大距离处的准确性降低。</font>

​		有几种增加深度精度的方法。 一种常见的方法（我们称为反向z）是使用浮点深度或整型存储1.0 − zNDC [978]。 比较如图4.22所示。 Reed [1472]通过仿真显示，使用带反向z的浮点缓冲区可提供最佳精度，同时这也是整型深度缓冲区（通常每个深度有24bit）的首选方法。 对于标准映射（即非反向z）在变换中分离投影矩阵可降低错误率，如Upchurch和Desbrun [1803]所建议的。 例如，在$\mathbf{T} = \mathbf{PM}$的情况下，使用$\mathbf{P}（\mathbf{Mp}）$比使用$\mathbf{Tp}$更好。 同样，在$[0.5，1.0]$的范围内，fp32和int24的精度非常相似，因为fp32具有23bit的尾数。 使zNDC与$1 / p_z$成正比的原因是，它使硬件更简单并且压缩深度值更加成功，这将在23.7节中详细讨论。

![image-20191129232931850](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191129232931850.png)

​		<font size=2>图4.22。 使用DirectX变换设置深度缓冲区的几种方法，即zNDC∈[0，+1]。 左上方：标准整型深度缓冲区，此处显示为4位精度（因此y轴上有16个标记）。 右上角：远端平面设置为∞，在两个轴上的小位移不会损失太多精度。 左下：具有3个指数位和3个尾数位用于浮点深度。 注意，分布在y轴上是非线性的，这使得在x轴上的分布更糟。 右下：浮点深度反转，即1 − zNDC，分布要好得多。 （插图由内森·里德（Nathan Reed）提供。）</font>

​		劳埃德[1063]提出使用深度值的对数来提高阴影贴图的精度。 Lauritzen等[991]使用前一帧的z缓冲区确定最大近平面和最小远平面。 对于屏幕空间深度，Kemen [881]建议对每个顶点使用以下重新映射：
$$
\begin{align}
z&=w(\log_2(\text{max}(10^{-6},1+w))f_c-1),[\text{OpenGL}]\\
z&=w\log_2(\text{max}(10^{-6},1+w))f_c/2,[\text{DirectX}]
\end{align}
\qquad\qquad(4.79)
$$
​		其中$w$是投影矩阵之后的顶点的$w$值，而$z$是顶点着色器的输出$z$。常数$f_c = 2 / log2（f +1）$，其中$f$为远平面。当仅应用此变换在顶点着色器中时，深度仍将在三角形上被线性插值通过GPU在顶点的非线性变换深度之间（公式4.79）。由于对数是单调函数，因此只要分段线性插值与精确的非线性变换深度值之间的差异较小，遮挡剔除硬件和深度压缩技术仍将起作用。对于大多数具有足够的几何细分的情况，这是正确的。但是，也可以对每个片段应用转换。这是通过输出每个顶点的值$e = 1 + w$来完成的，然后由GPU在三角形上进行插值。然后，像素着色器将片段深度修改为$\log2（e_i）f_c / 2$，其中$e_i$是$e$的插值。当GPU中没有浮点深度并且使用深度较大的距离进行渲染时，此方法是一个很好的选择。

​		Cozzi [1605]建议使用多个视锥，这可以提高精度以有效地达到任何所需的比率。 视锥在深度方向上分为几个不重叠的较小的子视锥，它们的组合是原先的视锥。 子视锥表以从后到前的顺序渲染。 首先，清空颜色和深度缓冲区，并将所有要渲染的对象分类到它们重叠的每个子视锥中。 对于每个子视锥，设置其投影矩阵，清空深度缓冲区，然后渲染与子视锥重叠的对象。

### 进一步阅读和资源

​		沉浸式线性代数站点[1718]提供了一本关于该主题基础知识的互动书籍，通过鼓励您操纵数字来帮助建立直觉。其他的交互式学习工具和转换代码库都来自realtimerendering.com。

​		法林（Farin）和汉斯福德（Hansford）的《几何工具箱》（The Geometry Toolbox）[461]是一部以无痛的方式建立对矩阵的直觉的最佳书籍之一。另一个有用的著作是Lengyel的“ 3D游戏编程和计算机图形学数学” [1025]。从不同的角度来看，许多计算机图形学文本，例如Hearn和Baker [689]，Marschner和Shirley [1129]，以及Hughes等人 [785]也涵盖了矩阵基础知识。 Ochiai等人的课程[1310]介绍了矩阵的基础，以及矩阵的指数和对数，以及用于计算机图形学的知识。 Graphics Gems系列[72、540、695、902、1344]提出了各种与变换相关的算法，并且在线提供了许多此类算法的代码。 Golub和Van Loan的矩阵计算[556]通常是认真研究矩阵技术的起点。有关骨架-子空间变形/顶点融合和形状插值的更多信息，请参见Lewis等人的SIGGRAPH论文[1037]。 ]。

​		Hart等人[674]和Hanson [663]提供了四元数的可视化。 Pletinckx [1421]和Schlag [1566]提出了在一组四元数之间平滑内插的不同方法。 Vlachos和Isidoro [1820]推导了四元数的$c^2$插值公式。四元数插值是沿曲线计算相符的坐标系的问题。 Dougan [374]对此进行了处理。

​		Alexa [28]和Lazarus and Verroust [1000]对许多不同的变形技术进行了调查。父母的书[1354]是有关计算机动画技术的绝佳来源。

## 5.着色基础

​		渲染三维对象的图像时，模型不仅应具有适当的几何形状，而且还应具有所需的视觉外观。根据应用程序的不同，其范围可以从写实感（外观与真实物体的照片几乎相同）到出于创造性原因选择的各种类型的风格化外观。有关两者的示例，请参见图5.1。

​		本章将讨论同样适用于真实感渲染和风格化渲染的那些方面。第15章专门致力于风格化渲染，而本书的重要部分（第9章至第14章）则着重于通常基于物理的真实感渲染方法。

### 5.1着色模型

​		确定渲染对象外观的第一步是选择一个着色模型，用于描述对象的颜色如何根据表面取向，视图方向和光照等因素而产生变化。

​		例如，我们将使用Gooch着色模型[561]的变体。这是第15章讨论的非真实感渲染的一种形式。Gooch着色模型旨在提高技术插图(类似工艺品)中细节的清晰度。

​		Gooch着色背后的基本思想是将表面法线与光源的位置进行比较。如果法线指向灯光，则使用较暖的色调为表面着色；如果指向不对，则使用较冷的色调。介于两者之间的角度在这些色调之间进行插值，这取决于用户提供的表面颜色。在此示例中，我们向模型添加了风格化的“突出显示”效果，以使表面具有光泽外观。图5.2显示了实际的着色模型。

​		着色模型通常具有用于控制外观变化的属性。设置这些属性的值是确定对象外观的下一步。我们的示例模型只有一种属性，即表面颜色，如图5.2的底部图像所示。

![1570721010717](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1570721010717.png)

​		<font size=2>图5.1。顶部图像来自使用虚幻引擎渲染的真实风景场景。底部图片来自Campo Santo的游戏Firewatch，该游戏采用说明性艺术风格设计。 （上图由G̈okhanKaradayi提供，下图由Campo Santo提供。）</font>

​	![1570721041515](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1570721041515.png)

​		<font size=2>图5.2。风格化的着色模型，结合了Gooch着色和高光效果。顶部图像显示了具有中性表面颜色的复杂对象。下图显示了具有各种不同表面颜色的球体。 （来自计算机图形档案[1172]的中国龙网格，来自斯坦福3D扫描存储库的原始模型。）</font>

![1570721057335](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1570721057335.png)

​		<font size=2>图5.3。单位长度矢量输入到示例阴影模型（以及其他大多数着色模型）：表面法线n，视图矢量v和光照方向l。</font>

​		与大多数着色模型一样，此示例受与表面取向相关的视点和照明方向的影响。为了方便着色，这些方向通常表示为归一化（单位长度）向量，如图5.3所示。

​		现在，我们已经定义了阴影模型的所有输入，接下来可以看一下模型本身的数学定义：

​		
$$
\mathbf{c}_{shaded}=
s\textbf{c}_{highlight}+(1-s)(t\textbf{c}_{warm}+(1-t)\textbf{c}_{cool}).
\qquad\qquad(5.1)
$$
​		在此方程式中，我们使用了以下中间计算：
$$
\begin{align}
\textbf{c}_{cool}&=(0,0,0.55)+0.25\textbf{c}_{surface},\\
\textbf{c}_{warm}&=(0.3,0.3,0)+0.25\textbf{c}_{surface},\\
\textbf{c}_{highlight}&=(1,1,1),\\
t&=\frac{\mathbf{n}\cdot\mathbf{l}+1}{2},
\qquad\qquad(5.2)
\\
r&=2(\mathbf{n}\cdot\mathbf{l})\mathbf{n}-\mathbf{l},\\
s&=(100(\mathbf{r}\cdot\mathbf{v})-97)^{\mp}.
\end{align}
$$

​		该定义中的几个数学表达式也经常在其他着色模型中找到。着色操作中通常会进行区间限定操作，通常区间限定到0或在0到1之间。这里，我们将在1.2节中介绍的x表示法用于计算高光混合因子s，限制在0和1之间的区间。点积运算符出现3次，每次出现在两个单位长度的矢量之间；这是一种极为常见的运算。两个向量的点积是它们的长度与它们之间夹角的余弦的乘积。因此，两个单位长度向量的点积就是夹角的余弦，它是两个向量彼此相似程度的度量。由余弦组成的简单函数通常是最令人愉悦且最准确的数学表达式，用于说明着色模型中两个方向（例如，光线方向和表面法线）之间的关系。

​		另一种常见的着色操作是在两种颜色之间基于0到1之间的标量值的线性插值。该操作采用tca +（1- t）cb的形式，随着t的值在1和0之间移动，它会分别在ca和cb各自进行插值。此操作在此着色模型中出现了两次，第一是在$$\mathbf{c}_{warm}$$和$$\mathbf{c}_{cool}$$之间进行插值，第二是将第一的插值结果与$$\mathbf{c}_{hightlight}$$之间进行插值。线性插值在着色器中出现的频率很高，以至于在我们已经看到的每种着色语言中，它都是一个内置函数，称为lerp或mix。

​		线“ r = 2（n·l）n-l”计算反射光矢量，将l反射大约n。尽管不像前两个操作那样普遍，但是对于大多数着色语言来说，它也具有内置的反射功能就足够了。

​		通过将这些操作以不同的方式与各种数学表达式和着色参数组合在一起，可以为多种风格化和逼真的外观定义着色模型

### 5.2光源

​		光照对我们的示例着色模型的影响非常简单。它提供了着色的主要方向。当然，现实世界中的光照可能非常复杂，可以有多个光源，每个光源都有自己的大小，形状，颜色和强度。间接光照会带来更多变化。正如我们将在第9章中看到的那样，基于物理的真实感着色模型需要考虑所有这些参数。

​		相反，风格化的着色模型根据应用程序和视觉样式的需要可以以多种不同方式使用光照。但一些高度风格化的着色模型可能根本没有照明的概念，或者（例如我们的Gooch着色示例）可能仅使用光照来提供一些简单的方向性。

​		光照复杂性的下一步是使着色模型以二元关系对光的存在或不存在做出反应。使用这种着色模型的表面在受到光线影响时将具有一种外观，而在不受光线影响的情况下将具有另外不同的外观。这提供了区分这两种情况的一些准则：与光源的距离，阴影（将在第7章中讨论），表面是否背对光源（即表面法线n与光矢量l之间的角度大于90°），或这些因素的某种组合。

​		从光的二元存在或不存在到光强度的连续性，这都是一小步。这可以表示为不存在和完全存在之间的简单插值，可以表示为强度的有界范围，可能为0到1，或者表示为以无界数量级影响着色的某种方式。后者的一个常见选择是将着色模型分解为亮和不亮部分，而光强$$k_{light}$$线性缩放被亮部分：

​		
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+
k_{light}f_{lit}(\mathbf{l},\mathbf{n},\mathbf{v})
\qquad\qquad(5.3)
$$
​		这可以轻松拓展为RGB型的光颜色：
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+
c_{light}f_{lit}(\mathbf{l},\mathbf{n},\mathbf{v})
\qquad\qquad(5.4)
$$
​		和扩展为多光源：
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+
\sum_{i=1}^{n}c_{light}f_{lit}(\mathbf{l},\mathbf{n},\mathbf{v})
\qquad\qquad(5.5)
$$
​		未受到光照的部分$$f_{unlit}$$（n，v）对应于将光视为二元存在的着色模型中的“不受光影响时的外观”。它可以具有各种形式，具体取决于所需的视觉样式和应用程序的需求。例如，$$f_{unlit}$$（）=（0,0,0）将使不受光源影响的任何表面变为纯黑色。另外，未照明的部分可以为未照明的对象表达某种形式的外观，类似于Gooch模型的冷色，用于远离光线的表面。通常，着色模型的这一部分表示某种形式的光照，这些光照并非直接来自明确放置的光源，例如来自天空的光或来自周围物体反射的光。这些其他形式的照明将在第10章和第11章中讨论。

​		前面我们提到过，如果光方向l与表面法线n的角度大于90°，则光源不会影响表面点，实际上是来自表面下面。这种情况可以视为表面和光照方向在对着色影响中的一种特殊情况。尽管是基于物理的，但这种关系可以从简单的几何原理中得出，并且对于许多基于非物理的类型的和风格化的着色模型也很有用。

​		可以将光在表面上的效果显示为一组射线，其中射线击中表面的密度对应于用于表面着色目的的光强度。参见图5.4，该图显示了光照表面的横截面。沿该截面入射到表面的光线之间的间距与l和n之间的角度的余弦成反比。因此，入射到表面的光线的总密度与l和n之间的角度的余弦成正比，正如我们之前所看到的，它等于这两个单位长度矢量之间的点积。在这里，我们看到了为什么定义与光的传播方向相反的光矢量l会很方便；否则，在执行点积运算之前，我们必须将其取反。

![image-20191201233449917](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233449917.png)

​		<font size=2>图5.4。图的上排示出了表面上的光的截面图。左侧的光线笔直地撞击表面，在中心的光线以一定角度撞击表面，在右侧，我们看到使用矢量点积来计算角度余弦。下图显示了相对于整个表面的横截面平面（包括光和视图向量）。</font>

​		更准确地说，当光线密度为正时，其光线密度（以及光线对着色的贡献）与点积成正比。负值对应于从表面后面发出的光线，无效。因此，在将光的着色乘以光照的点积之前，我们需要先将点积的值进行区间限定为0。使用第1.2节中介绍的$$x^+$$表示，即将负值置为零，我们有
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+
\sum_{i=1}^{n}(\mathbf{l}_{i}\cdot\mathbf{n})^{+}c_{light}f_{lit}(\mathbf{l},\mathbf{n},\mathbf{v})
\qquad\qquad(5.6)
$$
​		支持多个光源的着色模型通常将使用公式5.5（更通用）或公式5.6（基于物理的模型所需）中的一种。公式5.6这对于风格化模型也可能是有利的，因为它有助于确保照明的总体一致性，尤其是对于背离灯光或阴影的表面。但是，某些模型不适用于该结构。此类模型将使用公式5.5。

​		函数flit()的最简单选择是使其颜色恒定，
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+
\sum_{i=1}^{n}(\mathbf{l}_{i}\cdot\mathbf{n})^{+}c_{light}c_{sufface}
\qquad\qquad(5.8)
$$
​		该模型上收到光照的部分符合兰伯特着色模型，Johann Heinrich Lambert [967]（于1760年提出），该模型在理想的漫反射表面（即完全无光泽的表面）的背景下工作。在这里，我们对Lambert模型进行了一些简化的解释，将在第9章中更严格地介绍。Lambertian模型可以单独用于简单着色，它是许多着色模型的关键组成部分。

​		从公式5.3-5.6中可以看出，光源通过两个参数与着色模型交互：入射光的方向l和光的颜色$$c_{light}$$。有多种不同类型的光源，它们的主要区别在于这两个参数在场景中的变化方式。

​		接下来，我们将讨论几种流行类型的光源，它们有一个共同点：在给定的表面位置，每个光源仅从一个方向l照射表面。换句话说，从作色表面位置看，光源是一个无限小的点。对于现实世界的光源，这并非严格如此，但是大多数光源相对于它们与照明表面的距离较远，因此这是一个合理的近似值。在7.1.2和10.1节中，我们将讨论从多个方向照亮表面位置的光源，即“区域光”。

#### 5.2.1平行光

​		平行光是最简单的光源模型。l和$$c_{light}$$两个部分在整个场景中都保持不变，除了$$c_{light}$$可能受到阴影的影响而产生衰减。平行光在空间中没有具体的位置坐标，这和真实的光源不同。真实的光源一般在空间中都有明确的坐标位置。平行光是一种抽象概念，当场景到光源的距离远大于场景大小时，平行光是很好选择。例如，一个小的桌面模型受到距离20英尺远的泛光灯的照射，泛光灯可以被视为平行光。或者几乎所有受到太阳照射的场景，除了所涉及的场景是诸如太阳系内行星之类的场景。

​		可以扩展平行光的概念，允许在入射光方向l保持恒定的同时改变$$c_{light}$$的值。这种情况通常是将灯光效果绑定到场景的特定部分出于性能或者其他原因。例如，可以定义一个处于两个嵌套的（一个在另一个内）方形体积的区域，其中靠近外盒的$$c_{light}$$等于外盒外的（0,0,0）（纯黑色），靠近内盒的等于内盒的一个常量，而处于两个方形体积之间的区域的值将对两个$$c_{light}$$进行平滑插值。

#### 5.2.2精确光源

​		精确光源不是实时的光源，但精确光源具有位置坐标。与现实中的光源不同，此类光源没有大小，形状，尺寸信息。对于拉丁语中的“point”，我们用术语“punctual”来表示“point”，该术语包括源自单个局部位置的所有照明源。我们使用“point light”一词来表示一种特定类型的发射源，它在所有方向上均等地发射光。因此，点光源和聚光灯是精确光源的两种不同形式。入射光向量l随当前着色表面点$$p_{0}$$相对于点光源的位置$$p_{light}$$的位置而变化：
$$
\mathbf{l}=\frac{\mathbf{p}_{light}-\mathbf{p}_{0}}
{\Arrowvert\mathbf{p}_{light}-\mathbf{p}_{0}\Arrowvert}
\qquad\qquad(5.9)
$$
​		这个等式是向量归一化的一个例子：一个向量除以它的长度得到一个单位长度的和原向量同方向的向量。这是一个常见的作色运算，这和我们之前提到其他作色运算一样，对于大多数的着色语言都内置了这个运算。但是，有时需要此操作的中间结果，这需要使用更多基本操作以多个步骤显式执行归一化。将其应用于精确光源方向计算可以得到以下结果：
$$
\begin{align}
\mathbf{d}&=\mathbf{p}_{light}-\mathbf{p}_{0}\\
r&=\sqrt{\mathbf{d}\cdot\mathbf{d}}\\
\mathbf{l}&=\frac{\mathbf{d}}{r}
\qquad\qquad(5.10)
\end{align}
$$
​		两个向量间的点乘操作等于两个向量的长度乘以这两个向量之间的夹角的cos值，因为cos0°=1，所以点乘向量自身的操作等于该向量长度的平方。所以要想获得任意向量的长度只需要将该向量点乘自己然后开方。

​		我们所需要的中间值是r，从精确光源到当前作色点的距离。它除了用来归一化入射光向量，还被用来计算光线颜色的衰减其中$$c_{light}$$作为距离函数，这将在之后的章节讨论。

##### 点光源/全向光源

​		在所有方向上均匀发光的精确光源被称为点光源或全向光源。对于点光源，$$c_{light}$$的值作为距离r的函数，唯一的变化源是之前提到的距离衰减。图5.5使用类似于图5.4中余弦因数的几何推理，说明了为什么会变暗。在给定的表面上，来自点光源的射线之间的间隔与从表面到光源的距离成比例。与图5.4中的余弦因子不同，此间隔的增加沿表面上的两个维度发生，因此射线密度（光线颜色$$ c_{light}$$）与距离r的平方的倒数$$\frac{1}{r^2}$$成比例。这使我们能够使用单个光照属性$$c_{light_{0}}$$来指定$$ c_{light} $$的空间变化，该属性定义为在固定参考距离$$r_{0}$$处的$$c_{light}$$值：
$$
\mathbf{c}_{light}(r)=
\mathbf{c}_{light_{0}}(\frac{r_{0}}{r})^2
\qquad\qquad(5.11)
$$
​		等式5.11经常被称为平方反比光线衰减。尽管公式对点光源的距离衰减是对的，但还有一些问题让这个等式不能作为理想状态被实际的着色使用。

​		第一个问题是当相对距离过小的时候，公式中的r值趋向于0，$$c_{light}$$的值会无限的增大。当r的值等于0，我们会面临一个除零的问题，解决这个问题的一个方法是为分母添加一个极小的值$$\epsilon$$:

​		$$\epsilon$$值的精确大小取决于应用程序的需要，例如，虚幻引擎让$$\epsilon$$=1cm
$$
\mathbf{c}_{light}(r)=
\mathbf{c}_{light_{0}}\frac{r_{0}^2}{r^2+\epsilon}
\qquad\qquad(5.12)
$$
​		另一个方法是限制r的最小值到$$r_{min}$$，这在CryEngine和寒霜引擎中被使用

​		
$$
\mathbf{c}_{light}(r)=
\mathbf{c}_{light_{0}}
\begin{pmatrix}
\frac{r_{0}}
{max(r,r_{min})}
\end{pmatrix}
^2
\qquad\qquad(5.13)
$$
​		不同于先前方法中使用的任意$$ \epsilon $$值，$$r_{ min }$$的值具有物理解释：发射光的物理半径。 r小于$$r_{ min }$$的值对应于穿透物理光源内部的着色表面，这是不可能的。

![image-20191201233522012](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233522012.png)

​		<font size=2>图5.5。来自点光源的光线之间的间距与距离r成正比增加。由于间距的增加是二维的，因此光线的密度（以及光强度）成比例地降低随着1/r平方的增大。</font>

​		平方反比衰减的第二个问题发生在相对较大的距离处。问题不在于视觉效果，而在于性能。尽管光强度会随着距离的增加而降低，但它永远不会变为0。为进行高效渲染，希望光在某个有限距离处达到0强度（第20章）。可以通过多种不同的方式修改平方反比公式来实现这一目的。理想情况下，修改应引入尽可能少的更改。为了避免在光线影响的边界处出现明显的截止，还建议修改函数的导数和值在相同距离处达到0。一种解决方案是将平方函数乘以具有所需属性的开窗函数。虚幻引擎[861]和寒霜[960]游戏引擎都使用了这样一种功能[860]：

​		
$$
f_{win}(r)=
\begin{pmatrix}
1-(\frac{r}{r_{max}})^4
\end{pmatrix}^{+2}
\qquad\qquad(5.14)
$$
​		+2表示限定值，如果值为负数则限定值为0。图5.6展示了反比平方曲线和窗口函数乘积的结果。

![image-20191201233549219](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233549219.png)

​		<font size=2>图5.6。该图显示了平方反比曲线（使用ε方法避免奇异性，ε值为1），公式5.14中描述的窗口函数（rmax设置为3）和窗口曲线。</font>.

​		应用程序的需求将影响所用方法的选择。例如，当以相对较低的空间频率（例如，在光照贴图或每个顶点中）采样距离衰减函数时，在rmax处使导数等于0尤为重要。 CryEngine不使用光照贴图或顶点照明，因此它采用了更简单的调整，在0.8rmax和rmax之间变换为线性衰减[1591]。

​		对于某些应用程序，匹配平方反比曲线不是优先事项，因此完全使用其他功能函数。这有效地将公式5.11-5.14概括为以下内容：
$$
\mathbf{c}_{light}(r)=
\mathbf{c}_{light_{0}}f_{dist}(r)
\qquad\qquad(5.15)
$$
​		其中fdist（r）是距离的某些函数。这种函数称为距离衰减函数。在某些情况下，非反平方衰减函数的使用受性能约束。例如，“正当防卫2（Just Cause 2）”游戏需要的照明非常便利。它规定了一个衰减函数，该函数易于计算，同时还足够平滑，可以避免每个顶点的照明特效[1379]：

​		
$$
f_{dist}(r)=
\begin{pmatrix}
1-(\frac{r}{r_{max}})^2
\end{pmatrix}^{+2}
\qquad\qquad(5.16)
$$
​	在其他情况下，衰减功能的选择可能受到设计因素的影响。例如，用于真实感游戏和风格化游戏的虚幻引擎具有两种用于光衰减的模式：如公式5.12中所述的平方反比模式，以及可以调整以创建各种衰减曲线的指数衰减模式。 [1802]。游戏古墓丽影（2013）的开发人员使用样条编辑工具来编写衰减曲线[953]，从而可以更好地控制曲线形状。

##### 聚光灯

​		与点光源不同，几乎所有真实世界的光源照明都随方向和距离而变化。这种变化可以表示为方向衰减函数fdir（l），该函数与距离衰减函数结合以定义光强度的整体空间变化：
$$
\mathbf{c}_{light}=
\mathbf{c}_{light_{0}}f_{dist}(r)f_{dir}(r)
\qquad\qquad(5.17)
$$
​		选择不同的fdir（l）可以产生各种光照效果。其中一种重要的效果是聚光灯，它将光投射到圆锥形中。聚光灯的方向衰减函数具有围绕聚光灯方向矢量s的旋转对称性，因此可以表示为s与相对于表面的反向光线向量-l之间的角度θs的函数。需要反转光线向量，因为我们之前将光线向量l定义为从表面上指向光源，但在这里我们需要从光源发射的向量。

​		大多数聚光灯函数都使用由θs的余弦组成的表达式，这是着色中角度最常见的形式（如我们先前所见）。聚光灯通常具有本影角θu，该本影角对光进行限制，以使所有θs≥θu的fdir（l）= 0。该角度可以与前面看到的最大衰减距离rmax类似用于剔除。聚光灯通常还具有半影角θp，该半影角定义了一个内锥，在该锥中，光拥有其全部强度。见图5.7。

![image-20191201233607238](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233607238.png)

​		<font size=2>图5.7。聚光灯：θs是从灯的定义方向s到向量-l的角度，即到表面的方向； θp表示半影； θu表示为光定义的本影角。</font>

​		许多种类的方向衰减函数被聚光灯所使用，但它们往往大致相似。例如，函数FdirF（l）用于寒霜游戏引擎[960]，函数fdirT（l）用于three.js浏览器图形库[218]：
$$
\begin{align}
t&=
\begin{pmatrix}
\frac{\cos\theta_{s}-\cos\theta{u}}{\cos\theta_{p}-\cos\theta{u}}
\end{pmatrix}^{\mp},\\
f_{dir_{F}}(\mathbf{l})&=t^2,\\
f_{dir_{T}}(\mathbf{l})&=smoothstep(t)=t^2(3-2t).
\qquad\qquad(5.18)
\end{align}
$$
​		回想一下，$$x^{ \mp }$$是我们在1.2节中介绍的将限制在0和1之间的符号。平滑步长函数是三次多项式，通常用于着色中的平滑插值。它是大多数着色语言的内置函数。

​		图5.8显示了到目前为止我们讨论过的某些光源类型。

![image-20191201233621968](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233621968.png)

​		<font size=2>图5.8。某些类型的灯。从左到右：平行光，无衰减的点光源和平滑过渡的聚光灯。请注意，由于光线和表面之间的角度变化，点光会朝边缘变暗。</font>

##### 其他类型的精确光源

​		精确光源中clight的部分的值可以通过多种方式进行变化。

​		fdir（l）函数不仅限于上述简单的聚光灯衰减功能；它可以表示任何类型的方向变化，包括从实际光源测量的复杂列表模式。照明工程协会（IES）已为此类测量定义了标准文件格式。 IES配置文件可从许多照明设备制造商处获得，并已用于游戏Killzone：Shadow Fall [379，380]，以及虚幻 [861]和寒霜 [960]游戏引擎中。 Lagarde很好地总结了[961]在解析使用此文件格式中的问题。

​		游戏《古墓丽影》（Tomb Raider，2013年）[953]具有一种精确光源，可对沿x，y和z世界轴的距离应用独立的衰减功能。在《古墓丽影》中，曲线还应用于随时间变化的光强，例如产生闪烁的手电筒。

​		在第6.9节中，我们将讨论如何通过使用纹理来改变光强和颜色。

#### 5.2.3其他光照类型

​		平行光和精确光源的主要特征是光线方向l是如何计算的。可以通过使用其他方法来计算光线方向来定义不同类型的光。例如，除了前面提到的光源类型外，古墓丽影还拥有使用线段作为光源而不是点的胶囊灯[953]。对于每个着色像素，将线段上最接近点的方向用作光线方向l。

​		一旦着色器拥有在着色方程中使用的l和clight值，可以使用任何方法去计算这些值。

​		到目前为止讨论的光的类型是抽象的。实际上光源具有大小和形状，并且它们从多个方向照亮表面点。在渲染中，此类光源称为区域光源，它们在实时应用程序中的使用稳步增长。区域光渲染技术分为两类：一种模拟由于区域光受到部分遮挡而产生的阴影，阴影边缘变柔和的技术（第7.1.2节），和模拟区域光对表面着色的影响的技术。 （第10.1节）。第二类光照对于光滑的镜面表面最为明显，在这种表面上，可以通过反射清楚地看到光源的形状和大小。平行光和精确光源不太可能被废弃，尽管它们不再像过去那样普遍。已经开发出一种近似光照面积而且实现起来相对简单的技术，因此得到了广泛的应用。GPU性能的增强还允许使用比过去更复杂的技术。

### 5.3实现着色模型

​		为了发挥作用，这些着色和光照方程式当然必须在代码中实现。在本节中，我们将介绍设计和编写此类实现的一些关键注意事项。我们还将逐步介绍一个简单的实现示例。

#### 5.3.1评估频率

​		在设计着色实现时，需要根据计算频率对计算进行划分。首先，确定给定计算的结果在整个draw call中是否始终恒定。在这种情况下，尽管GPU计算着色器可用于特别昂贵的计算，但计算通常可由应用程序在CPU上执行。得到的结果通过统一的着色器输入传递到图形API。

​		即使在这一类别中，也可能有各种各样的可能的评估频率，从“一次性”开始。这种情况最简单的情况就是着色方程式中的常数子表达式，但这可以应用于基于很少更改的诸如硬件配置和安装选项之类的因素。当编译着色器时可以解决这种着色计算，在这种情况下，甚至不需要设置统一的着色器输入。或者，可以在安装时或在加载应用程序时在离线预计算过程中执行这种计算。

​		另一种情况是，着色计算的结果在整个应用程序运行中发生变化，但是变化速度如此之慢以至于不需要在每一帧进行更新。例如，光照因素取决于虚拟游戏世界中的一天中的时间。如果计算成本很高，则需要在多个帧上进行摊销。

​		其他情况包括每帧执行一次的计算，例如合并视图和透视矩阵。或每个模型一次，例如根据位置更新模型照明参数；或每次绘图调用一次，例如，更新模型中每种材质的参数。通过评估频率将统一的着色器输入分组有助于提高应用程序的效率，并且还可以通过最大程度地减少持续更新来提高GPU性能[1165]。

​		如果着色计算的结果在一次绘制调用中发生更改，则无法通过统一的着色器输入将其传递给着色器。取而代之的是，它必须由第3章中描述的可编程着色器阶段之一进行计算，并在需要时通过更改着色器输入传递到其他阶段。从理论上讲，可以在任何可编程阶段执行着色计算，每个阶段对应于不同的评估频率：

  * 顶点着色器——每个曲面细分顶点之前评估
  * 外壳着色器——评估每个表面的面片
  * 域着色器——每个曲面细分顶点之后评估
  * 几何着色器——每个图元评估
  * 像素着色器——每个像素评估

​		实际上，大多数着色计算是针对每个像素执行的。尽管这些通常是在像素着色器中实现的，但计算着色器的实现却越来越普遍。第20章将讨论几个示例。其他阶段主要用于几何运算，例如变换和变形。为了理解为什么会这样，我们将比较每个顶点和每个像素着色评估的结果。在较早的文本中，有时有时将它们分别称为Gouraud着色[578]和Phong着色[1414]，尽管这些术语在今天并不常用。该比较使用的着色模型与公式5.1中的阴影模型有些相似，但经过修改可与多个光源一起使用。完整的模型将在稍后我们详细介绍示例实现时给出。

​		图5.9显示了在具有大量顶点密度的模型上按像素和按顶点着色的结果。对于龙来说，这是一个非常致密的网格，两者之间的差异很小。但是在茶壶上，顶点着色评估会导致可见的错误，例如成角度的高光，而在两个三角形平面上，顶点着色版本显然是不正确的。这些错误的原因是，着色方程的各个部分（尤其是高光）的值在网格表面上非线性地变化。这使得它们不适合顶点着色器，其结果在被馈送到像素着色器之前在三角形上线性插值。

![image-20191201233655017](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233655017.png)

​		<font size=2>图5.9。比较公式5.19中示例阴影模型的每个像素和每个顶点的评估结果的比较，显示在顶点密度不同的三个模型上。左列显示每个像素的评估结果，中间列显示每个顶点的评估，右列显示每个模型的线框渲染以显示顶点密度。 （来自计算机图形档案[1172]的中国龙网格，来自斯坦福3D扫描存储库的原始模型。）</font>

​		原则上，仅计算着色模型的镜面反射的高光部分是可能的在像素着色器中，并在顶点着色器中计算其余部分。这可能不会导致视觉误差，并且理论上将节省一些计算。实际上，这种混合实现通常不是最佳的。着色模型的线性变化部分往往在计算上花费最少，并且以这种方式拆分着色计算往往会增加一定的开销（例如重复计算和其他变化的输入），从而弊大于利。
​		如前所述，在大多数实现中，顶点着色器负责非着色操作，例如几何变换和变形。生成的几何表面属性（转换为适当的坐标系）由顶点着色器写入，在三角形上线性插值，并作为变化的着色器输入传递到像素着色器中。这些属性通常包括曲面的位置，曲面法线以及（如果需要）法线贴图，还可以包括曲面切线向量。
​		请注意，即使顶点着色器始终生成单位长度的表面法线，插值也可以更改其长度。参见图5.10的左侧。因此，需要在像素着色器中对法线进行重新归一化（缩放为长度1）。但是，顶点着色器生成的法线的长度仍然很重要。如果法线长度在各个顶点之间变化很大，例如，作为顶点融合的副作用，这将使插值倾斜。这可以在图5.10的右侧看到。由于这两种效果，实现常常在插值之前和之后，即在顶点着色器和像素着色器中，对插值矢量进行归一化。

![image-20191201233711504](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233711504.png)

​		<font size=2>图5.10。在左侧，我们看到单位法线在整个表面上的线性插值会产生长度小于1的插值向量。在右侧，我们看到具有明显不同长度的法线的线性插值导致插值方向偏向两个法线中的较长方向。</font>

​		与表面法线不同，通常不插值指向特定位置的矢量，例如视图矢量和点光源的光线矢量。取而代之的是，使用插值的表面位置来计算像素着色器中的这些向量。除了需要在像素着色器中执行的归一化之外，在任何情况下这些向量中的每一个都是通过向量减法来计算的，这很快。如果出于某种原因有必要对这些向量进行插值，请不要事先对其进行归一化。如图5.11所示，这将导致错误的结果。

![image-20191201233726314](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191201233726314.png)

​		<font size=2>图5.11。两个光向量之间的插值。在左侧，在插值前对其进行归一化会导致插值后方向不正确。在右侧，对未归一化的向量进行插值可得出正确的结果。</font>

​		前面我们提到顶点着色器将表面几何形状转换为“适当的坐标系”。通过统一变量传递到像素着色器的相机和灯光位置通常由应用程序转换为相同的坐标系。这样可以最大程度地减少像素着色器将所有阴影模型矢量带入相同坐标空间的工作。但是，哪个协调系统是“适当的”系统？可能性包括全局世界空间以及相机的局部坐标系，或者更罕见的是当前渲染模型的局部坐标系。通常根据系统性能（例如性能，灵活性和简单性）为整个渲染系统做出选择。例如，如果预计渲染的场景将包含大量灯光，则可以选择世界空间以避免变换灯光位置。或者，最好使用摄像机空间，以更好地优化与视图矢量有关的像素着色器操作，并可能提高精度（第16.6节）。

​		尽管大多数着色器实现（包括我们将要讨论的示例实现）都遵循上述一般概述，但当然也有例外。例如，某些应用出于风格原因选择了原始着色评估的多面外观。这种样式通常称为平面着色。图5.12中显示了两个示例。

![image-20191216224545211](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224545211.png)

​		<font size=2>图5.12。 有两种使用平面阴影作为样式选择的游戏：肯塔基州零号路线（顶部）和巨龙（巨蟹座），底部。 （上部图片由Cardboard Computer提供，下部图片由Numinous Games提供。）</font>>

​		原则上，可以在几何着色器中执行平面着色，但是最近的实现通常使用顶点着色器。这是通过将每个图元的属性与其第一个顶点相关联并禁用顶点值插值来完成的。禁用插值（可以分别为每个顶点值完成）将导致第一个顶点的值传递到图元中的所有像素。

#### 5.3.2实现样例
​		现在，我们将提供一个实现着色模型的示例。 如前所述，我们正在实现的着色模型与从公式5.1中扩展的Gooch模型相似，但修改可与多个光源一起使用。 它由以下描述
$$
\mathbf{c}_{shaded}=\frac{1}{2}\mathbf{c}_{cool}+\sum^n_{i=1}(\mathbf{l}_i\cdot\mathbf{n})^+\mathbf{c}{light}_i(s_i\mathbf{c}_{hightlight}+(1-s_i)\mathbf{c}_{warm}),
\qquad\qquad(5.19)
$$
​		中间值由以下计算：
$$
\begin{align}
\mathbf{c}_{cool}&=(0,0,0.55)+0.25\mathbf{c}_{surface},\\
\mathbf{c}_{warm}&=(0.3,0.3,0)+0.25\mathbf{c}_{surface},\\
\mathbf{c}_{hightlight}&=(2,2,2),\\
\mathbf{r}_{i}&=2(\mathbf{n}\cdot\mathbf{l}_i)\mathbf{n}-\mathbf{l}_i,\\
s_i&=(100(\mathbf{r}_i\cdot\mathbf{v})-97)^\mp.\\
\end{align}
\qquad\qquad(5.20)
$$
​		该公式适合公式5.6中的多光源结构，为方便起见，在此重复：
$$
\mathbf{c}_{shaded}=f_{unlit}(\mathbf{n},\mathbf{v})+\sum^n_{i=1}(\mathbf{l}_i\cdot\mathbf{n})^+\mathbf{c}{light}_i f_{lit}(\mathbf{l}_i,\mathbf{n},\mathbf{v}).
$$
​		在这种情况下，照亮和不照亮项的是
$$
\begin{align}
f_{unlit}(\mathbf{n},\mathbf{v})&=\frac{1}{2}\mathbf{c}_{\text{cool}},\\
f_{lit}(\mathbf{l}_i,\mathbf{n},\mathbf{v})&=s_i\mathbf{c}_{hightlight}+(1-s_i)\mathbf{c}_{warm},
\end{align}
\qquad\qquad(5.21)
$$
​		调整冷色项的不亮贡献，使结果看起来更像原始方程式。

​		在大多数典型的渲染应用程序中，诸如$\mathbf{c}_{surface}$之类的材质属性的变化值将存储在顶点数据中，或更常见的是存储在纹理中（第6章）。 但是，为使此实现示例简单，我们将假设$\mathbf{c}_{surface}$在整个模型中是恒定的。

​		此实现将使用着色器的动态分支功能遍历所有光源。虽然这种简单的方法可以在相当简单的场景中很好地使用，但对于具有许多光源的大型且复杂的几何场景却无法很好地缩放。第20章将介绍有效处理大量光源的渲染技术。此外，为了简单起见，我们将仅支持一种光源：点光源。尽管实现非常简单，但是它是前面介绍的最佳实践。

​		着色模型不是孤立实现的，而是在更大的渲染框架中实现的。这个例子是在一个简单的WebGL 2应用程序中实现的，该应用程序由Tarek Sherif [1623]的“ Phong-shaded Cube” WebGL 2示例进行了修改，但是相同的原理也适用于更复杂的框架。

​		我们将讨论来自应用程序的GLSL着色器代码和JavaScript WebGL调用的一些示例。目的不是讲授WebGL API的细节，而是展示普遍的实现原理。我们将以“由内而外”的顺序进行实现，首先是像素着色器，然后是顶点着色器，最后是应用程序方向的图形API调用。

​		在着色器代码完全之前，着色器源包括着色器输入和输出的定义。 如第3.3节中所述，使用GLSL术语，着色器输入分为两类。 其中之一是一组统一的输入，这些输入值由应用程序设置并且在绘制调用中保持不变。 另一种类型由变化的输入组成，这些输入值可以在着色器调用（像素或顶点）之间改变。 在这里，我们看到像素着色器的各种输入（在GLSL中被标记）及其输出的定义：

```GLSL
in vec3 vPos;
in vec3 vNormal;
out vec4 outColor;
```

​		此像素着色器具有单个输出，即最终的着色颜色。 像素着色器输入与顶点着色器输出匹配，顶点着色器输出在送到像素着色器之前由三角形上进行插值。 该像素着色器具有两个不同的输入：表面位置和表面法线，两者都在应用程序的世界空间坐标系中。统一输入的数量要大得多，因此，为了简便起见，我们仅显示两个定义，这两者均与光源有关：

```GLSL
struct Light {
  vec4 position;
  vec4 color;
 };
uniform LightUBlock {
  Light uLights[MAXLIGHTS];
};
uniform uint uLightCount;
```

​		由于这些是点光源，因此每个光源的定义都包括一个位置和一个颜色。 为了符合GLSL std140数据设计标准的限制，将它们定义为vec4而不是vec3。 尽管在这种情况下std140布局可能会导致一些空间的浪费，但它简化了确保CPU和GPU之间的数据设计一致的任务，这就是我们在此示例中使用它的原因。 Light结构体数组是在一个统一块内定义的，该块是GLSL功能，用于将一组统一变量绑定到缓冲区对象，以加快数据传输速度。 数组长度定义为等于应用程序在单个绘制调用中允许的最大灯光数量。 稍后我们将看到，应用程序在编译着色器之前将着色器源中的MAXLIGHTS字符串替换为正确的值（本例中为10）。 统一整型uLightCount是绘制调用中的实际处于激活状态的灯光数。
​		接下来，我们将看一下像素着色器代码：

```GLSL
vec3 lit(vec3 l, vec3 n, vec3 v) {
	vec3 r_l = reflect(-l, n);
	float s = clamp(100.0 * dot(r_l, v) - 97.0, 0.0, 1.0);
	vec3 highlightColor = vec3(2,2,2);
	return mix(uWarmColor , highlightColor , s);
}
void main () {
	vec3 n = normalize(vNormal);
	vec3 v = normalize(uEyePosition.xyz - vPos);
	outColor = vec4(uFUnlit , 1.0);
	for (uint i = 0u; i < uLightCount; i++) {
  		vec3 l = normalize(uLights[i].position.xyz - vPos);
    	float NdL = clamp(dot(n, l), 0.0, 1.0);
  		outColor.rgb += NdL * uLights[i].color.rgb * lit(l,n,v);
  }
}
```


​		我们有一个关于照亮项的函数定义，它由main（）函数调用。总的来说，这是方程式5.20和5.21的简单GLSL实现。请注意，$f_{unlit}()$和$\mathbf{c}_{warm}$的值作为统一变量传入。由于这些值在整个绘制调用中是恒定的，因此应用程序可以计算这些值，从而节省了一些GPU周期。

​		该像素着色器使用了几个内置的GLSL函数。 reflect（）函数反射一个向量（在此情况下为光向量）在第二个向量（在这种情况下是表面法线）定义的平面上。由于我们希望光向量和反射向量都指向远离表面的位置，因此我们需要将前者传递给reflect（）之前对其取反。 clamp（）函数具有三个输入。其中两个限制了第三个输入的范围。在大多数GPU上，到0到1（与HLSL saturate（）函数相对应）之间的范围的夹取是快速的，通常有高效的释放。这就是为什么我们在这里使用它的原因，尽管我们只需要将值限制到0（因为我们知道它不会超过1）。函数mix（）也具有三个输入，并在两个输入之间线性插值，即暖色和高光颜色在这种情况下，取决第三个值（介于0和1之间的混合参数）。在HLSL中，此函数称为lerp（），用于“线性插值”。最后，normalize（）将向量除以其长度，将其长度缩放到1。

​		现在让我们看一下顶点着色器。由于我们已经看到了像素着色器的一些统一定义（uniform definitions）示例，因此我们将不显示其任何统一定义，但是变化的输入和输出定义值得研究：

```GLSL
layout(location=0) in vec4 position;
layout(location=1) in vec4 normal;
out vec3 vPos;
out vec3 vNormal;
```

​		请注意，如前所述，顶点着色器输出与像素着色器变化的输入匹配。 输入包含指令，这些指令指定如何在顶点数组中排列数据。 接下来是顶点着色器代码：

```GLSL
void main () {
	vec4 worldPosition = uModel * position;
	vPos = worldPosition.xyz;
	vNormal = (uModel * normal).xyz;
	gl_Position = viewProj * worldPosition;
}
```

​		这些是顶点着色器的常用操作。着色器将表面位置和法线转换为世界空间，并将它们传递给像素着色器以用于着色。最后，将表面位置转换为裁剪空间，并将其传递给gl_position，这是是光栅器使用的特殊系统定义的变量。 gl_position变量是任何顶点着色器的必需输出。

​		请注意，法线向量未在顶点着色器中归一化。由于它们在原始网格数据中的长度为1，因此不需要进行归一化，并且此应用程序不会执行任何可能会不均匀改变其长度的操作，例如顶点混合或不均匀缩放。模型矩阵可以具有统一的缩放因子，但是会成比例地改变所有法线的长度，因此不会导致图5.10右侧所示的问题。

​		该应用程序使用WebGL API进行各种渲染和着色器设置。每个可编程着色器阶段都是单独设置的，然后将它们都绑定到一个程序对象。这是像素着色器设置代码：

```GLSL
var fSource = document.getElementById("fragment").text.trim();

var maxLights = 10;
fSource = fSource.replace(/MAXLIGHTS/g, maxLights.toString());

var fragmentShader = gl.createShader(gl.FRAGMENT_SHADER); gl.shaderSource(fragmentShader , fSource);
gl.compileShader(fragmentShader);
```

​		请注意“片段着色器”参考。 WebGL（以及它所基于的OpenGL）使用此术语。如本书前面所述，尽管“像素着色器”在某些方面不那么明确，但它是更常见的用法，我们在本书中将继续进行。该代码也是将MAXLIGHTS字符串替换为适当的数值的地方。大多数渲染框架执行类似的预编译着色器操作。

​		还有更多的应用程序端代码用于设置统一，初始化顶点数组，清除，绘制等，您可以在程序[1623]中查看这些代码，并且许多API指南对此进行了说明。我们的目标是理解着色器如何被视为单独的处理器在它们自身的编程环境下。因此，我们现在结束本示例。

#### 5.3.3材质系统

​		就像我们的简单示例一样，渲染框架很少只实现一个着色器。 通常，需要一个专用系统来处理应用程序使用的各种材质，着色模型和着色器。

​		如前几章所述，着色器是GPU的可编程着色器阶段之一的程序。 因此，它是低级图形API资源，而不是美工可以直接与其交互的东西。 相反，材质是面向美工的平面视觉外观的封装。 材质有时还会描述非视觉方面，例如碰撞属性，由于它们不在本书的讨论范围之内，因此我们将不对其进行进一步讨论。

​		虽然材质是通过着色器实现的，但这并不是简单的一对一对应。在不同的渲染情况下，相同的材质可能使用不同的着色器。一个着色器也可以由多种材质共享。最常见的情况是参数化材质。以最简单的形式，材质参数化需要两种类型的材质实体：材质模板和材质实例。每个材质模板都描述了一类材质，并具有一组参数，可以根据参数类型为它们分配数字，颜色或纹理值。每个物料实例都对应一个材质模板，外加其所有参数的一组特定值。诸如Unreal Engine [1802]之类的某些渲染框架允许使用更复杂的层次结构，其中材质模板是从多个级别的其他模板派生的。

​		可以在运行时通过将统一的输入传递给着色器程序来解析参数，也可以在编译时通过在着色器被编译之前替换值来解析参数。一种常见的编译时参数类型是布尔型，它控制给定材质的特征是否激活。这可以由美工人员通过材质用户界面中的复选框设置，也可以由材质系统程序设置，例如，可忽略的远处物体的视觉效果以减低着色器开销。

​		尽管材质的参数可能与着色模型中参数一一对应，但并非总是如此。一个材质可以将给定着色模型参数的值（例如表面颜色）固定为恒定值。或者，一个着色模型的参数被计算作为一系列复杂的操作（将多个材质参数以及经过插值的顶点或纹理值作为输入）。在某些情况下，诸如平面位置，平面方向甚至时间之类的参数也可能会影响计算。基于表面位置和方向的着色在地形材质中尤其常见。例如，高度和表面法线可用于控制降雪效果，在高海拔几乎水平的表面上和白色表面颜色混合。基于时间的着色在动画材质中很常见，例如闪烁的霓虹灯。

​		材质系统最重要的任务之一是将各种着色器功能划分为单独的元素，并控制这些元素的组合方式。在许多情况下，这种类型的组合很有用，包括以下几种：

* 使用几何处理（例如，刚体变换，顶点混合，渐变，曲面细分，实例化和裁剪）来构成表面着色。 这些功能各不相同：表面着色取决于材质，几何处理取决于网格。 因此，分别编写它们并让材质系统根据需要进行组合很方便。

* 使用诸如像素丢弃和混合之类的合成操作来构成表面着色。 这与移动GPU尤其相关，在移动GPU中，混合通常是在像素着色器中执行的。 通常希望选择让这些操作独立于材质来用于表面着色。

* 将用于计算着色模型参数的操作与着色模型本身的计算组合在一起。 这允许只编写一次着色模型实现，然后将其与各种不同方法结合使用来用于计算阴影模型参数。

* 互相组合单个可选的材质特征，选择逻辑和着色器的其余部分。 这样可以分别编写每个功能的实现。

* 构成着色模型并通过光源评估计算其参数：计算每个光源在着色点的$\mathbf{c}_{light}$和$l$值。 延迟渲染（在第20章中讨论）等技术会更改此构成的结构。 在支持多种此类技术的渲染框架中，这增加了一层额外的复杂性。

​		如果图形API提供这种类型的着色器代码模块作为核心功能，将会很方便。可悲的是，与CPU代码不同，GPU着色器不允许对代码片段进行编译后链接。每个着色器阶段的程序都作为一个单元编译。着色器阶段之间的分隔确实提供了一些有限的模块化，这在某种程度上匹配我们列表中的第一项：通过几何处理（通常在其他着色器阶段中执行）来构成表面着色（通常在像素着色器中执行）。但是这种匹配并不完美，因为每个着色器也执行其他操作，并且仍然需要处理其他类型的组合。考虑到这些限制，材质系统可以实现所有这些类型的合成的唯一方法是在源代码级别。这主要涉及字符串操作，例如连接和替换，通常通过C风格的预处理指令（例如＃include，＃if和#define）执行。

​		早期的渲染系统具有相对较少的着色器变量，并且通常每个都是手动编写的。这有一些好处。例如，可以在完全了解最终着色器程序的情况下优化每个变量。但是，随着变量数量的增加，这种方法很快变得不切实际。当考虑到所有不同的部分和选项时，可能存在的不同着色器变量数量很多。这就是为什么模块化和可组合性如此重要的原因。

​		设计用于处理着色器变量的系统时要解决的第一个问题是，是在运行时通过动态分支还是在编译时通过条件预处理在不同选项之间进行选择。在较旧的硬件上，动态分支通常是不可能或非常缓慢的，因此，运行时选择不是一个选择。然后所有变量都在编译时进行处理，包括对不同光源类型数量的所有可能组合[1193]。

​		相反，当前的GPU可以很好地处理动态分支，尤其是在一次绘制调用中所有像素的分支行为相同时。 如今，许多功能变量（例如灯光数量）都在运行时处理。 但是，向着色器添加大量功能变量会产生不同的成本：寄存器数量的增加和占用率的相应降低，进而导致性能降低。有关更多详细信息，请参见第18.4.5节。 因此，编译时变量仍然很有价值。 它避免包含永远不会执行的复杂逻辑。

​		例如，让我们想象一个支持三种不同类型灯光的应用程序。两种光源类型很简单：点光源和平行光源。第三种是支持列表照明模式和其他复杂功能的通用聚光灯，需要大量的着色器代码才能实现。但是，比方说，通用聚光灯很少使用，在应用程序中只有不到5％的灯是这种类型的。过去，将为三种灯源类型的数量的每种可能组合编译成单独的着色器变量，以避免动态分支。尽管今天并不需要，但是编译两个单独的变量仍然是有益的，一个变量适用于通用聚光灯的数量等于或大于1的情况，而另一个变量适用于此类聚光灯的数量恰好等于0的情况。由于其代码更简单，因此第二种变量（最常用）可能具有较低的寄存器占用率，从而具有更高的性能。

​		现代材质系统同时使用了运行时着色器变量和编译时着色器变量。即使不再只在编译时处理全部负担，但总体复杂性和变量数量仍在增加，因此仍需要编译大量着色器变量。例如，在《命运：被占领的国王》游戏的某些区域中，在单个帧中使用了9000多种编译的着色器变量[1750]。可能的变量数量可能会更大，例如，Unity渲染系统的着色器具有接近1000亿个可能的变量。仅编译实际使用的变量，但是必须重新设计着色器编译系统以处理大量可能的变量[1439]。

​		材质系统设计师采用不同的策略来解决这些设计目标。尽管有时将它们表示为互斥的系统结构[342]，但这些策略可以（通常是）合并在同一系统中。这些策略包括：

* 代码重用——在共享文件中实现功能，使用#include预处理程序指令访问这些功能从需要它们的任何着色器中。
* 减法——一个着色器，通常称为超级着色器[1170，1784]，使用编译时预处理器条件和动态分支的组合来聚集大量功能，以删除未使用的部分并在互斥的选择中切换。
* 加法——各种功能定义为具有输入和输出连接器的节点，并将它们组合在一起。这类似于代码重用策略，但结构更清晰。节点的组成可以通过文本[342]或可视图形编辑器完成。后者旨在使非工程师（例如技术美术）更容易编写新的材质模板[1750，1802]。通常，可视化图形创作只能访问着色器的一部分。例如，在虚幻引擎中，图形编辑器只能影响着色模型输入的计算[1802]。参见图5.13。
* 基于模板——定义了一个接口，只要符合该接口，就可以插入不同的实现。 这比加法策略更为正式，通常用于较大的功能块。 这种接口的一个常见示例是遮光模型参数的计算与遮光模型本身的计算之间的分离。 虚幻引擎[1802]具有不同的“材质域”，其中包括用于计算着色模型参数的表面域和用于计算对给定光源调制$\mathbf{c}_{light}$的标量值的光函数域。 Unity [1437]中也存在类似的“表面着色器”结构。 注意，延迟着色技术（在第20章中讨论过）采用G缓冲区作为接口，实现了类似的结构。

​		![image-20191216224645030](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224645030.png)

​		<font size=2>图5.13。 虚幻引擎材质编辑器。 注意节点图右侧的高节点。 该节点的输入连接器对应于渲染引擎使用的各种着色输入，包括所有着色模型参数。 （材质样本由Epic Games提供。）</font>

​		对于更特殊的示例，（现在免费的）WebGL Insights [301]一书中的几章讨论了各种引擎如何控制其着色器管线。 除了组合之外，现代材质系统还有其他一些重要的设计注意事项，例如需要以最少的着色器代码重复来支持多个平台。 这包括功能上的变化，以解决平台，着色语言和API之间的性能和功能差异。 Des-tiny着色器系统[1750]是此类问题的一种代表性解决方案。 它使用专有的预处理器层，该层接受着色语言编写的着色器。 这允许编写与平台无关的材质，并自动翻译成不同的着色语言和实现。 虚幻引擎[1802]和Unity [1436]具有相似的系统。

​		材质系统还需要确保良好的性能。除了对着色变体进行专门编译外，材质系统还可以执行其他一些常见的优化。 Destiny着色器系统和虚幻引擎会自动检测在一次绘制调用中保持不变的计算（例如，较早实现示例中的暖色和冷色计算）并将其移到着色器之外。另一个示例是Destiny中使用的范围界定系统，以区分以不同频率更新的常量（例如，每帧一次，每个灯光一次，每个对象一次）并在适当的时间更新每组常量以减少API开销。

​		如我们所见，实现着色方程是决定可以简化哪些部分，各种表达式的计算频率以及用户如何修改和控制外观的问题。渲染管道的最终输出是颜色和混合值。剩余章节有关抗锯齿，透明度和图像展示细节介绍了如何组合和修改这些值以进行显示。

### 5.4走样和反走样

​		想象一个大的黑色三角形在白色背景上缓慢移动。由于屏幕网格单元被三角形覆盖，该单元表示的像素值强度应平稳下降。通常发生在各种基本渲染器中的情况是，一旦网格单元的中心被覆盖，像素颜色就会立即从白色变为黑色。标准GPU渲染也不例外。参见图5.14的最左列。![image-20191216224722203](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224722203.png)

​		<font size=2>图5.14。 上排显示了具有不同反走样级别的三幅图像，它们分别具有三角形，直线和一些点。 下排图像是上排的放大。 最左列的图像每个像素仅使用一个样本，这意味着不使用反走样。 中间列图像每个像素四个样本（以网格模式）渲染，而右列的每个像素使用八个样本（在4×4棋盘中，一半的正方形被采样）。</font>

​		无论三角形在那里或不在那里，三角形都显示在像素中。画出的线段有类似的问题。因为边的边缘呈锯齿状，因此这种视觉现象称为“锯齿”，经过动画处理后会变成“爬虫”。更正式地说，此问题称为走样（图形失真），而为避免该问题所做的努力称为反走样技术。

​		采样原理和数字滤波的主题足够大，足以填满自己的书[559，1447，1729]。但这是渲染的关键领域，因此将介绍采样和过滤的基本原理。然后，我们将专注于当前可以实时完成的工作，以减轻走样。

#### 5.4.1采样与滤波原理

​		渲染图像的过程本质上是一个采样任务。之所以如此，是因为图像的生成是对三维场景进行采样的过程，以便获得图像中每个像素（离散像素的数组）的颜色值。要使用纹理映射（第6章），必须对纹理像素（不是像素）进行重采样才能在不同条件下获得良好的效果。为了在动画中生成图像序列，通常以统一的时间间隔对动画进行采样。本节介绍采样，重构和过滤的主题。为简单起见，大多数材质将以一维显示。这些概念也可以自然扩展到二维，因此可以在处理二维图像时使用。

​		图5.15显示了如何以均匀空间间隔对连续信号进行采样，即离散化。该采样过程的目标是

![image-20191216224807229](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224807229.png)

​		<font size=2>图5.15。 对连续信号（左）进行采样（中），然后通过重建恢复原始信号（右）。</font>

​		以数字方式表示信息。这样做可以减少信息量。但是，采样信号需要被重构用于恢复原始信号。这是通过对采样信号进行滤波来完成的。

​		无论何时采样，都可能发生走样。这是不想要的现象，我们需要对抗走样才能生成满意的图像。在古老的西方人看来，走样的一个典型例子是由电影摄影机拍摄的旋转的纺车轮。因为旋转带的移动速度比摄像机录制图像的速度快得多，所以轮子似乎在缓慢旋转（向后或向前），甚至看起来根本没有旋转。如图5.16所示。之所以会出现这种效果，是因为车轮的图像是按照一系列时间步长拍摄的，被称为时间走样。

![image-20191216224828768](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224828768.png)

​		<font size=2>图5.16。 第一行显示了一个纺车（原始信号）。 在第二行中采样不适当，使其看起来朝相反的方向移动。 这是由于采样率太低而造成走样的示例。 在第三行中，采样率正好是每转两个采样，因此我们无法确定轮子朝哪个方向旋转。 这是奈奎斯特极限。 在第四行中，采样率高于每转两个样本，我们突然可以看到轮子朝着正确的方向旋转。</font>

​		计算机图形中常见的走样示例是光栅化线或三角形边缘的“锯齿”，诸如“萤火虫”一样闪烁的高光，细化具有方格图案的纹理时（第6.2.2节）。

​		当信号以太低的频率采样时，会发生走样。这样，被采样的信号然后呈现为频率低于原始信号的信号。如图5.17所示。为了正确地采样信号（即，可以从采样中重建原始信号），采样频率必须大于要采样的信号的最大频率的两倍。这通常被称为采样定理，采样频率被称为奈奎斯特速率[1447]或奈奎斯特极限，此后是1928年瑞典科学家哈里·奈奎斯特（1889–1976）发现的。奈奎斯特极限也如图 5.16所示。该定理使用术语“最大频率”意味着该信号必须受到带宽限制，这仅意味着没有任何高于特定限制的频率。换句话说，信号必须足够平滑相对于相邻样本之间的间隔

![image-20191216224847933](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224847933.png)

​		<font size=2>图5.17。 蓝色实线是原始信号，红色圆圈表示均匀间隔的采样点，绿色虚线是重构的信号。 上图显示了太低的采样率。 因此，重建的信号似乎具有较低的频率，即原始信号的走样。 下图显示的采样率恰好是原始信号频率的两倍，而此处重构的信号是一条水平线。 可以证明，如果采样率稍稍增加，则可以实现完美的重构。</font>

​		三维场景通常从不限制带宽在使用点样本进行渲染时。 三角形的边缘，阴影边界和其他现象会产生不连续变化的信号，因此会产生无限的频率[252]。 同样，无论样本有多紧密，对象仍然可以足够小以至于根本无法进行采样。 因此，在使用点样本渲染场景时无法完全避免走样问题，但我们几乎总是使用点采样。 但是，有时可能会知道信号何时受到带宽限制。 一个示例是将纹理应用于表面时。 与像素的采样率相比，可以计算纹理采样的频率。 如果此频率低于奈奎斯特极限，则无需采取特殊措施即可正确采样纹理。 如果频率太高，则可以使用多种算法对纹理进行带宽限制（第6.2.2节）。

<font color=#ff7200>重建</font>

​		给定一个带宽限制的采样信号，我们现在将讨论如何从采样信号中重建原始信号。 为此，必须使用滤波器。 图5.18显示了三个常用的滤波器。 请注意，滤波器的面积应始终为1，否则重建的信号可能看起来会增大或缩小。

![image-20191216224916912](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224916912.png)

​		<font size=2>图5.18。 左上方显示盒式过滤器，右上方显示帐篷式过滤器。 底部显示了一个Sinc滤波器（已在此处固定在x轴上）。</font>

​		在图5.19中，盒式滤波器（最近邻居）用于重建采样信号。 这是最差的滤波器，因为产生的信号是不连续的阶梯状。 尽管如此，由于其简单性，它仍经常用于计算机图形学。 从图中可以看出，盒式滤波器放置在每个采样点上，然后进行缩放，以使滤波器的最高点与采样点重合。 这些经过缩放和转换后的框函数总和是右图所示的重构信号。

![image-20191216224932871](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224932871.png)

​		<font size=2>图5.19。 使用盒式滤波器重建采样信号（左）。 这是通过将盒式滤波器放置在每个采样点上，并在y方向上缩放使滤波器的高度与采样点相同来完成的。 其总和是重建信号（右）。</font>

​		盒式过滤器可以被任何其他过滤器替代。 在图5.20中，帐篷滤波器（也称为三角滤波器）用于重建采样信号。 请注意，此滤波器在相邻采样点之间实现线性插值，因此它比盒式滤波器更好，因为现在重建的信号是连续的。

![image-20191216224947854](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216224947854.png)

​		<font size=2>图5.20。 使用帐篷滤波器重建采样信号（左）。 重建的信号显示在右侧。</font>

但是，使用帐篷滤波器重构的信号的平滑度差。 采样点的坡度会突然变化。 帐篷滤波器不是理想的重建过波器。 为了获得完美的重构，必须使用理想的低通滤波器。 信号的频率分量是正弦波：$\sin（2\pi f）$，其中$f$是该分量的频率。 鉴于此，低通滤波器将去除频率高于滤波器定义的某个频率的所有频率分量。 直观地讲，低通滤波器消除了信号的尖锐特征，即滤波器使信号模糊。 理想的低通滤波器是Sinc滤波器（图5.18底部）：
$$
sinc(x)=\frac{\sin(\pi x)}{\pi x}.
\qquad\qquad(5.22)
$$

​		傅立叶分析[1447]的理论解释了为什么Sinc滤波器是理想的低通滤波器。简要地，推理如下。理想的低通滤波器是频域中的盒式滤波器，当与信号相乘时，它会去除超过滤波器宽度以上的所有频率。将盒式滤波器从频域转换为空间域可得到Sinc函数。同时，乘法运算被转换为卷积函数，这是我们在本节中一直使用的函数，而没有实际描述该术语。
​		使用sinc滤波器重构信号可获得更平滑的结果，如图5.21所示。采样过程在信号中引入了高频成分（突变），低通滤波器的任务是消除这些成分。实际上，sinc滤波器消除了所有频率高于采样率1/2的正弦波。当采样频率为1.0（即采样信号的最大频率必须小于1/2）时，sinc函数是理想的重构滤波器，如方程式5.22所示。更一般地，假设采样频率为$f_s$，即，相邻样本之间的间隔为$1 / f_s$。在这种情况下，理想的重建滤波器是$sinc（f_sx）$，它消除了所有高于$f_s / 2$的频率。重采样信号时，这很有用（下一部分）。但是，sinc的滤波器宽度是无限的，并且在某些区域为负，因此在实践中很少有用。

![image-20191216225028849](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225028849.png)

​		<font size=2>图5.21。 在这里，sinc滤波器用于重建信号。 sinc滤波器是理想的低通滤波器。</font>

​		一方面，在低质量的盒式和帐篷滤波器之间存在有用的中间地带，另一方面，和不切实际的Sinc滤波器。最广泛使用的滤波器功能[1214、1289、1413、1793]介于这些极端之间。所有这些滤波器函数都与sinc函数近似，但是对它们影响多少像素有限制。与sinc函数最接近的滤波器在其部分域中具有负值。对于应用程序来说负的滤波器值是不被希望或不现实的，通常使用无负波的滤波器（通常称为高斯滤波器，因为它们要么源自高斯曲线，要么类似于高斯曲线）[1402]。第12.1节详细讨论了过滤器功能及其使用。
​		使用任何滤波器后，都会获得连续信号。但是，在计算机图形学中，我们不能直接显示连续信号，但可以使用它们将连续信号重新采样为另一种尺寸，即放大或缩小信号。接下来讨论这个主题。

<font color=ff7200>重采样</font>


​		重采样用于放大或缩小采样信号。假设原始样本点位于整数坐标（0、1、2，...），即样本之间的单位间隔。此外，假设在重新采样后，我们希望新采样点均匀地放置在间隔a之间。对于a> 1，将发生缩小（下采样），对于a<1，将发生放大（上采样）。

​		放大倍数是两者中最简单的情况，因此让我们从此开始。假设如上一节中所示重构了采样信号。凭直觉，由于现在信号已被完美地重建并且是连续的，因此所需要做的只是以所需的间隔对重建的信号进行重新采样。这个过程可以在图5.22中看到。

![image-20191216225050715](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225050715.png)

​		<font size=2>图5.22。 左侧是采样信号和重构信号。 在右侧，用两倍的采样率对重构的信号进行了重新采样，即发生放大</font>

​		但是，发生缩小时，此技术不起作用。原始信号的频率对于采样率来说太高了，以避免混叠。取而代之的是，已经表明应该使用$sinc（x / a）$的滤波器来从被采样的连续信号中创建连续信号[1447，1661]。之后，可以按所需的间隔进行重采样。如图5.23所示。换句话说，通过使用sinc（x / a）作为滤波器，低通滤波器的宽度增加了，从而消除了更多信号的高频成分。如图所示，（单个Sinc的）滤波器宽度翻倍，以将重采样率降低到原始采样率的一半。将其与数字图像相关，这类似于首先对其进行模糊处理（以去除高频），然后以较低的分辨率对图像进行重采样。

![image-20191216225102674](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225102674.png)

​		<font size=2>图5.23。 左侧是采样信号和重构信号。 在右侧，滤波器宽度翻倍，以便使样本之间的间隔加倍，也就是说，已经发生缩小。</font>

​		以采样和过滤理论为框架，现在讨论在实时渲染中用于减少混叠的各种算法。

#### 5.4.2基于屏幕的反走样

​		如果未正确采样和填充，三角形的边缘会产生明显的失真。 阴影边界，镜面高光和其他颜色快速变化的现象可能会导致类似的问题。 本节讨论的算法有助于改善这些情况的渲染质量。 它们具有基于屏幕的通用线程，即它们仅对管道的输出样本进行操作。 没有一种最佳的抗锯齿技术，因为每种技术在质量，捕获清晰细节或其他现象的能力，移动时的外观，内存开销，GPU要求和速度方面都具有不同的优势。

​		在图5.14的黑色三角形示例中，一个问题是低采样率。 在每个像素的网格单元的中心采样一个样本，因此，其中最需要了解的是该单元的中心是否被三角形覆盖。 通过在每个屏幕网格单元中使用更多样本并以某种方式混合它们，可以计算出更好的像素颜色。 如图5.24所示。

![image-20191216225129587](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225129587.png)

​		<font size=2>图5.24。 在左侧，将绘制一个红色三角形，其中一个样本位于像素的中心。 由于三角形不覆盖样本，因此即使像素的大部分被红色三角形覆盖，像素也将是白色的。 在右侧，每个像素使用四个样本，可以看到，其中两个样本被红色三角形覆盖，从而产生了粉红色的像素颜色。</font>

​		基于屏幕的反走样的一般策略是对屏幕使用采样模式，然后对样本进行加权和求和以产生像素颜色$\mathbf{p}$：
$$
\mathbf{p}(x,y)=\sum_{t=1}^{n}w_i\mathbf{c}(i,x,y)
\qquad\qquad(5.23)
$$
​		其中，n为在一个像素中采集的样本数。函数$\mathbf{c}（i，x，y）$是样本颜色，而$w_i$是在[0，1]范围内的权重，样本将对整个像素颜色有所贡献。根据序列$1，...，n$中的样本来获取样本位置，并且该函数还可以选择性使用像素位置（x，y）的整数部分。换句话说，对于每个样本而言，在屏幕网格上获取样本的位置是不同的，并且可选地让采样模式可以随像素而变化。样本通常是实时渲染系统（和大多数其他渲染系统）中的点样本。因此，可以将函数$\mathbf{c}$视为两个函数。首先，函数$\mathbf{f}（i，n）$检索屏幕上需要样本的浮点$（x_f，y_f）$位置。然后对屏幕上的该位置进行采样，即，检索该精确点处的颜色。选择采样方案，并且将渲染管线配置为通常基于每帧（或每个应用程序）来计算特定子像素位置的采样。

​		反走样的另一个变量是$w_i$，即每个样本的权重。 这些权重总和为一。 实时渲染系统中使用的大多数方法都为它们的样本赋予统一的权重，即$w_i$ = 1。 图形硬件的默认模式是在像素中心采集单个样本n，这是上面的反走样方程式的最简单情况。 只有一个项，该项的权重为一，采样函数f始终返回被采样像素的中心。

​		每个像素计算一个以上完整样本的反走样算法称为超级采样（或过采样）方法。从概念上讲，最简单的全场景反走样（FSAA）也称为“超采样抗锯齿”（SSAA），它以较高的分辨率渲染场景，然后过滤相邻的样本以创建图像。例如，假设需要1280×1024像素的图像。如果在屏幕外渲染2560×2048的图像，然后对屏幕上每个2×2像素区域求平均，则将生成所需图像，每个像素具有四个样本，并使用盒式滤镜进行过滤。请注意，这对应于图5.25中的2×2网格采样。这种方法的成本很高，因为所有子样本都必须完全着色并填充，每个样本具有z缓冲区深度。 FSAA的主要优势是简单。此方法的其他较低质量版本仅在一个屏幕轴上以两倍的速率采样，因此称为1×2或2×1超级采样。通常，为简化起见，使用二的幂次方分辨率和盒式滤波器。 NVIDIA的动态超分辨率功能是超级采样的一种更精细的形式，其中场景以更高的分辨率渲染，并使用13个样本的高斯滤镜生成显示的图像[1848]。

![image-20191216225218009](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225218009.png)

​		<font size=2>图5.25。 一些像素采样方案的比较，范围从每个像素的最少到最多样本。 Quincunx共享边角样本并对其中心样本进行加权，以使其值达到像素最终颜色的一半。 2×2旋转网格比2×2直形网格在几乎水平的边缘捕获更多的灰阶。 类似地，尽管使用的样本较少，但8 rooks模式却比4×4 grid捕获了更多的此类近乎水平线的灰阶。</font>

​		一种与超级采样有关的采样方法是基于累积缓冲区的概念[637，1115]。代替一个大的屏幕外缓冲区，此方法使用的缓冲区具有与所需图像相同的分辨率，但每个颜色通道具有更多bits。为了获得2×2的场景采样，将生成四个图像，并根据需要将视图在屏幕的x或y方向上移动半个像素。生成的每个图像均基于网格单元内的不同样本位置。每帧必须重新渲染场景几次并将结果复制到屏幕的额外开销使该算法在实时渲染系统中开销很高。当性能不是很关键时，它对于生成更高质量的图像很有用，因为每个像素可以使用任意位置的任意数量的样本[1679]。累积缓冲区曾经是单独的硬件。 OpenGL API直接支持它，但在3.0版中已弃用。在现代GPU上，可以通过对输出缓冲区使用更高精度的颜色格式，在像素着色器中实现累积缓冲区的概念。

​		当诸如物体边缘，镜面高光和尖锐阴影之类的现象导致颜色突然变化时，需要额外的样本。通常可以使阴影更柔和使高光更平滑以避免走样。可以增加特定对象的大小，例如电线，以确保它们在其长度的每个位置覆盖至少一个像素[1384]。对象边缘的走样仍然是主要的采样问题。可以使用分析方法，其中在渲染过程中检测到对象边缘并考虑它们的影响，但是与仅获取更多样本相比，这些方法通常更昂贵且更不可靠。但是，诸如保守光栅化和光栅器顺序视图之类的GPU功能开辟了新的可能性[327]。

​		诸如超级采样和累积缓冲之类的技术通过生成单独计算的阴影和深度和完全指定的样本来工作。由于每个样本都必须通过像素着色器，因此总增益相对较低，成本也较高。

​		多重采样抗锯齿（MSAA）通过对每个像素一次计算表面着色并在样本之间共享该结果，从而降低了高计算成本。 每个片段的像素可能有四个（x，y）采样位置，每个都有自己的颜色和z深度，但是对于每个应用于像素的对象片段，像素着色器仅评估一次。 如果片段覆盖了所有MSAA位置样本，则在像素中心评估作色样本。 相反，如果片段包含较少的位置样本，则可以移动阴影样本的位置以更好地表示所覆盖的位置。 例如，这样做可以避免从纹理的边缘进行着色采样。 此位置调整称为质心采样或质心插值，如果启用，则由GPU自动完成。 质心采样避免了非三角形问题，但会导致导数计算返回不正确的值[530，1041]。 参见图5.26。

![image-20191216225237945](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225237945.png)

​		<font size=2>图5.26。 在中间，像素被两个对象重叠。 红色的物体覆盖了三个样本，蓝色的只是一个。 像素着色器评估位置以绿色显示。 由于红色三角形覆盖了像素的中心，因此此位置用于着色器评估。 在样本的位置评估蓝色对象的像素着色器。 对于MSAA，所有四个位置存储单独的颜色和深度。 右侧显示了EQAA的2f4x模式。 现在，这四个样本具有四个ID值，它们由存储的两种颜色和深度的构成的表索引。</font>

​		MSAA比纯超级采样方案快，因为片段仅被着色一次。它着重于以更高的速率采样片段的像素覆盖范围并共享计算出的着色。通过进一步分离采样和覆盖范围，可以节省更多的内存，这反过来又可以使反走样更快—触摸的内存越少，渲染越快。 NVIDIA在2006年推出了覆盖采样抗锯齿（CSAA），AMD随之推出了增强质量抗锯齿（EQAA）。这些技术通过以较高的采样率仅存储片段的覆盖范围来工作。例如，EQAA的“ 2f4x”模式存储两个颜色和深度值，在四个样本位置之间共享。颜色和深度不再存储在特定位置，而是存储在表格中。然后，四个样本中的每个样本仅需要一位来指定两个存储值中的哪一个与其位置相关联。见图5.26。覆盖样本指定每个片段对最终像素颜色的贡献。如果超过了存储的颜色数量，则将存储的颜色逐出，并将其样本标记为未知。这些样本对最终颜色没有帮助[382，383]。对于大多数场景而言，相对较少的像素包含三个或更多可见的不透明片段，它们的着色根本不同，因此该方案在实践中表现良好[1405]。但是，为了获得最高质量，游戏《极限竞速：地平线2》采用了4倍MSAA，尽管EQAA具有性能优势[1002]。

将所有几何图形渲染到多样本缓冲区后，便会执行解析操作。此过程将样本颜色平均在一起，以确定像素的颜色。值得注意的是，当使用具有高动态范围颜色值的多重采样时，可能会出现问题。在这种情况下，为避免失真，通常需要在解析之前对值进行色调映射[1375]。这可能很昂贵，因此可以使用更简单的近似色调映射函数或其他方法[862，1405]。

​		默认情况下，MSAA通过框滤波器进行解析。在2007年，ATI引入了自定义滤波器抗锯齿（CFAA）[1625]，它具有使用窄而宽的帐篷滤镜的能力，这些滤镜会略微扩展到其他像素单元中。此后此模式已被EQAA支持所取代。在现代GPU上，像素或计算着色器可以访问MSAA样本并使用所需的任何重建滤波器，包括从周围像素的样本中采样的。较宽的滤镜可以减少走样，尽管会丢失锐利的细节。 Pettineo [1402，1405]发现，滤波器宽度为2或3像素的三次平滑插值和B样条滤波器总体上具有最佳效果。还有一个性能成本，因为即使使用自定义着色器模拟默认的框滤波器解析也将花费更长的时间，而更宽的过滤器内核意味着增加的样本访问的成本。

​		NVIDIA的内置TXAA支持类似地在比单个像素更宽的区域上使用更好的重建滤波器，以提供更好的结果。它和更新的MFAA（多帧抗锯齿）方案都使用了时间抗锯齿（TAA），这是一类通用的技术，可使用先前帧的结果来改善图像。由于使程序员能够设置每帧MSAA采样模式的功能，部分程度上使此类技术成为可能[1406]。这样的技术可以解决诸如旋转的车轮等走样问题，并且还可以改善边缘渲染质量。

​		想象一下，通过生成一系列图像来“手动”执行采样模式，其中每次渲染使用在像素中采样位置的不同位置。这种偏移是通过在投影矩阵上附加一个微小的平移来完成的[1938]。生成并平均的图像越多，结果越好。这个使用多个偏移图像的概念在时间抗混叠算法中被使用。可以使用MSAA或另一种方法生成单个图像，然后和先前的图像混合。通常只使用两到四个帧[382、836、1405]。较旧的图像可能会被赋予较小的权重[862]，然而如果观看者和场景不移动，这可能会导致帧闪烁，因此通常只对最后一帧和当前帧进行相等的加权。由于每个帧的样本位于不同的子像素位置，因此这些样本的加权总和比单个帧具有更好的边缘覆盖估计。因此，使用最后的两个帧平均的系统可以提供更好的结果。每个帧都不需要额外样本，这就是这种方法如此吸引人的原因。甚至可以使用时间采样来生成较低分辨率的图像，该图像将放大到显示器的分辨率[1110]。另外，需要很多样本才能获得良好结果的照明方法或其他技术可以被代替为每帧使用较少的样本，因为结果将在几帧中混合[1938]。

​		在不增加额外采样成本的情况下为静态场景提供抗锯齿功能时，这种类型的算法在用于时间抗锯齿功能时会遇到一些问题。如果没有对帧进行均等加权，则静态场景中的对象可能会出现微光。快速移动的物体或快速的摄像机移动可能会导致重影，即物体留下的轨迹由于先前帧的影响。重影的一种解决方案是仅对缓慢移动的对象执行这种抗锯齿处理[1110]。另一个重要的方法是使用重投影（第12.2节）来更好地关联先前和当前帧的对象。在这样的方案中，对象生成运动矢量，这些运动矢量存储在单独的“速度缓冲区”中（第12.5节）。这些向量用于将前一帧与当前帧相关联，即，从当前像素位置中减去该向量，以找到前一帧该对象表面位置的颜色像素。在当前帧中一部分不太可能成为表面的样本将被丢弃[1912]。由于时间抗锯齿不需要额外的样本，因此也不需要太多的额外工作，因此近年来人们对这种类型的算法产生了浓厚的兴趣并得到了广泛的采用。之所以有些关注，是因为延迟着色技术（第20.1节）与MSAA和其他多采样支持不兼容[1486]。方法各不相同，并且根据应用程序的内容和目标，已经开发了避免失真和提高质量的一系列技术[836，1154，1405，1533，1938]。例如，Whilidal的演示文稿[1885]显示了EQAA，时间抗锯齿和应用于棋盘采样模式的各种过滤技术如何结合起来以保持质量，同时减少像素着色器调用的次数。 Iglesias-Guitian等。 [796]总结了以前的工作，并提出了他们的方案，以使用像素历史记录和预测来最小化过滤失真。 Patney等。 [1357]扩展了Karis和Lottes在虚幻引擎4实现[862]用于虚拟现实应用程序的TAA工作，增加了可变大小的采样以及对眼睛运动的补偿（第21.3.2节）。

<font color=ff7200>采样模式</font>

​		高效的采样模式是减少失真，时间和其他方面的关键因素。 Naiman [1257]表明，在接近水平和接近垂直的边缘上的失真对人类的影响最大。接近45度倾斜的边缘是第二个最影响最大的地方。旋转网格超级采样（RGSS）使用旋转正方形模式来在像素内提供更多垂直和水平分辨率。图5.25显示了此模式的示例。

​		RGSS模式是一种Latin hypercube或N-rooks采样的形式，其中n个样本放置在n×n网格中，每行和每列一个样本[1626]。使用RGSS，四个样本分别位于4×4子像素网格的单独行和列中。与常规2×2采样模式相比，此类模式特别适合捕获几乎水平和垂直的边缘，在常规2×2采样模式下，此类边缘可能会覆盖偶数个样本，因此效率水平较低。

​		N-rooks是创建良好采样模式的开始，但还不够。例如，这些样本都可能沿着子像素网格的对角线放置，因此对于几乎平行于该对角线的边缘给出较差的结果。参见图5.27，为获得更好的采样，我们希望避免将两个样本彼此靠近。我们还希望分布均匀，将样本均匀分布在整个区域。为了形成这样的模式，分层采样技术（例如拉丁超立方体采样）与其他方法（例如抖动，霍尔顿序列和泊松磁盘采样）相结合[1413，1758]。

![image-20191216225320726](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225320726.png)

​		<font size=2>图5.27。 N-rooks采样。 左侧是合法的N-rooks模式，但在捕获沿其对角线的三角形边缘时效果不佳，因为随着该三角形的移动，所有采样位置都将位于三角形的内部或外部。 右侧是一种模式，可以更有效地捕获此边缘和其他边缘。</font>

​		实际上，GPU制造商通常将此类采样模式硬连接到其硬件中，以进行多重采样抗锯齿。图5.28显示了实际使用的一些MSAA模式。对于时间抗锯齿，覆盖模式是程序员想要的，因为样本位置可以逐帧变化。例如，Karis [862]发现基本的霍尔顿序列比GPU提供的任何MSAA模式效果更好。霍尔顿序列会在空间中生成样本，这些样本看起来是随机的，但差异很小，也就是说，它们在空间中分布良好，并且没有聚类的现象[1413，1938]。

​		虽然子像素网格模式可以更好地近似每个三角形如何覆盖网格单元，但这并不理想。场景可以由在任意屏幕上很小的物体组成，这意味着没有采样率可以完美地捕获它们。如果这些微小的物体或特征形成图案，则以恒定间隔进行采样可能会导致莫尔条纹和其他干涉图案。超级采样中使用的网格模式特别容易混叠。

​		一种解决方案是使用随机采样，这样可以提供更加随机的图案。如图5.28所示的图案肯定是合格的。想象一下，远距离有齿的梳子，每个像素覆盖几个齿。当采样模式与齿频率异相时，规则模式会产生严重的失真。具有较少顺序的采样模式可以分解这些模式。随机化倾向于用噪声代替重复的混叠效应，人类视觉系统对此更为接受[1413]。结构较少的模式有帮助，但是当像素间重复时，它仍会出现混叠现象。一种解决方案是在每个像素上使用不同的采样模式，或者随时间更改每个采样位置。在过去的几十年中，偶尔会硬件中支持交错采样，即一组像素集合的每个像素具有不同的采样模式。例如，ATI的SMOOTHVISION允许每个像素最多16个样本和最多16个用户定义的不同采样模式，这些模式可以混合在一起以重复模式（例如4×4像素图块）。 Molnar [1234]以及Keller和Heidrich [880]发现，对于每个像素使用相同的模式时，使用交错随机采样可以最大程度地减少混叠失真。

![image-20191216225348874](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225348874.png)

​		<font size=2>图5.28。 适用于AMD和NVIDIA图形加速器的MSAA采样模式。 绿色正方形是着色样本的位置，红色正方形是计算和保存的位置样本。 从左至右：2倍，4倍，6倍（AMD）和8倍（NVIDIA）采样。 （由D3D FSAA查看器生成。）</font>

​		值得注意的是其他一些GPU支持的算法。 NVIDIA的较早的Quincunx方法[365]是一种可以使样本影响多个像素的实时抗锯齿方案。 “ Quincunx”是指五个对象的排列，四个在正方形边角，第五个在中心，例如在六面模具上的五个点的图案。 Quincunx多重采样抗锯齿使用此模式，将四个外部采样放在像素的角上。参见图5.25。每个角样本值被分配到其四个相邻像素。并非像其他大多数实时方案那样平均地对每个样本加权，而是对中心样本赋予1/2的权重，而对每个角落样本赋予的权重为1/8。由于这种共享，每个像素平均只需要两个样本，其结果比两个样本的FSAA方法要好得多[1678]。这种模式近似于二维帐篷滤波器，如上一节所述，该过滤器优于盒式过滤器。

​		通过将每个像素使用单个样本，也可以将Quincunx采样应用于时间抗锯齿[836，1677]。每个帧在每个轴上比之前的帧偏移半个像素，偏移方向在帧之间交替。前一帧提供像素角样本，并且使用双线性插值快速计算每个像素的贡献。将结果与当前帧取平均值。每个帧的权重相等意味着静态视图没有闪烁的现象。校准移动物体的问题仍然存在，但是该方案本身易于编码，并且在每帧每像素仅使用一个样本的情况下具有更好的外观。

​		当在单个帧中使用时，Quincunx通过在像素边界共享样本而具有仅两个样本的低成本。 RGSS模式更适合捕获接近水平和垂直边缘的更多灰度。 FLIPQUAD模式最初是为移动图形开发的，结合了这两个理想的功能[22]。 它的优点是成本仅为每个像素两个样本，并且质量类似于RGSS（每个像素四个样本）。 此采样模式如图5.29所示。 Hasselgren等人探索了其他利用样本共享的低开销采样模式。 [677]。

![image-20191216225412945](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225412945.png)

​		<font size=2>图5.29。 左侧显示了RGSS采样模式。 每个像素花费四个样本。 通过将这些位置移到像素边缘，可以跨边缘进行样本共享。 但是，要解决此问题，每个其他像素必须具有反射的样本图案，如右图所示。 所得的样本模式称为FLIPQUAD，每个像素花费两个样本。</font>

​		与Quincunx一样，两个样本的FLIPQUAD模式也可以与时间抗锯齿一起使用，并分布在两个帧上。 Drobot [382，383，1154]解决了在他的混合重建抗锯齿（HRAA）工作中哪种两个样本模式最好的问题。 他探索了用于时间抗锯齿的不同采样模式，并发现FLIPQUAD模式是五个测试中最好的。 棋盘图案还可以用于时间抗锯齿。 El Mansouri [415]讨论了使用两个样本的MSAA创建棋盘渲染，以减少着色器开销，同时解决混淆问题。 Jimenez [836]使用SMAA，时间抗锯齿和多种其他技术来提供一种解决方案，其中抗锯齿质量可以随着渲染引擎负载而改变。 Carpentier和Ishiyama [231]在边缘采样，将采样网格旋转了45°。 他们将此时间抗锯齿方案与FXAA（稍后讨论）结合在一起，以在较高分辨率的显示器上进行高效渲染。

<font color=ff7200>形态学方法</font>

​		混叠通常是由边缘引起的，例如由几何形状，尖锐的阴影或明亮的高光形成的边缘。 可以利用与混叠相关的知识体系来提供更好的抗锯齿结果。 2009年，Reshetov [1483]沿着这些思路提出了一种算法，称其为形态抗锯齿（MLAA）。 “形态”是指“与结构或形状有关”。早在1983年，Bloomenthal [170]就在该领域[830]中开展了早期工作。 Reshetov的论文重新激发了对多采样方法替代方法的研究，强调搜索和重建边缘[1486]。

​		这种抗锯齿形式是在后期处理中执行的。 也就是说，以通常的方式完成渲染，然后将结果送到生成抗锯齿结果的过程。 自2009年以来，已经开发出了各种各样的技术。那些依赖于其他缓冲区（例如深度和法线）的技术可以提供更好的结果，例如子像素重构抗锯齿（SRAA）[43，829]，但仅适用于几何边缘的抗锯齿。 诸如几何缓冲区抗锯齿（GBAA）和距离边缘抗锯齿（DEAA）之类的分析方法，使渲染器计算有关三角形边缘位于何处的附加信息，例如，边缘距像素中心的距离多[829] ]。

​		最通用的方案只需要颜色缓冲区，这意味着它们还可以改善阴影，高光或以前应用的各种后处理技术（如轮廓边缘渲染）中的边缘（第15.2.3节）。 例如，定向局部抗锯齿（DLAA）[52，829]是基于以下观察结果：接近垂直的边缘应水平模糊，同样，接近水平的边缘也应与其邻居垂直模糊。

​		边缘检测的更复杂形式试图找到可能以任何角度包含边缘的像素并确定其覆盖范围。 检查潜在边缘周围的邻域，目标是尽可能重建原始边缘所在的位置。 然后可以使用边缘对像素的影响来混合相邻像素的颜色。 有关过程的概念视图，请参见图5.30。

![image-20191216225437269](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225437269.png)

​		<font size=2>图5.30。 形态抗锯齿。 左侧是锯齿图像。 目标是确定形成边缘的边缘的可能方向。 在中间，该算法通过检查邻居来记录边缘的可能性。 给定样本，显示了两个可能的边缘位置。 在右侧，最佳估计边缘用于将邻近的颜色与估计的覆盖率成比例地混合到中心像素中。 对图像中的每个像素重复此过程。</font>

​		Iourcha等 [798]通过检查像素中的MSAA样本来计算更好的结果，从而改善了边缘查找。注意，与基于样本的算法相比，边缘预测和混合可以提供更高的精度。例如，一种使用每个像素四个样本的技术只能为对象的边缘提供五个混合级别：没有样本覆盖，一个样本覆盖，两个样本，三个样本和四个样本。估计的边缘位置可以具有更多位置，因此可以提供更好的结果。

​		基于图像的算法有几种可能会误入歧途。首先，如果两个对象之间的色差低于算法的阈值，则可能无法检测到边缘。难以解释具有三个或更多不同表面重叠的像素。具有高对比度或高频元素的表面，其中颜色在像素之间快速变化，可能导致算法遗漏边缘。特别地，当对其应用形态抗锯齿时，文本质量通常会受到影响。对象角可能是一个挑战，有些算法可以使它们具有圆润的外观。假设边缘是直的，曲线也会受到不利影响。单个像素变化可能会导致边缘重建方式发生较大变化，从而在帧与帧之间产生明显的失真。解决此问题的一种方法是使用MSAA覆盖蒙版来改善边缘确定性[1484]。

​		形态抗混叠方案仅使用所提供的信息。例如，宽度小于像素的对象（例如电线或绳索）将在屏幕上如果它没有覆盖像素的中心位置出现间隙。在这种情况下，采集更多的样本可以提高质量；仅基于图像的抗锯齿不能。此外，执行时间可以根据查看内容的内容而变化。例如，一片草地的视野所需的抗锯齿时间是天空的三倍[231]。

​		综上所述，基于图像的方法可以为有限的内存和处理成本提供抗锯齿支持，因此它们被用于许多应用程序中。仅彩色版本还与渲染管线分离，使其易于修改或禁用，甚至可以作为GPU驱动程序选项公开。两种最流行的算法是快速近似抗锯齿（FXAA）[1079、1080、1084]和子像素形态抗锯齿（SMAA）[828、830、834]，部分原因是两者都提供了可靠的（免费的）源代码实现为各种机器。两种算法都使用颜色输入，SMAA具有能够访问MSAA样本的优势。每个都有自己的各种可用设置，在速度和质量之间进行权衡。每帧的成本通常在1-2毫秒的范围内，主要是因为这就是视频游戏愿意花费的时间。最后，两种算法都可以利用时间抗锯齿[1812]。 Jimenez [836]提出了一种改进的SMAA实现，比FXAA更快，并描述了一种时间抗混叠方案。最后，我们向读者推荐Reshetov和Jimenez [1486]对形态技术及其在视频游戏中的使用的广泛评论。

### 5.5透明度，Alpha和合成

​		半透明物体可以通过许多不同的方式使光线穿过它们。 对于渲染算法，可以将这些大致分为基于灯光的效果和（light-based）基于视图的效果（view-based effects）。 基于光的效果是对象导致光被衰减或转移，从而导致场景中的其他对象被照亮并以不同方式渲染。 基于视图的效果是呈现半透明对象本身的效果。

​		在本节中，我们将讨论基于视图的透明的最简单形式，其中半透明对象充当其后对象颜色的衰减器。 在后面的章节中，将讨论更为详细的基于视线和光的效果，例如，毛玻璃，光的弯曲（折射），由于透明物体的厚度导致的光衰减以及由于视角导致的反射率和透射率变化。

​		一种给出透明感的方法称为屏门透明（creen-door transparency）[1244]。这个想法是用像素对齐的棋盘填充图案渲染透明三角形。也就是说，三角形的每个其他像素都将被渲染，从而使位于其后面的对象部分可见。通常，屏幕上的像素距离足够近，以至于棋盘图案本身不可见。该方法的主要缺点是通常只能令人信服地在屏幕的一个区域上渲染一个透明对象。例如，如果在蓝色对象上绘制了透明的红色对象和透明的绿色对象，则三种颜色中只有两种可以显示在棋盘图案上。同样，50％的棋盘格是有限的。其他较大的像素遮罩可用于给出其他百分比，但是这些往往会创建可检测的图案[1245]。

​		也就是说，该技术的一个优势是它的简单性。透明对象可以随时以任何顺序呈现，并且不需要特殊的硬件。通过使所有对象在其覆盖的像素处不透明，可以解决透明性问题。同样的想法也被用于对剪切纹理的边缘进行抗锯齿，但在子像素级别使用称为覆盖的Alpha功能（alpha to coverage）（第6.6节）。

​		由Enderton等人介绍。 [423]，随机透明度使用子像素的屏门遮盖与随机采样相结合。通过使用随机点画图案表示片段的alpha覆盖范围，可以创建合理但嘈杂的图像。见图5.31。每个像素需要大量样本才能使结果看起来合理，并且所有子像素样本都需要大量内存。吸引人的是，不需要混合，并且抗锯齿，透明度和创建部分覆盖像素的任何其他现象都可以通过单一机制覆盖。

![image-20191216225517964](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225517964.png)

​		<font size=2>图5.31。 随机透明。 产生的噪音显示在放大的区域。 （图像来自NVIDIA SDK 11 [1301]示例，由NVIDIA Corporation提供。）</font>

​		大多数透明度算法会将透明对象的颜色与其后面对象的颜色混合在一起。为此，需要Alpha混合的概念[199，387，1429]。当在屏幕上渲染对象时，RGB颜色和z缓冲区深度与每个像素相关联。还可以为对象覆盖的每个像素定义另一个组件，称为alpha（α）。 Alpha是一个值，它描述给定像素的对象片段的不透明度和覆盖度。 alpha为1.0表示对象是不透明的，并且完全覆盖了像素的关注区域； 0.0表示完全不遮盖像素，即片段是完全透明的。

​		像素的Alpha值可以表示不透明度或覆盖率，或者两者，视情况而定。例如，肥皂泡的边缘可能会覆盖像素的四分之三，即0.75，并且可能几乎是透明的，从而使十分之九的光线直达眼睛，所以它的十分之一是不透明的，即0.1。那么其alpha将为0.75×0.1 = 0.075。但是，如果我们使用MSAA或类似的抗锯齿方案，则样本本身将考虑覆盖范围。四分之三的样本将受到肥皂泡的影响。然后，在每个这些样本中，我们将使用0.1不透明度值作为Alpha。

#### 5.5.1混合顺序

​		为了使对象看起来透明，它以小于1.0的alpha渲染到现有场景的顶部。 对象覆盖的每个像素将从像素着色器接收到生成的RGBα（也称为RGBA）。 通常使用over运算符将此片段的值与原始像素颜色混合，如下所示：
$$
\mathbf{c}_o=\alpha_s\mathbf{c}_s+(1-\alpha_s)\mathbf{c}_d\qquad[\textbf{over} \quad\text{operator}]
\qquad\qquad(5.24)
$$
​		其中$\mathbf{c}_s$是透明对象的颜色（称为源），$\alpha_s$是对象的alpha$，\mathbf{c}_d$是混合之前的像素颜色（称为目标），$\mathbf{c}_o$是由于将透明对象放置在现有场景上而产生的颜色 。 在渲染管线发送$\mathbf{c}_s$和$α_s$的情况下，像素的原始颜色$\mathbf{c}_d$被结果$\mathbf{c}_o$代替。 如果传入的RGBα实际上是不透明的（$α_s= 1.0$），则该方程式简化为用对象的颜色完全替换像素的颜色。

示例：混合。 红色的半透明对象被渲染到蓝色的背景上。 假设对象的某些像素的RGB着色为（0.9,0.2,0.1），背景为（0.1，0.1，0.9），并且对象的不透明度设置为0.6。 然后将这两种颜色混合
$$
0.6(0.9, 0.2, 0.1) + (1 − 0.6)(0.1, 0.1, 0.9),
$$

其颜色为（0.58，0.16，0.42）。

​		over运算符为要渲染的对象提供半透明外观。透明度是这样工作的，从某种意义上说，只要可以通过物体看到后面的物体，我们就会将其视为透明物体[754]。使用over可以模拟薄纱织物的真实效果。织物后面的对象被部分遮挡了-织物的线是不透明的。在实践中，宽松的织物具有随角度变化的Alpha覆盖[386]。这里的要点是Alpha模拟了材质覆盖像素的程度。

​		over操作对模拟其他透明效果的效果较弱，尤其是透过有色玻璃或塑料观看时。在现实世界中，放置在蓝色物体前面的红色滤镜通常会使蓝色物体看起来很暗，因为该物体反射的可以穿过红色滤镜的光线很少。请参阅图5.32。当使用over进行混合时，结果是红色和蓝色部分加在一起。最好将这两种颜色相乘，并增加透明对象本身的反射。 14.5.1和14.5.2节中讨论了这种类型的物理透射率。

![image-20191216225546634](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225546634.png)

​		<font size=2>图5.32。 一个红色的薄纱正方形织物和一个红色的塑料过滤器，具有不同的透明效果。 注意阴影也不同。 （照片由Morgan McGuire提供。）</font>

​		在基本的混合阶段运算符中，over是通常用于透明效果的运算符[199，1429]。另一种有用的操作是加法混合，将像素值简单地求和。那是，
$$
\mathbf{a}_o=\alpha_s\mathbf{c}_s+\mathbf{c}_d\qquad\qquad(5.25)
$$
​		这种混合模式可以很好地用于发光效果，例如闪电或火花，它们不会使后面的像素衰减，而只会使它们变亮[1813]。 但是，此模式的透明度看起来不正确，因为不透明的表面似乎没有被过滤[1192]。 对于诸如烟或火之类的多层半透明表面，加法混合具有使现象的颜色饱和的效果[1273]。

​		为了正确渲染透明对象，我们需要在不透明对象之后绘制它们。首先通过混合关闭渲染所有不透明对象，然后打开over渲染透明对象。从理论上讲，我们总是可以一直打开over，因为不透明的alpha值为1.0会给出源颜色并隐藏目标颜色，但是这样做更昂贵，而且没有真正的收益。

​		z缓冲区的一个限制是每个像素只能存储一个对象。如果多个透明对象与同一像素重叠，则仅z缓冲区无法容纳并稍后解决所有可见对象的影响。在任何给定像素的透明表面上使用over时，通常需要以从后到前的顺序进行渲染。不这样做可能会导致错误的感知提示。一种实现这种排序的方法是，沿视图方向按照到单个对象的质心的距离对其进行排序。这种粗略的分类可以很好地工作，但是在各种情况下都有许多问题。首先，排序值只是一个近似值，因此被分类为距离较远的对象可能位于距离较近的对象的前面。互相贯穿的对象无法针对所有视角在每个网格的基础上进行解析，除非将每个网格分解为单独的部分。有关示例，请参见图5.33的左图。即使是单个具有凹面的网格，也可能在自身重叠的屏幕视图方向上出现排序问题。

![image-20191216225609109](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225609109.png)

​		<font size =2>图5.33。 在左侧，使用z缓冲区透明渲染了模型。 以任意顺序渲染网格会产生严重的错误。 在右侧，去除深度可提供正确的外观，但要付出额外的时间。 （图片由NVIDIA Corporation提供。）</font>

​		但是，由于其简单性和速度以及不需要额外的内存或特殊的GPU支持，仍然经常使用对透明度进行粗糙排序的方法。 如果实现，通常最好在执行透明度时关闭z深度替换。 也就是说，z缓冲区仍然可以正常测试，但是现存的曲面不会改变所存储的z深度； 最接近的不透明表面的深度保持不变。 这样，所有透明对象将至少以某种形式出现，而不会因照相机旋转而更改排序顺序时突然出现或消失。 其他技术也可以帮助改善外观，例如，每次绘制两次透明网格，首先渲染背面，然后渲染正面[1192，1255]。

​		还可以修改over方程，以便从前向后混合得到相同的结果。 这种混合模式称为Under运算符：
$$
\begin{align}
\mathbf{c}_o=&\alpha_d\mathbf{c}_d+(1-\alpha_d)\alpha_s\mathbf{c}_s\qquad[\textbf{under} \text{operator}],\\
a_o=&\alpha_s(1-\alpha_d)+\alpha_d=\alpha_s-\alpha_s\alpha_d+\alpha_d.
\end{align}
\qquad\qquad(5.26)
$$
​		请注意，under要求目标保持Alpha值，而over则不需要。换句话说，目标（在其下面混合了更近的透明表面）不是不透明的，因此需要具有alpha值。under的公式就像over一样，但是交换了源和目标。另外，请注意，用于计算Alpha的公式与顺序无关，因为可以交换源Alpha和目标Alpha，结果是相同的最终Alpha。

​		alpha公式来自将片段的alpha作为覆盖范围。 Porter和Duff [1429]指出，由于我们不知道每个片段的覆盖区域的形状，因此我们假设每个片段都按其alpha比例覆盖另一个片段。例如，如果$\alpha_s$= 0.7，则以某种方式将像素分为两个区域，其中源片段覆盖0.7，而0.3不是。除非有其他知识，否则覆盖目标范围（例如$\alpha_d$= 0.6）的目标片段将与源片段成比例地重叠。此公式具有几何解释，如图5.34所示。

![image-20191216225632460](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225632460.png)

​		<font size=2>图5.34。 一个像素和两个片段s和d。 通过沿着不同的轴对准两个片段，每个片段覆盖彼此成比例的量，即，它们是不相关的。 两个片段覆盖的面积等于under的输出Alpha值$\alpha_s-\alpha_s\alpha_d+\alpha_d$。 这意味着将两个面积相加，然后减去它们重叠的面积。</font>

#### 5.5.2与顺序无关的透明

​		under方程式通过将所有透明对象绘制到一个单独的颜色缓冲区中，然后使用over将此颜色缓冲区合并到场景的不透明视图上。 Under运算符的另一种用途是执行与顺序无关的透明（OIT）算法，称为深度剥离（depth peeling）[449，1115]。顺序无关意味着应用程序不需要执行排序。深度剥离背后的想法是使用两个z缓冲区和多次passes。第一次渲染pass，以使所有表面的z深度（包括透明表面）都位于第一个z缓冲区中。在第二次pass中，将渲染所有透明对象。如果对象的z深度与第一个z缓冲区中的值匹配，则我们知道这是最近的透明对象，并将其RGBα保存到一个单独的颜色缓冲区中。我们还通过保存任何透明对象（如果有的话）的z深度来“剥离”该层，如果该透明对象超过了第一个z深度并且是最接近的，则该z深度就是第二近的透明对象的距离。连续的pass继续剥落并在下面添加透明层。经过一定次数的pass后我们停止，然后将透明图像混合在不透明图像之上。见图5.35。

![image-20191216225706000](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225706000.png)

​		<font size=2>图5.35。 每个深度剥离pass都绘制透明层中的一层。 左侧是第一次pass，显示了直接可见的图层。 中间是第二层，第二次pass在每个像素处显示第二近的透明表面，在这种情况下为对象的背面。 右边是第三层，一组第三近的透明表面。 最终结果可以在第624页的图14.33中找到。（图片由Louis Bavoil提供）。</font>

​		已经出现了该方案的几种变形。例如，Thibieroz [1763]提供了一种从后到前的算法，其优点是能够立即混合透明值，这意味着不需要单独的alpha通道。深度剥离的一个问题是知道需要多少次pass足以捕获所有透明层。一种硬件解决方案是提供一个像素绘制计数器，该计数器可告知渲染时中写入了多少像素。如果一次pass中没有任何像素被渲染，则渲染完成。使用under的优势在于，最重要的透明层（眼睛首先看到的那些层）会尽早渲染。每个透明表面始终会增加其覆盖的像素的alpha值。如果像素的Alpha值接近1.0，则混合贡献会使像素几乎不透明，因此距离较远的对象的影响可以忽略不计[394]。当一次pass中渲染的像素数量降至某个最小值以下时，可以缩短从前到后类型剥离的距离，或者可以指定固定的pass次数。这对于从后到前的剥离类型效果不佳，因为最近（通常是最重要的）层是最后绘制的，因此可能会因提前终止而丢失。

​		虽然深度剥离是有效率的，但它可能会很慢，如果被剥离的每一层都是所有透明对象的单独渲染pass。 Bavoil和Myers [118]提出了双重深度剥离，其中在每个遍中剥离了两个深度剥离层（剩余的最接近和最远的），从而将渲染pass的数量减少了一半。刘等[1056]探索了一种桶分类方法，该方法在一次pass中可捕获多达32个层。这种方法的一个缺点是，它需要大量内存才能为所有层保持排序顺序。通过MSAA或类似方法进行抗锯齿会如天文数字般增加成本。

​		将以交互速率正确地将透明对象混合在一起的问题并不是由于我们缺少算法，而是如何将这些算法有效率地映射到GPU。 1984年，Carpenter提出了A缓冲区[230]，这是另一种多重采样形式。在A缓冲区中，每个被渲染的三角形都会为其完全或部分覆盖的每个屏幕网格单元创建一个覆盖蒙版。每个像素存储一个所有其相关片段的列表。不透明的片段可以清除它们后面的片段，类似于z缓冲区。所有片段均存储在透明表面上。一旦形成所有列表，就可以通过遍历片段并解析每个样本来产生最终结果。

​		通过DirectX 11 [611，1765]中公开的新功能，使在GPU上创建片段的链接列表的想法成为可能。使用的功能包括无序访问视图（UAV）和原子操作，如3.8节所述。通过访问覆盖蒙版并评估每个样本处的像素着色器，来使用MSAA进行抗锯齿。该算法通过光栅化每个透明表面并将生成的片段插入长数组中。连同颜色和深度一起，生成了一个单独的指针结构，该结构将每个片段链接到像素存储的先前片段。然后执行一个单独的pass操作，渲染填充屏幕的四边形，以便在每个像素处评估一个像素着色器。该着色器通过跟随链接检索每个像素处的所有透明片段。检索到的每个片段都与先前的片段依次排序。然后将排序后的列表从后向前混合，以给出最终的像素颜色。因为混合是由像素着色器执行的，所以如果需要，可以为每个像素指定不同的混合模式。 通过减少使用原子运算符的成本提高性能，随着GPU和API的不断发展[914]。

​		A缓冲区的优点是，仅分配每个像素所需的片段，GPU上的链表实现也是如此。 从某种意义上讲，这也可能是不利的，因为在开始渲染一帧之前尚不知道所需的存储量。 具有头发，烟雾或其他物体的场景可能具有许多重叠的透明表面，这可能会产生大量片段。Andersson[46]指出，对于复杂的游戏场景，最多对象们（例如树叶）中的50个透明网格和最多200个半透明粒子可能会重叠。

​		GPU通常具有预先分配的内存资源，例如缓冲区和数组，并且链表方法也不例外。用户需要确定所需的内存大小，而内存大小不足会导致明显的瑕疵。 Salvi和Vaidyanathan [1532]提出了一种通过使用Intel引入的称为像素同步的GPU功能来解决此问题的方法，即多层alpha混合。见图5.36。此功能提供了比原子操作更少的开销的可编程混合。他们的方法重新定义了存储和混合的方式，以便在内存用完时优雅地降低性能。粗略的排序顺序可以使他们的方案受益。 DirectX 11.3引入了光栅化程序顺序视图（第3.8节），这是一种缓冲区类型，允许在任何支持此功能的GPU上实现此透明方法[327，328]。移动设备具有类似的技术，称为“瓦片本地存储”，它允许它们实现多层alpha混合[153]。但是，这种机制会降低性能，因此这种算法可能是高消耗的[1931]。

![image-20191216225733273](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225733273.png)

​		<font size=2>图5.36。 在左上方，执行传统的从后到前的Alpha混合，由于排序顺序不正确，导致渲染错误。 右上方的A缓冲区被用于提供一个完美的非交互结果。 左下方显示了具有多层alpha混合的渲染。 右下方显示了A缓冲区和多层图像之间的差异，乘以4可得到可见性[1532]。 （图片由英特尔公司的Marco Salvi和Karthik Vaidyanathan提供。）</font>

​		这种方法建立在Bavoil等人提出的k缓冲区的概念上[115]，其中保存了前几层可见图层并对其进行了排序，而更深的图层则被丢弃和合并。 Maule等[1142]使用k缓冲区并通过使用加权平均来解决这些较远的深层。 加权总和[1202]和加权平均[118]透明性技术与顺序无关，是单次pass并且可以几乎在每个GPU上运行。 问题在于它们没有考虑对象的顺序。 因此，例如，使用Alpha表示覆盖率，蓝色纱布围巾上方的红色纱巾给出了紫色，而正确地看到红色的围巾却带有一点蓝色。 虽然对于几乎不透明的对象给出的结果很差，但是这类算法对于可视化很有用，并且对于高度透明的表面和粒子也适用。 见图5.37。

![image-20191216225751091](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216225751091.png)

​		<font size=2>图5.37。 随着不透明度的增加，对象顺序变得越来越重要。 （Dunn [394]之后的图像。）</font>

在加权和透明中，公式为
$$
\mathbf{c}_o=\sum_{i=1}^{n}(\alpha_i\mathbf{c}_i)+
\mathbf{c}_d(1-\sum_{i=1}^{n}\alpha_i),
\qquad\qquad(5.27)
$$
​		其中n是透明表面的数量，$\mathbf{c}_i$和$\alpha_i$表示透明度值的集合，而$\mathbf{c}_d$是场景的不透明部分的颜色。 当渲染透明表面时，将两个和累积并分别存储作，并在透明pass结束时在每个像素处评估方程式。 该方法的问题在于，第一总和饱和，即生成大于（1.0、1.0、1.0）的颜色值，并且背景颜色可能会产生负面影响，因为alpha的总和可能超过1.0。

通常首选加权平均方程式，因为它避免了这些问题：
$$
\begin{align}
\mathbf{c}_{sum}&=\sum_{i=1}^n(alpha_i\mathbf{c}_i),\alpha_{sum}=\sum_{i=1}^n\alpha_i,\\
\mathbf{c}_{wavg}&=\frac{\mathbf{c}_{sum}}{\alpha_{sum}},\alpha_{avg}=\frac{\alpha_{sum}}{n},\\
u&=(1-\alpha_{avg})^n,\\
\mathbf{c}_o&=(1-u)\mathbf{c}_{wavg}+u\mathbf{c}_d.
\end{align}
\qquad\qquad(5.28)
$$
​		第一行表示透明渲染期间在两个单独的缓冲区中生成的结果。 每个对$\mathbf{c}_{sum}$有贡献的表面都受到一个由其alpha加权的影响； 几乎不透明的表面贡献了更多的颜色，几乎透明的表面几乎没有影响。 通过将$\mathbf{c}_{sum}$除以$\alpha_{sum}$，可以得到加权平均透明颜色。 值$\alpha_{avg}$是所有alpha值的平均值。 值$u$是对$n$个透明表面应用此平均alpha值$n$次后目标（不透明场景）的估计可见性。 最后一行实际上是over运算符，其中（1- u）代表源的alpha。

​		加权平均值的一个限制是，对于相同的Alpha，它将均匀混合所有颜色，而不考虑顺序。 McGuire和Bavoil [1176，1180]引入了加权混合与顺序无关的透明，以提供更具说服力的结果。 在它们的公式中，到表面的距离也会影响权重，而更近的表面会受到更大的影响。 而且，不是对alpha进行平均，而是通过将与项$（1-\alpha_i）$相乘并减一来计算u，从而获得一组表面的正确alpha覆盖。 如图5.38所示，该方法产生了更具视觉效果的结果。

![image-20191216230234435](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216230234435.png)

​		<font size=2>图5.38。 查看同一引擎模型的两个不同的摄像头位置，均使用加权混合与顺序无关的透明度进行渲染。 按距离加权有助于弄清哪些表面更靠近观察者[1185]。 （图片由Morgan McGuire提供。）</font>

​		缺点是，在较大的环境中，彼此靠近的对象的距离权重几乎相等，因此结果与加权平均值几乎没有区别。 另外，随着相机到透明物体的距离改变，深度权重可能会随之改变，但是这种改变是逐渐的。

​		McGuire和Mara [1181，1185]将这种方法扩展为包括一种可能的透射色效果。 如前所述，本节中讨论的所有透明度算法都将各种颜色混合在一起而不是过滤它们，从而模仿了像素覆盖。 为了提供滤色器效果，不透明场景由像素着色器读取，每个透明表面将其在该场景中覆盖的像素乘以其颜色，然后将结果保存到第三个缓冲区。 现在，在解析透明缓冲区时，将使用该缓冲区（其中的不透明对象现在由透明对象着色）来代替不透明场景。 该方法之所以有效，是因为与覆盖所致的透明不同，颜色传输与顺序无关。

​		还有其他算法使用这里介绍的几种技术中的元素。例如，Wyman[1931]通过内存需求，插入和合并方法，使用alpha覆盖率还是几何覆盖率以及如何处理丢弃的片段对先前的工作进行了分类。他介绍了通过寻找先前研究中的空白而发现的两种新方法。他的随机分层alpha混合方法使用k缓冲区，加权平均值和随机透明。他的其他算法是Salvi和Vaidyanathan方法的一种变体，使用了覆盖蒙版而不是alpha。

​		鉴于各种类型的透明内容，渲染方法和GPU功能，没有完美的解决方案来渲染透明对象。我们请感兴趣的读者阅读Wyman的论文[1931]和Maule等人的关于交互式透明算法的更详细的调查[1141]。 McGuire的演讲[1182]提供了该领域的更广阔视野，贯穿了其他相关现象，例如体积光，颜色透射和折射，这些将在本书的后面进行更深入的讨论。

#### 5.5.3预乘Alpha和合成

​		over操作符还用于将照片或合成渲染的对象混合在一起。 此过程称为合成（compositing）[199，1662]。 在这种情况下，每个像素的alpha值将与对象的RGB颜色值一起存储。 由Alpha通道形成的图像有时称为遮罩。 它显示了对象的轮廓形状。 有关示例，请参见第203页的图6.27。 然后可以将此RGBα图像与其他此类元素或背景混合使用。

​		使用合成RGBα数据的一种方法是使用预乘alpha（也称为关联的alpha）。 即，在使用之前，RGB值乘以alpha值。 这使得对合成under方程更加高效：
$$
\mathbf{c}_o=\mathbf{c}_s'+(1-\alpha_s)\mathbf{c}_d
\qquad\qquad(5.29)
$$
​		其中$\mathbf{c}'_s$是预乘的源通道，代替公式5.25中的$\alpha_s\mathbf{c}_s$。 预乘Alpha还可以在不更改混合状态的情况下使用over和加法混合，因为现在在混合过程中已添加了源颜色[394]。 请注意，预乘的RGBα值它们通常不大于alpha值，尽管可以使RGB分量产生特别明亮的半透明值。

​		渲染合成图像自然的与预乘alpha吻合。 默认情况下，在黑色背景上渲染的不透明抗锯齿对象会提供预乘值。 假设白色（1,1,1）三角形沿其边缘覆盖了某些像素的40％。 使用（极精确）抗锯齿功能，像素值将设置为0.4的灰度，即我们将为此像素保存颜色（0.4,0.4,0.4）。 如果存储，alpha值也将为0.4，因为这是三角形覆盖的区域。 RGBα值为（0.4、0.4、0.4、0.4），这是一个预乘值。

​		图像存储的另一种方式是使用未乘积的alpha，也称为未关联的alpha，或者甚至是术语非预乘的alpha。未乘Alpha就是它的意思：RGB值不乘以Alpha值。对于白色三角形示例，未相乘的颜色为（1,1,1,0.4）。这种表示形式的优点是可以存储三角形的原始颜色，但是在显示之前，始终需要将该颜色乘以存储的alpha值。每次执行过滤和混合操作时，最好使用预乘数据，因为使用未乘Alpha不能正确执行线性插值之类的操作[108，164]。可能会出现诸如围绕对象边缘的黑色条纹之类的瑕疵[295，648]。请参见第6.6节的结尾进行进一步讨论。预乘的alpha值也可以进行更清晰的理论处理[1662]。

​		对于图像处理应用程序而言，未关联的alpha值可用于遮盖照片而不影响基础图像的原始数据。同样，未关联的alpha表示可以使用颜色通道的整个精度范围。就是说，必须注意正确地将未相乘的RGBα值与用于计算机图形计算的线性空间正确地相互转换。例如，没有浏览器正确执行此操作，也没有可能这样做，因为现在预计会出现不正确的行为[649]。支持Alpha的图像文件格式包括PNG（仅非关联的Alpha），OpenEXR（仅关联）和TIFF（两种Alpha类型）。

​		与alpha通道有关的一个概念是色键[199]。这是视频制作中的一个术语，其中演员是在绿色或蓝色屏幕上拍摄并与背景融合在一起的。在电影行业中，此过程称为绿屏或蓝屏。这里的想法是将特定的色调（用于胶卷）或精确值（用于计算机图形）指定为透明；只要检测到背景，就会显示背景。这样，仅使用RGB颜色即可为图像提供轮廓形状。无需存储任何Alpha。该方案的一个缺点是，对象在任何像素处要么完全不透明，要么完全透明，即Alpha实际上仅为1.0或0.0。例如，GIF格式允许将一种颜色指定为透明。

### 5.6显示编码

​		当我们计算照明，纹理或其他操作的效果时，使用的值假定为线性。 非正式地，这意味着加法和乘法按预期工作。 但是，为了避免各种视觉瑕疵，显示缓冲区和纹理使用我们必须考虑的非线性编码。 简短而草率的答案如下：选取[0，1]范围内的着色器输出颜色并将其提高1 / 2.2的幂，执行所谓的伽马校正。 对传入的纹理和颜色执行相反的操作。 在大多数情况下，您可以告诉GPU为您执行这些操作。 本节说明了快速摘要的方式和原因。

​		我们从阴极射线管（CRT）开始。在数字成像的早期，CRT显示器已成为常态。这些设备在输入电压和显示辐射率之间表现出幂关系。随着施加到像素的能量水平的增加，发出的辐射不会线性增长，而是（令人惊讶地）与该水平成比例地上升，并提高到大于1的功率。例如，假设幂为2。设置为50％的像素将发出设置为1.0的像素的四分之一的光量，即$0.5^2 = 0.25 $[607]。尽管LCD和其他显示技术的固有色调响应曲线与CRT不同，但它们是通过转换电路制造的，从而使它们模仿了CRT响应。

​		该幂函数几乎与人类视觉的亮度灵敏度相反[1431]。这种幸运的巧合的结果是，编码在感觉上大致是统一的。即，在可显示范围内，一对编码值N和N + 1之间的感知差大致恒定。通过测量阈值对比度，我们可以在各种条件下检测到亮度差异约1％。当将颜色存储在有限精度的显示缓冲区中时，这种接近值的最佳分布可以最大程度地减少条带化现象（第23.6节）。相同的好处也适用于通常使用相同编码的纹理。

​		显示传递函数描述了显示缓冲区中的数字值与从显示器发出的辐射度之间的关系。因此，它也称为电光学传递函数（EOTF）。显示传递函数是硬件的一部分，在计算机显示器，电视和电影放映机之间有不同的标准。还有一个标准的传递函数对于过程的另一端，图像和视频捕获设备，称为光电传递函数（OETF）[672]。

​		在编码用于显示的线性颜色值时，我们的目标是消除显示传递函数的影响，以便我们计算的任何值都将发出相应的辐射度。例如，如果我们的计算值加倍，我们希望输出辐射率加倍。为了保持这种连接，我们应用了显示传递函数的逆函数来抵消其非线性效应。使显示屏的响应曲线无效的过程也称为伽马校正，其原因很快就会清楚。在解码纹理值时，我们需要应用显示传递函数来生成用于着色的线性值。图5.39显示了在显示过程中解码和编码的使用。

![image-20191216230605336](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216230605336.png)

​		<font size=2>图5.39。 在左侧，GPU着色器访问PNG颜色纹理，并将其非线性编码的值转换为线性（蓝色）。 进行着色和色调映射后（第8.2.2节），最终的计算值被编码（绿色）并存储在帧缓冲区中。 该值和显示传递函数确定发出的辐射量（红色）。 绿色和红色功能的组合抵消了，因此发出的辐射与线性计算值成正比。</font>

​		个人计算机显示器的标准传递函数由被称为sRGB的颜色空间规范定义。当从纹理读取值或将值写入颜色缓冲区时，可以将大多数控制GPU的API设置为自动应用正确的sRGB转换[491]。如第6.2.2节所述，生成Mipmap还将考虑sRGB编码。通过先转换为线性值，然后执行插值，纹理值之间的双线性插值将正确工作。通过将存储的值解码回线性值，混合新值，然后对结果进行编码，可以正确完成Alpha混合。

​		当将值写入显示的帧缓冲区时，在渲染的最后阶段应用转换很重要。 如果在显示编码之后应用后期处理，则此类效果会在非线性值上计算，这通常是不正确的，并且经常会导致伪影。 可以将显示编码视为一种压缩形式，这可以最好地保留该值的感知效果[491]。 考虑这一领域的一个好方法是使用线性值来执行物理计算，每当我们要显示结果或访问可显示图像（例如颜色纹理）时，我们需要使用适当的编码或解码转换，将数据移入或移出其显示编码形式。

如果确实需要手动应用sRGB，则可以使用标准转换公式或一些简化版本。 实际上，显示是由每个颜色通道的bit数控制的，例如，对于消费者级别的显示器而言，bit数是8，从而给出了一组在[0,255]范围内的级别。 在这里，我们将显示编码的级别表示为[0.0,1.0]范围，而忽略bit数。 线性值也在[0.0，1.0]范围内，表示浮点数。 我们用x表示这些线性值，用y表示存储在帧缓冲区中的非线性编码值。 要将线性值转换为sRGB非线性编码值，我们应用sRGB显示传递函数的逆函数：
$$
y=f_{sRGB}^{-1}(x)=
\begin{cases}
\begin{align}
&1.055x^{1/2.4}-0.055,\quad \text{where} x >0.0031308,\\
&12.92x,\quad \text{where} x\leq 0.0031308,
\end{align}
\end{cases}
\qquad\qquad(5.30)
$$
​		x代表线性RGB三元组的通道。 该方程式适用于每个通道，这三个生成的值驱动显示。 如果您手动应用转换函数，请当心。 错误的一种来源是使用编码的颜色而不是线性形式，而另一种来源是对颜色进行两次解码或编码。

​		这两个变换表达式的底部是一个简单的乘法，这是由于数字硬件需要使变换完全可逆[1431]。顶部的表达式，涉及将值提升为幂的几乎适用于输入值x的整个范围[0.0，1.0]。 考虑到偏移量和缩放，此函数非常近似于一个更简单的公式[491]：
$$
y=f_{display}^{-1}(x)=x^{1/\gamma}
$$
​		$\gamma$= 2.2。 希腊字母$\gamma$是名称“伽玛校正”的基础。

​		正如必须对计算值进行编码以进行显示一样，在进行计算之前，必须将静态相机或摄像机捕获的图像转换为线性值。 您在显示器或电视上看到的任何颜色都有一些可通过屏幕捕获或颜色选择器获得的显示编码的RGB三元组。 这些值是以PNG，JPEG和GIF等文件格式存储的，这些格式可以直接发送到帧缓冲区以在屏幕上显示而无需转换。 换句话说，您在屏幕上看到的任何内容都是定义为显示编码的数据。 在着色计算中使用这些颜色之前，我们必须将这种编码形式转换回线性值。 从显示编码到线性值我们需要的sRGB转换：
$$
x=f_{sRGB}(y)=
\begin{cases}
\begin{align}
\left(
\frac{y+0.055}{1.055}
\right)^{2.4}, \text{where} y>0.04045,\\
\frac{y}{12.92},\text{where} y\leq 0.04045,
\end{align}
\end{cases}
\qquad\qquad(5.32)
$$
​		其中y表示标准化的显示通道值，即存储在图像或帧缓冲区中的值，表示为[0.0，1.0]范围内的值。 此解码函数与我们先前的sRGB公式相反。 这意味着，如果着色器访问纹理并输出纹理而未做任何更改，则其外观将与预期的一样。 解码函数与显示传递函数相同，因为存储在纹理中的值已被编码以正确显示。 我们没有为转换提供线性响应显示，而是为转换提供线性值。

​		更简单的伽玛显示传递函数是公式5.31的反函数
$$
x=f_{display}(y)=y^{\gamma}.\qquad\qquad(5.33)
$$
​		有时，您会看到一个更简单的转化对，尤其是在移动应用和浏览器应用中[1666]：
$$
\begin{align}
y=&f_{simpl}^{-1}(x)=\sqrt{x},\\
x=&f_{simpl}(y)=y^2;
\end{align}
\qquad\qquad(5.34)
$$
​		也就是说，取线性值的平方根进行转换以进行显示，而将其自身的多个值取反即可。 虽然粗略近似，但这种转换比完全忽略该问题要好。

​		如果我们不注意伽玛，则较低的线性值将在屏幕上显得太暗。 一个相关的错误是，如果不执行伽玛校正，某些颜色的色调可能会偏移。 假设我们的$\gamma$= 2.2。 我们要从显示的像素发出与线性计算值成正比的辐射，这意味着我们必须将线性值提高到（1 / 2.2）幂。 线性值0.1给出0.351，0.2给出0.481，而0.5给出0.730。 如果未编码，则按原样使用这些值将导致显示器发出的辐射比所需的少。 请注意，任何这些转换都始终不会更改0.0和1.0。 在使用伽玛校正之前，场景建模人员通常会人为地增加深色表面的颜色，并在逆显示变换中对其进行折叠。

​		忽略伽马校正的另一个问题是，以非线性值执行物理线性辐射度值正确的着色计算。 图5.40给出了一个示例。

![image-20191216231908818](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216231908818.png)

​		<font size=2>图5.40。 两个重叠的聚光灯照亮平面。 在左图像中，在将光值0.6和0.4相加后不执行伽马校正。 有效地对非线性值执行加法操作，从而导致错误。 请注意，左侧的光线看起来比右侧的光线明显明亮，并且重叠部分显得不切实际地明亮。 在右图中，相加后将对值进行伽玛校正。 灯光本身成比例地变亮，并且在重叠的地方可以正确组合。</font>

​		忽略伽玛校正也会影响抗锯齿边缘的质量。 例如，假设一个三角形的边缘覆盖了四个屏幕网格单元（图5.41）。 三角形的规范化辐射率为1（白色）； 背景为0（黑色）。 从左到右，单元格覆盖了$\frac{1}{8}$、$\frac{3}{8}$、$\frac{5}{8}$和$\frac{7}{8}$。因此，如果我们使用盒式滤镜，我们希望将像素的规范化线性辐射度表示为0.125、0.375、0.625和0.875。 正确的方法是对线性值执行抗锯齿，将编码函数应用于四个结果值。 如果不这样做，像素的代表辐射将太暗，从而导致边缘的变形，如图右侧所示。 这种伪影称为绕线，因为边缘看起来有点像扭绳[167，1265]。 图5.42显示了这种效果。

![image-20191216231931569](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216231931569.png)

​		<font size=2>图5.41。 在左侧，黑色（显示为灰色）背景上的白色三角形的边缘覆盖了四个像素，并显示了真实的区域覆盖率。 如果不执行伽玛校正，则中间色调的变暗会导致边缘的扭曲，如右图所示。</font>

![image-20191216231948366](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216231948366.png)

​		<font size=2>图5.42。 左侧的一组抗锯齿线经过了伽马校正； 在中间，该集合被部分校正； 在右边，没有伽马校正。 （图片由Scott R. Nelson提供。）</font>

​		sRGB标准创建于1996年，现已成为大多数计算机显示器的标准。 但是，从那时起，显示技术得到了发展。 已经开发出更明亮并且可以显示更多颜色的显示器。 在8.1.3节中讨论了彩色显示和亮度，在8.2.1节中介绍了高动态范围显示的显示编码。 哈特（Hart）的文章[672]特别详尽地提供了有关高级显示器的更多信息。

### 进一步阅读和资源

​		Pharr等[1413]更深入地讨论了采样模式和抗锯齿。 Teschner的课程笔记[1758]显示了各种采样模式生成方法。 Drobot [382，383]对实时抗锯齿进行了以前的研究，解释了各种技术的属性和性能。可以在相关的GRAGRAPH课程[829]的注释中找到有关各种形态抗锯齿方法的信息。 Reshetov和Jimenez [1486]提供了游戏中使用的形态学和相关时间抗锯齿工作的最新回顾。

​		对于透明性研究，我们再次请有兴趣的读者阅读McGuire的陈述[1182]和Wyman的著作[1931]。布林（Blinn）的文章“什么是像素？” [169]很好地浏览了计算机图形学的多个领域，同时讨论了不同的定义。 Blinn的“脏像素和符号，符号，符号”书籍[166，168]包含一些有关滤波和抗锯齿的介绍性文章，以及有关alpha，合成和gamma校正的文章。 Jimenez的演讲[836]详细介绍了抗锯齿技术。

​		Gritz和d'Eon [607]对伽玛校正问题进行了很好的总结。 Poynton的书[1431]对各种媒体中的伽玛校正以及其他与颜色有关的主题进行了详尽的介绍。塞兰（Selan）的白皮书[1602]是更新的资料，它解释了显示编码及其在电影行业中的用途，以及许多其他相关信息。

## 6.纹理
​		表面的纹理就是外观和感觉-只要想一想油画的质感。在计算机图形学中，纹理化是获取表面并使用某些图像，函数或其他数据源在每个位置修改其外观的过程。例如，不是精确地表示砖墙的几何形状，而是将砖墙的彩色图像应用于由两个三角形组成的矩形。查看矩形时，彩色图像显示在矩形所在的位置。除非观察者靠近墙壁，否则几何细节的缺失将不会引起注意。

​		但是，某些带纹理的砖墙可能会无法令人信服不仅因为缺乏几何形状而。例如，如果砂浆应该是哑光的，而砖是光滑的，那么观察者会注意到两种材料的粗糙度是相同的。为了产生更令人信服的体验，可以在表面上应用第二个图像纹理。根据表面上的位置，此纹理可以更改壁的粗糙度，而不是更改表面的颜色。现在，砖和灰浆的图像纹理具有颜色，而新纹理具有粗糙度值。

​		观看者可能会看到，现在所有的砖都是光滑的，而砂浆不是，但是请注意，每个砖的表面看起来都非常平坦。这看起来不对，因为砖的表面通常会有些不规则。通过应用凹凸贴图，可以改变砖的着色法线，以便在渲染砖时，它们看起来并不十分平滑。这种纹理会摆动矩形原始表面法线的方向，以用于计算光照。

​		从浅视角看，这种凹凸的错觉可能会出问题。砖块应突出在砂浆上方，以使其看不见。即使从直视角度看，砖块也应将阴影投射到砂浆上。视差贴图使用一个纹理在渲染时使平坦表面变形，而视差遮挡贴图将射线投射到高度场纹理上以提高真实感。位移贴图通过修改形成模型的三角形高度来真正位移表面。图6.1显示了带有颜色纹理和凹凸贴图的示例。

![image-20191216232142141](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191216232142141.png)

​		图6.1。 纹理。 将颜色和凹凸贴图应用于此鱼以增加其视觉细节水平。 （图片由Elinor Quittner提供。）

​		这些是使用越来越复杂的算法可以通过纹理解决的问题类型的示例。 在本章中，将详细介绍纹理化技术。 首先，介绍了纹理化过程的一般框架。 接下来，我们专注于使用图像对表面进行纹理化处理，因为这是实时工作中最流行的纹理化形式。 简要讨论了程序纹理，然后说明了使纹理影响表面的一些常用方法。

### 6.1纹理管线
​		纹理是一种用于有效地模拟表面材质和表面抛光度变化的技术。思考纹理的一种方法是考虑单个着色像素会发生什么。如上一章所述，通过考虑材质的颜色和灯光以及其他因素来计算着色。如果存在，透明度也会影响样本。纹理通过修改在着色方程式中使用的值来工作。这些值的更改方式通常基于表面上的位置。因此，对于砖墙示例，根据表面位置，表面上任意点的颜色使用砖墙图像中的相应颜色替换。纹理图像中的像素通常称为纹理像素，以区别于屏幕上的像素。粗糙度纹理会修改粗糙度值，而凹凸纹理会更改着色法线的方向，因此每个更改都会改变着色方程式的结果。
​		纹理可以通过广义纹理管线来描述。稍后将介绍许多术语，但请振作起来：将详细描述管线中的每一部分。
​		在空间中的位置是纹理过程的起点。该位置可以位于世界空间中，但通常位于模型的参照系中，因此随着模型的移动，纹理也随之移动。使用Kershaw的术语[884]，然后在空间上的这一点应用projector函数，以获得一组数字被称为纹理坐标，这些数字将用于访问纹理。此过程称为映射，这导致短语纹理映射。有时纹理图像本身称为纹理贴图，尽管这并非严格正确。
​		在使用这些新值访问纹理之前，可以使用一个或多个对应函数将纹理坐标转换为纹理空间。这些纹理空间位置用于从纹理中获取值，例如，它们可以是图像纹理的数组索引以检索像素。然后，取回的值可能会通过值转换函数再次进行转换，最后，这些新值将用于修改表面的某些属性，例如材质或着色法线。图6.2详细显示了应用单个纹理的过程。管道复杂的原因是每个步骤都为用户提供了有用的控制。应当指出，并非所有步骤都需要始终激活。

​		![image-20191218223755140](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218223755140.png)

​		<font size=2>图6.2。 单个纹理的广义纹理管线。</font>
​		使用该管道，当三角形具有砖墙纹理和在其表面上生成的样本时，就会发生这种情况（见图6.3）。找到对象的局部参照系中的（x，y，z）位置；说是（−2.3,7.1,88.2）。然后将projector函数应用于此位置。正如世界地图是将三维对象投影到二维中一样，此处的projector函数通常会将（x，y，z）向量更改为两个元素的向量（u，v）。此示例中使用的projector函数等效于正交投影（第2.3.1节），其作用类似于幻灯片投影仪，将砖墙图像照在三角形的表面上。回到墙上，可以将其表面上的一个点转换为一对值，范围从0到1。假设获得的值为（0.32，0.29）。这些纹理坐标将用于查找此位置的图像颜色。我们的砖纹理的分辨率为256×256，因此对应函数将（u，v）乘以256，得到（81.92，74.24）。丢掉这些分数，在砖墙图像中发现像素（81，74），并且颜色为（0.9，0.8，0.7）。纹理颜色位于sRGB颜色空间中，因此，如果要在着色方程式中使用该颜色，则将其转换为线性空间，得到（0.787，0.604，0.448）（第5.6节）。

​		![image-20191218223825748](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218223825748.png)

​		<font size=2>图6.3。 砖墙的管线。</font>

#### 6.1.1projector函数

​		纹理处理中第一步是获取表面的位置并将其投影到纹理坐标空间中，通常是二维（u，v）空间。建模包通常允许美工定义每个顶点的（u，v）坐标。这些可以从projector函数或网格展开算法中初始化。美工可以以编辑顶点位置的相同方式来编辑（u，v）坐标。projector函数通常通过将空间中的三维点转换为纹理坐标来工作。建模程序中常用的函数包括球形投影，圆柱形投影和平面投影[141、884、970]。

​		其他输入可用于projector函数。例如，可以使用表面法线确定一个用于该表面的平面投影方向从六个平面投影方向中。在面相接处的连接缝隙中会出现纹理匹配问题；Geiss[521，522]讨论了一种将它们融合的技术。 Tarini等[1740]描述了多立方体贴图，其中一个模型被映射到一组立方体投影，而不同体积的空间映射到不同的立方体。

​		其他projector函数根本不是投影，而是表面创建和细分的隐含部分。例如，参数化曲面具有合适的（u，v）值集合作为其定义的一部分。参见图6.4。纹理坐标也可以根据各种不同的参数生成，例如视野方向，表面温度或其他任何可想象的参数。projector函数的目标是生成纹理坐标。根据这些推导出位置只是实现这一目标的一种方法。

![image-20191218224123963](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218224123963.png)

​		<font size=2>图6.4。 不同的纹理投影。 从左到右显示了球形，圆柱形，平面和自然（u，v）投影。 底行显示了应用所有这些投影（没有自然投影）于单个对象。</font>

​		非交互式渲染器通常将这些projector函数称为渲染过程本身的一部分。单个projector函数可能足以满足整个模型的需要，但美术师通常必须使用工具来细分模型并分别应用各种projector函数[1345]。见图6.5。

![image-20191218224152251](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218224152251.png)

​		<font size=2>图6.5。 在单个模型上如何使用各种纹理投影。 盒子贴图由六个平面贴图组成，每个盒子面一个。 （图片由TitoPagán提供。）</font>

​		在实时工作中，通常在建模阶段应用projector函数，并将投影结果存储在顶点。这并非总是如此;有时在顶点或像素着色器中应用投影功能是有利的。这样做可以提高精度，并有助于启用各种效果，包括动画（第6.4节）。某些渲染方法（例如环境映射（第10.4节））具有自己的专用projector函数，这些函数按像素进行评估。

​		球形投影（图6.4的左侧）将点投射到以某个点为中心的假想球体上。此投影与Blinn和Newell的环境映射方案（第10.4.1节）中使用的投影相同，因此第407页的公式10.30描述了此函数。这种投影方法也遇到了该章节所述的顶点插值问题。

​		圆柱投影计算u纹理坐标的方式与球面投影相同，而v纹理坐标被计算为沿圆柱轴的距离。该投影对于具有自然轴的对象（例如旋转表面）很有用。当曲面与圆柱轴垂直时，会发生变形。

​		平面投影就像X射线束一样，沿着一个方向平行投影，并将纹理应用于所有表面。它使用正交投影（第4.7.1节）。例如，这种类型的投影可用于贴花（第20.2节）。

​		由于投影方向边缘的表面存在严重的变形，因此美工通常必须手动将模型分解为接近平面的部分。还有一些工具可以通过解开网格或创建一组接近最佳的平面投影来帮助最大程度地减少变形，或者通过其他方式帮助完成此过程。我们的目标是使每个多边形在纹理区域中享有更公平的份额，同时还要保持尽可能多的网格连接。连接性很重要，因为采样伪像可能沿着纹理的各个单独部分相遇的边缘出现。具有良好展开性的网格也使美工的工作更加轻松[970，1345]。 16.2.1节讨论了纹理变形如何对渲染产生不利影响。图6.6显示了用于创建图6.5中的雕像的工作空间。这种展开过程是网格参数化这一较大研究领域的一个方面。有兴趣的读者可以参考Hormann等人的SIGGRAPH课程笔记[774]。

![image-20191218224209890](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218224209890.png)

​		<font size=2>图6.6。 雕像模型的几个较小的纹理，保存为两个较大的纹理。 右图显示了三角形网格如何展开并显示在纹理上以帮助其创建。（图片由TitoPagán提供。）</font>

​		纹理坐标空间并不总是二维平面。有时是三维体积。在这种情况下，纹理坐标表示为三元素矢量（u，v，w），其中w为沿投影方向的深度。其他系统最多使用四个坐标，通常指定为（s，t，r，q）[885]； q用作齐次坐标中的第四个值。它的作用类似于电影或幻灯机，投影纹理的大小随距离而增加。例如，将装饰性聚光图案（称为gobo）投影到舞台或其他表面上这很有用[1597]。

​		纹理坐标空间的另一种重要类型是方向性，其中空间中的每个点都可以通过输入方向访问。可视化这种空间的一种方法是将其作为单位球体上的点，每个点的法线表示用于访问该位置纹理的方向。使用方向参数化的最常见纹理类型是立方体贴图（第6.2.4节）。

​		还值得注意的是，一维纹理图像和函数有其用途。例如，在地形模型上，可以通过高度确定颜色，例如低地是绿色。山峰是白色的。线条也可以纹理化；这样做的一种用途是将雨水渲染为一组带有半透明图像的长线。这种纹理对于从一个值转换为另一值，即作为查找表，也是有用的。

​		由于可以将多个纹理应用于一个表面，因此可能需要定义多组纹理坐标。 但是，如果应用坐标值，则思路是相同的：将这些纹理坐标插值到整个表面上，并用于检索纹理值。 但是，在插值之前，这些纹理坐标由corresponder函数进行转换。

#### 6.1.2corresponder函数

​		corresponder函数将纹理坐标转换为纹理空间位置。它们提供了将纹理应用于表面的灵活性。对corresponder函数的一个示例是使用API选择现有纹理的一部分进行显示。仅此而已子图像将在后续操作中使用。

​		corresponder函数的另一种类型是矩阵变换，可以将其应用于顶点或像素着色器。这样可以在表面上平移，旋转，缩放，剪切或投影纹理。如第4.1.5节所述，转换的顺序很重要。令人惊讶的是，纹理转换的顺序必须与预期的顺序相反。这是因为纹理变换实际上会影响空间，这个空间决定图像被查看的位置。图像本身不是转换的对象；定义图片位置的空间被更改。

​		另一类corresponder函数控制图像的应用方式。我们知道图像将出现在（u，v）在[0，1]范围内的表面上。但是超出此范围会发生什么？corresponder函数确定行为。在OpenGL中，这种类型的对应功能称为“包装模式”（wrapping mode）。在DirectX中，它称为“纹理寻址模式”（texture addressing mode）。这种类型的corresponder函数包括：

* wrap（包装（DirectX）），repeat（重复（OpenGL））或tile（平铺）——图像在整个表面上重复。 从算法上讲，将删除纹理坐标的整数部分。 此功能对于使材质的图像重复覆盖其表面很有用，通常是默认设置。

* mirror（镜像）——图像在整个表面上重复，但在其他所有重复上都是镜像的（翻转）。 例如，图像通常显示从0到1，然后在1和2之间反转，然后在2和3之间正常，然后反转，依此类推。 这提供了沿纹理边缘的某些连续性。

* clamp（钳制（DirectX））或clamp to edge（OpenGL）——超出[0，1]范围的值被钳制到该范围。 这导致图像纹理的边缘重复。 此功能对于避免在纹理的边缘附近发生双线性插值时意外从纹理的相反边缘获取样本[885]很有用。

* border（边框（DirectX））或clamp to border（OpenGL）——纹理坐标[0，1]外部使用单独定义的边框颜色进行渲染。 此功能可以很好地将贴图渲染到单色表面上。例如，贴图的边缘将与边框颜色平滑融合。

​		参见图6.7。 可以为每个纹理轴不同地分配这些corresponder函数，例如，纹理可以沿u轴重复并限制在v轴上。 在DirectX中，还有一次镜像（mirror once）模式，该模式沿着纹理坐标的零值镜像一次纹理，然后进行限制，这对于对称贴花很有用。

![image-20191218224506337](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191218224506337.png)

​		<font size=2>图6.7。 图像纹理重复，镜像，钳位和边框功能起作用。</font>

​		重复平铺纹理是向场景添加更多视觉细节的廉价方法。然而，当眼睛察觉到图案时，在重复大约三遍纹理之后，该技术通常看起来并不令人信服。避免此类周期性问题的常见解决方案是将纹理值与另一种非平铺纹理组合。如在安德森[40]描述的商业地形绘制系统中所见，这种方法可以大大扩展。在此系统中，将根据地形类型，高度，坡度和其他因素来组合多个纹理。纹理图像还与场景中放置几何模型（例如灌木和岩石）的位置有关。
避免周期性的另一种选择是使用着色器程序来实现专门的corresponder函数，该函数随机地重新组合纹理图案或图块。Wang tiles 是这种方法的一个例子。 Wang瓦片集是一小组具有匹配边缘的正方形瓦片。在纹理化过程中[1860]随机选择图块。 Lefebvre和Neyret [1016]使用相关的纹理读取和表格来实现相似类型的corresponder函数，以避免图案重复。

​		最后一个corresponder函数的应用是隐式的，它是从图像的大小得出的。通常在u和v的[0，1]范围内应用纹理。如砖墙示例所示，通过在该范围内将纹理坐标乘以图像的分辨率，可以获得像素位置。可以在[0，1]范围内指定（u，v）值的优点在于，可以交换具有不同分辨率的图像纹理，而不必更改存储在模型顶点处的值。

#### 6.1.3纹理值

​		在使用corresponder函数生成纹理空间坐标之后，使用坐标获取纹理值。对于图像纹理，这是通过访问纹理以从图像中检索纹素信息的方式来完成的。此过程在6.2节中进行了大量处理。图像纹理构成了实时工作中绝大多数的纹理使用，但是也可以使用程序函数。在程序纹理化的情况下，从纹理空间位置获取纹理值的过程不涉及内存查找，而是函数的计算。程序纹理化将在6.3节中进一步描述。

​		最简单的纹理值是用于替换或修改表面颜色的RGB三元组。类似地，可以返回单个灰度值。另一种返回的数据类型是RGBα，如第5.5节所述。 α（alpha）值通常是颜色的不透明度，它确定颜色可能影响像素的程度。也就是说，可以存储任何其他值，例如表面粗糙度。可以在图像纹理中存储许多其他类型的数据，这将在详细讨论凹凸贴图时看到（第6.7节）。

​		从纹理返回的值可以选择性地在使用前进行转换。这些转换可能在着色器程序中执行。一个常见的示例是将数据从无符号范围（0.0到1.0）重新映射到有符号范围（-1.0到1.0），该数据范围用于对存储在颜色纹理中的法线进行着色。

### 6.2图像纹理化

​		在图像纹理化中，将二维图像有效地粘贴到一个或多个三角形的表面上。我们已经完成了计算纹理空间位置的过程。现在，我们将解决在给定位置下的情况下从图像纹理获中获取纹理值的问题和算法。在本章的其余部分中，图像纹理将简称为纹理。另外，当我们在此处引用像素单元时，是指围绕该像素的屏幕网格单元。如第5.4.1节所述，像素实际上是显示的颜色值，该颜色值可能（并且应该为了更好的质量）受到与其关联的网格单元外部的样本的影响。

​		在本节中，我们特别关注快速采样和过滤纹理图像的方法。第5.4.2节讨论了混叠的问题，特别是在渲染对象边缘方面。纹理也可能存在采样问题，但是它们发生在要渲染的三角形内部。

​		像素着色器通过将纹理坐标值传递给诸如texture2D之类的调用来访问纹理。这些值在（u，v）纹理坐标中，由corresponder函数映射到[0.0,1.0]范围。 GPU负责将此值转换为纹素坐标。不同API中的纹理坐标系统之间有两个主要区别。在DirectX中，纹理的左上角为（0，0），右下角为（1，1）。这与存储图像数据的图像类型匹配，第一行是文件中的第一行。在OpenGL中，纹素（0，0）位于左下角，是DirectX的y轴翻转。纹素具有整数坐标，但是我们经常要访问纹素之间的位置并在其中混合。这提出了像素中心的浮点坐标是什么的问题。 Heckbert [692]讨论了如何有两种可能的系统：截断（truncating）和舍入（rounding）。 DirectX 9将每个中心定义为（0.0，0.0）——使用四舍五入。这个系统有些混乱，因为在DirectX的原点，左上像素的左上角的值是（-0.5，-0.5）。 DirectX 10向前更改到OpenGL系统，在该系统上，纹素的中心具有小数值（0.5,0.5）——截断，或更准确地说是落在地板上的分数。地板是一种更自然的系统，可以很好地映射到语言，例如，像素（5,9）为u坐标定义范围为5.0到6.0，为v定义范围为9.0到10.0。

​		在这一点上，一个值得解释的术语是依赖纹理读取，它有两个定义。第一种特别适用于移动设备。当通过texture2D或类似方法访问纹理时，每当像素着色器计算纹理坐标而不是使用从顶点着色器传入的未修改纹理坐标[66]时，就会发生依赖纹理读取。请注意，这意味着对传入的纹理坐标进行任何更改，甚至包括交换u和v值之类的简单操作。当着色器没有依赖纹理读取时，较早的不支持OpenGL ES 3.0的移动GPU可以更高效地运行，因为可以预取纹素数据。这个术语的另一个较旧的定义对于早期台式机GPU特别重要。在这种情况下，当一个纹理的坐标取决于某些先前纹理值的结果时，就会发生依赖纹理读取。例如，一种纹理可能会更改着色法线，进而改变用于访问立方体贴图的坐标。在早期的GPU上，这种功能受到限制甚至不存在。如今，此类读取可能会影响性能，具体取决于一个批处理中要计算的像素数量以及其他因素。有关更多信息，请参见第23.8节。

​		GPU中使用的纹理图像大小通常为$2^m\times2^n$纹素，其中m和n为非负整数。这些被称为二次幂（POT）纹理。现代GPU可以处理任意大小的非2幂（NPOT）纹理，从而可以将生成的图像视为纹理。但是，某些较旧的移动GPU可能不支持NPOT纹理的mipmapping（第6.2.2节）。图形加速器对纹理大小有不同的上限。例如，DirectX 12最多允许$16384^2$个纹素。

​		假设我们有一个256×256纹素的纹理，并且我们想将其用作正方形的纹理。只要屏幕上投影的正方形与纹理的大小大致相同，正方形的纹理看起来就几乎像原始图像。但是，如果投影的正方形覆盖了原始图像所包含像素的十倍（称为放大倍数），或者投影的正方形仅覆盖了屏幕的一小部分（缩小），会发生什么呢？答案是，这取决于您决定在这两种情况下使用哪种采样和过滤方法。

​		本章讨论的图像采样和滤波方法适用于从每个纹理读取的值。但是，理想的结果是防止最终渲染的图像出现锯齿，这在理论上需要对最终像素的颜色进行采样和过滤。这里的区别是过滤着色方程的输入或过滤其输出。只要输入和输出是线性相关的（对于诸如颜色的输入来说就是如此），那么过滤单个纹理值就等于过滤最终颜色。但是，存储在纹理中的许多着色器输入值（例如表面法线和粗糙度值）与输出具有非线性关系。标准纹理过滤方法可能不适用于这些纹理，从而导致锯齿。在9.13节中讨论了过滤这种纹理的改进方法。

#### 6.2.1放大倍数（Magnification）

​		在图6.8中，将大小为48×48纹素的纹理纹理化为正方形，并且就纹理大小而言，正方形被观察相当接近，因此底层图形系统必须放大纹理。放大倍数最常用的滤波技术是最近邻（nearest neighbor）（实际的滤波称为盒滤波器，请参见第5.4.1节）和双线性插值。还有三次卷积，它使用4×4或5×5纹素数组的加权和。这样可以实现更高的放大质量。尽管目前硬件尚不普遍支持三次卷积（也称为双三次插值），但是其可以在着色器程序中执行。

​		在图6.8的左侧部分，使用了最近邻居方法。这种放大技术的一个特点是单个纹素可能变得明显。将该现象称为像素化（pixelation），是因为该方法在放大时会采用距每个像素中心最近的纹素值，从而导致出现块状外观。尽管这种方法的质量有时很差，但每个像素仅需要提取一个纹理像素。

​		在同一图的中间图像中，使用了双线性插值（有时称为线性插值）。对于每个像素，这种滤波都会找到四个相邻的纹素，并在二维上进行线性插值，以找到像素的混合值。结果是模糊的，使用最近邻居方法产生的许多锯齿现象已消失。作为实验，请在斜视的同时尝试看左图像，因为它的效果与低通滤镜大致相同，并且可以使人脸显得更多。

​	![image-20191222215906075](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222215906075.png)

​		<font size=2>图6.8。 将48×48图像的纹理放大率放大到320×320像素。 左：最近邻居过滤，其中每个像素选择最近的纹素。 中：使用四个最近纹素的加权平均值进行双线性滤波。 右：使用5×5最近的纹素的加权平均值进行三次滤波。</font>

​		返回到第170页的砖纹理示例：在不删除分数的情况下，我们获得了$（p_u，p_v）=（81.92,74.24）$。我们在这里使用OpenGL的左下原点纹素坐标系，因为它与标准笛卡尔坐标系相匹配。我们的目标是在四个最接近的纹素之间进行插值，并使用其纹素中心定义一个纹素大小的坐标系。见图6.9。要找到四个最近的像素，我们从样本位置减去像素中心分数（0.5，0.5），得出（81.42，73.74）。除去小数部分，四个最接近的像素的范围从（x，y）=（81，73）到（x +1，y +1）=（82，74）。在我们的示例中，小数部分（0.42，0.74）是样品相对于以四个纹素中心形成的坐标系的位置。我们将此位置表示为$（u'，v'）$。

![image-20191222220021439](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222220021439.png)

​		<font size=2>图6.9。 双线性插值。涉及的四个纹素由左侧的四个正方形表示，纹理像素中心为蓝色。右边是由四个纹理像素的中心形成的坐标系。</font>

​		将纹理访问函数定义为$\mathbf{t}（x，y）$，其中x和y是整数，并返回的纹素的颜色。可以将任何位置$（u'，v'）$的双线性插值颜色计算为两步过程。首先，水平地（使用$u'$）对底部纹素$\mathbf{t}（x，y）$和$\mathbf{t}（x + 1，y）$进行插值，类似地，对最顶部的两个纹素$\mathbf{t}（x，y + 1）$和$\mathbf{t}（ x + 1，y + 1）$。对于底部的纹理像素，我们获得$（1 − u'）\mathbf{t}（x，y）+ u'\mathbf{t}（x + 1，y）$（图6.9中的底部绿色圆圈），对于顶部的像素，我们获得$（1 − u'）\mathbf{t}（x，y +1）+ u'\mathbf{t}（x +1，y +1）$（上方的绿色圆圈）。然后(使用$v'$)对这两个值进行垂直插值，因此在$（p_u，p_v）$处的双线性插值颜色$\mathbf{b}$为
$$
\begin{align}
\mathbf{b}(p_u,p_v)=(1 − v')
\begin{cases}
(1 − u')\mathbf{t}(x, y) + u'\mathbf{t}(x + 1, y)
\end{cases}\\
+v'
\begin{cases}
(1 − u')\mathbf{t}(x, y + 1) + u'\mathbf{t}(x + 1, y + 1)
\end{cases}\\
= (1−u')(1−v')\mathbf{t}(x,y)+u'(1−v')\mathbf{t}(x+1,y)\\
+(1 − u')v'\mathbf{t}(x, y + 1) + u'v'\mathbf{t}(x + 1, y + 1).
\end{align}
\qquad\qquad(6.1)
$$
​		直觉上，接近我们样本位置的纹素将对最终值产生更大的影响。这确实是我们在等式中看到的。在（x + 1，y + 1）处的右上纹素具有u'v'的影响。注意对称性：右上的影响等于由左下角和采样点形成的矩形的面积。回到我们的示例，这意味着从该纹素检索的值将乘以0.42×0.74，等于0.3108。从该纹素沿顺时针方向，其他乘数分别为0.42×0.26、0.58×0.26和0.58×0.74，所有这四个权重的总和为1.0。

​		解决随着放大倍率的模糊问题的常见方法是使用细节纹理。这些纹理代表了精细的表面细节，从手机上的划痕到地形上的灌木丛。这样的细节作为单独的纹理以不同的比例覆盖在放大的纹理上。细节纹理的高频重复图案与低频放大的纹理相结合，具有类似于使用单个高分辨率纹理的视觉效果。

​		双线性插值在两个方向上线性插值。但是，不需要单个线性插值。假设纹理由棋盘图案中的黑白像素组成。使用双线性插值可在整个纹理上提供变化的灰度样本。通过重新映射，例如，所有低于0.4的灰度都是黑色，所有高于0.6的灰度都是白色，并且将两者之间的灰度拉伸以填充间隙，纹理看起来更像是棋盘格，同时还使纹素之间有些融合。参见图6.10。

​		![image-20191222220129454](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222220129454.png)

​		<font size=2>图6.10。 通过使用相同的2×2棋盘纹理，通过重新映射，可以实现最近邻，双线性插值和部分中间。 请注意，由于纹理和图像网格不完全匹配，最近邻居采样如何给出略有不同的正方形大小。</font>

​		使用更高分辨率的纹理将具有类似的效果。例如，假设每个方格正方形由4×4纹素而不是1×1组成。在每个方格的中心周围，插值的颜色将完全是黑色或白色。

​		在图6.8的右侧，已使用了双三次过滤器，剩余的阻塞已被大大消除。应当注意，双三次滤波器比双线性滤波器更昂贵。但是，许多高阶滤波器可以表示为重复线性插值[1518]（另请参见第17.1.1节）。结果，纹理单元中用于线性插值的GPU硬件可以通过几次查找来被利用。

​		如果双三次滤波器被认为太昂贵了，奎尔兹[1451]提出了一种简单的技术，使用平滑曲线在一组2×2纹素之间进行插值。 我们首先描述曲线，然后描述技术。 两种常用曲线是平滑步幅曲线和五次曲线[1372]：
$$
\underbrace{s(x)=x^2(3-2x)}_\text{smoothstep}
\qquad \text{and}\qquad
\underbrace{q(x)=x^3(6x^2-15x+10)}_\text{quintic
}.
\qquad\qquad(6.2)
$$
​		这些在许多其他情况下非常有用，在这些情况下，您希望从一个值平滑地插值到另一个值。平滑步幅曲线具有s'（0）= s'（1）= 0的特性，并且在0和1之间平滑。五角曲线具有相同的特性，但q''（0）= q'' （1）= 0，即二阶导数在曲线的起点和终点也为0。两条曲线如图6.11所示。

![image-20191222220353075](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222220353075.png)

​		<font size=2>图6.11。 平滑步幅曲线s（x）（左）和五阶曲线q（x）（右）。</font>

​		该技术首先通过将样本乘以纹理尺寸并加0.5来计算$（u'，v'）$（与公式6.1和图6.9中使用方式相同）。保留整数部分以备后用，并将小数部分存储在$u'$和$v'$中，它们的范围为[0，1]。然后将$（u'，v'）$变换为$（t_u，t_v）=（q（u'），q（v'））$，但仍在[0，1]的范围内。最后，减去0.5，再将整数部分相加；然后，将所得的u坐标除以纹理宽度，v类似。在这一点上，新的纹理坐标与GPU提供的双线性插值查找配合使用。请注意，此方法将在每个纹素处产生平稳状态，这意味着，例如，如果这些纹素位于RGB空间中的平面上，则此类型的插值将给出平滑但仍然呈阶梯状的外观，但不一定总是想要的。见图6.12。

![image-20191222220411042](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222220411042.png)

​		<font size=2>图6.12。 四种放大一维纹理的方法。 橙色圆圈表示纹素的中心以及纹素值（高度）。 从左到右：最接近的邻居，线性，使用每对相邻纹理像素之间的五阶曲线，并使用三次插值。</font>

#### 6.2.2 缩小（Minification）

​		当纹理最小化时，几个纹素可能会覆盖一个像素单元，如图6.13所示。为了获得每个像素的正确颜色值，您应该整合影响像素的纹素的效果。但是很难精确地确定特定像素附近所有纹素的确切影响，并且实际上不可能实时地完美地做到这一点。

![image-20191222220611461](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222220611461.png)

​		<font size=2>图6.13。 缩小：通过一排像素单元的棋盘纹理正方形的视图，粗略显示了纹素数量如何影响每个像素。</font>

​		由于此限制，在GPU上使用了几种不同的方法。一种方法是使用最近邻居，它的工作原理与相应的放大滤波器完全相同，即，它选择在像素像单元中心可见的纹素。该滤波器可能会导致严重的混叠问题。在图6.14中，最上面的图使用了最近邻居。在地平线上，会出现伪影，因为只选择了影响单个像素的众多纹素之一来表示表面。当表面相对于观看者移动时，这些伪像甚至更加明显，并且是所谓的时间混叠的一种表现。

![image-20191222221013456](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221013456.png)

​		<font size=2>图6.14。 顶部图像是通过点采样（最近的邻居）渲染的，中心是mipmapping渲染的，底部是求和面积表的渲染。</font>

​		经常使用的另一个过滤器是双线性插值，工作原理还是与放大滤波器完全一样。该过滤器仅比最邻近的方法略胜一筹。它混合了四个纹素，而不是仅使用一个，但是当一个像素受到四个以上纹素的影响时，滤波器很快就会失效并产生锯齿。
​		更好的解决方案是可能的。 如第5.4.1节所述，可以通过采样和过滤技术解决混叠问题。 纹理的信号频率取决于其纹素在屏幕上的间隔。 由于奈奎斯特限制，我们需要确保纹理的信号频率不大于采样频率的一半。 例如，假设一张图像是由交替的黑白线组成的，相隔一个纹素。 波长为两个纹素宽（从黑线到黑线），因此频率为$\frac{1}{2}$。 为了在屏幕上正确显示此纹理，频率必须至少为$2×\frac{1}{2}$，即每个像素至少一个纹素。 因此，通常对于纹理，每个像素最多应有一个纹理像素以避免混叠。
​		为了达到这个目标，必须增加像素的采样频率或降低纹理频率。 前一章讨论的抗锯齿方法提供了提高像素采样率的方法。 但是，这些仅有限地增加了采样频率。 为了更充分地解决这个问题，已经开发了各种纹理缩小算法。
​		所有纹理抗锯齿算法背后的基本思想是相同的：预处理纹理并创建数据结构，这将有助于计算一个像素上一组纹素的效果的快速近似值。 对于实时工作，这些算法具有使用固定数量的时间和资源来执行的特征。 以此方式，每个像素获取固定数量的样本，并将其组合起来以计算一定数量（可能很大）的纹素的效果。

<font color =ff7200>多纹理映射（Mipmapping）</font>

​		最流行的纹理抗锯齿方法称为mipmapping [1889]。 现在已生产的所有图形加速器都以某种形式实现了该功能。 “ Mip”代表multum in parvo，拉丁语代表“小地方的许多东西”，这是一个过程的好名字，在该过程中，原始纹理被反复过滤成较小的图像。
​		当使用mipmapping最小化滤波器时，在进行实际渲染之前，使用一组较小版本的纹理增强原始纹理。 纹理（级别0）被下采样到原始面积的四分之一，每个新的纹素值通常计算为原始纹理中四个相邻纹素的平均值。 新的级别1纹理有时称为原始纹理的子纹理。 递归执行缩小操作，直到纹理的一个或两个维度等于一个纹素。 此过程如图6.15所示。 整个图像集通常称为mipmap链。

![image-20191222221033523](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221033523.png)

​		<font size=2>图6.15。 通过在金字塔的底部拍摄原始图像（级别0），然后平均每个2×2区域为下一级别的纹素值，即可形成mipmap。 垂直轴是第三个纹理坐标分量d。 在该图中，d不是线性的。 它衡量用于插值样本的两个纹理级别。</font>

​		形成高质量Mipmap的两个重要元素是良好的过滤和伽马校正。形成Mipmap级别的常见方法是获取每2×2组纹素，并将它们平均以得到Mip像素值。这样，使用的滤波器便是盒式滤波器，它可能是最差的过滤器之一。这可能会导致质量差，因为它会不必要地模糊低频，同时保留一些会引起混叠的高频[172]。最好使用高斯，Lanczos，Kaiser或类似的滤波器。快速，免费的源代码以存在并可用于任务[172，1592]，并且某些API在GPU本身上支持更好的过滤。在纹理边缘附近，在过滤过程中必须注意纹理是重复的还是单个复制。

​		对于在非线性空间中编码的纹理（例如大多数颜色纹理），忽略伽玛校正当过滤会修改感知到的Mipmap级别的亮度[173，607]。当您离对象越来越远并且使用了未经校正的mipmap时，对象的整体外观可能会更暗，并且对比度和细节也会受到影响。因此，重要的是将此类纹理从sRGB转换为线性空间（第5.6节），在该空间中执行所有mipmap过滤，然后将最终结果转换回sRGB颜色空间以进行存储。大多数API支持sRGB纹理，因此将在线性空间中正确的生成mipmap，并将结果存储在sRGB中。访问sRGB纹理时，首先将它们的值转换到线性空间，以便正确执行放大和缩小。

​		如前所述，某些纹理与最终的着色颜色基本上具有非线性关系。 尽管这通常会给过滤带来问题，但由于要过滤数百或数千个像素，因此mipmap生成对此问题特别敏感。 为了获得最佳结果，通常需要专门的mipmap生成方法。 此类方法在第9.13节中进行了详细说明。

​		构造纹理时访问此结构的基本过程很简单。屏幕像素将纹理自身上的区域包围起来。当像素区域投影到纹理上时（图6.16），它包含一个或多个纹素。严格来说，使用像素单元的边界不是严格正确的方法，但此处使用它来简化演示。单元外部的纹素可能会影响像素的颜色。请参阅第5.4.1节。目的是大致确定多少纹理会影响像素。有两种用于计算d的常用量度（OpenGL将其称为λ，也称为细节的纹理级别）。一种方法是使用像素单元所形成的四边形的较长边缘来近似像素的覆盖范围[1889]；另一种方法是使用四个微分∂u/∂x，∂v/∂x，∂u/∂y和∂v/∂y的最大绝对值作为度量[901，1411]。每个微分是纹理坐标相对于屏幕轴的变化量的量度。例如，∂u/∂x是一个像素的u纹理值沿x屏幕轴的变化量。有关这些方程式的更多信息，请参见Williams的原始文章[1889]或Flavell [473]或Pharr[1411]的文章。 McCormack等[1160]讨论了通过在混叠中引入最大绝对值方法，并提出了一个替代公式。 Ewins等[454]分析了质量相当的几种算法的硬件成本。

![image-20191222221049435](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221049435.png)

​		<font size=2>图6.16。 左侧是一个正方形像素单元及其纹理视图。 右边是像素单元在纹理上其自身的投影。</font>

​		使用Shader Model 3.0或更高版本的像素着色器程序可以使用这些渐变值。由于它们基于相邻像素值之间的差异，因此在受动态流控制影响的像素着色器部分中无法访问它们（第3.8节）。为了在这样的部分中（例如，在循环内）执行纹理读取，必须较早地计算导数。请注意，由于顶点着色器无法访问渐变信息，因此在使用顶点纹理时，需要在顶点着色器本身中计算渐变或LOD并将其提供给GPU。

​		计算坐标分量d的目的是确定沿mipmap的金字塔轴进行采样的位置。见图6.15。目标是达到奈奎斯特速率的像素与纹素比至少为1：1。这里的重要原理是，随着像素单元包含更多的纹素和d的增加，将访问较小，模糊的纹理版本。（u，v，d）三元组用于访问mipmap。值d与纹理级别类似，但是d是级别之间的距离的小数，而不是整数值。采样高于d位置的纹理级别和低于d位置的级别。 （u，v）位置用于从这两个纹理级别的每一个中检索一个双线性插值样本。然后根据从每个纹理级别到d的距离对生成的样本进行线性插值。整个过程称为三线性插值，而且每个像素执行一次。

​		用户在d坐标分量上的一个控制是控制细节偏差（LOD偏差）的水平。这是与d相加的值，因此会影响纹理的相对清晰度。如果我们进一步向上移动金字塔以开始（增大d），则纹理将显得模糊。对于任何给定的纹理，良好的LOD偏差将随图像类型及其使用方式而变化。例如，开始时有些模糊的图像可能会使用负偏差，而用于纹理化的过滤效果差（混叠）的合成图像可能会使用正偏差。可以为纹理整体或像素着色器中的每个像素指定偏差。为了更好地控制，用户可以提供d坐标或计算它的导数。

​		mipmapping的好处在于，访问并插值了预先组合的像素集，而不是试图对影响像素的所有像素进行求和。无论缩小多少，此过程都会花费固定的时间。但是，mipmapping有几个缺陷[473]。一个主要的是模糊。想象一下，一个像素单元在u方向上覆盖大量纹素，而在v方向上仅覆盖少数纹素。这种情况通常发生在观看者近乎边缘地沿着带纹理的表面看时。实际上，可能需要沿着纹理的一个轴进行最小化，而沿着另一个轴进行放大。访问mipmap的效果是检索了纹理上的正方形区域。无法检索矩形区域。为避免混淆，我们选择纹理上像素单元的近似覆盖范围的最大度量。这导致检索到的样本通常相对模糊。在图6.14的mipmap图像中可以看到这种效果。移到右侧距离的线显示为模糊。

<font color=ff7200>求和面积表</font>

​		避免过度模糊的另一种方法是求和面积表（SAT）[312]。 要使用此方法，首先要创建一个数组，该数组的大小与纹理大小相同，但包含更多的精度bit为了颜色存储（例如，红色，绿色和蓝色分别为16bit或更多）。 在此数组的每个位置，必须计算并存储所有相应纹理的纹理像素的总和在矩形中，该矩形由该位置和纹理像素（0，0）（原点）形成。 在纹理化过程中，像素单元在纹理上的投影由矩形限制。 然后访问求和面积表以确定该矩形的平均颜色，该颜色作为像素的纹理颜色传回。 使用图6.17所示的矩形的纹理坐标计算平均值。 这可使用公式6.3中给出的公式完成：
$$
\mathbf{c}=\frac{\mathbf{s}[X_{ur},y_{ur}]-\mathbf{s}[x_{ur},y_{ll}]-
\mathbf{s}[x_{ll},y_{ur}]+\mathbf{s}[x_{ll},y_{ll}]}
  {(x_{ur}-x_{ll})(y_{ur}-y_{ll})}.
\qquad\qquad(6.3)
$$
​		![image-20191222221136160](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221136160.png)

​		<font size=2>图6.17。 像素单元反投影到纹理上，并由矩形限制； 矩形的四个角用于访问求和面积表。</font>

​		在此，x和y是矩形的纹素坐标，而$\mathbf{s} [x，y]$是该纹素的求和面积值。该方程的工作原理是：从右上角到原点，取整个区域的总和，然后通过减去相邻角的贡献，减去面积A和B。区域C已被减去两次，因此将其添加到左下角。请注意$（x_{ll}，y_{ll}）$是区域C的右上角，即$（x_{ll} + 1，y_{ll} + 1）$是边界框的左下角。

​		使用求和面积表的结果如图6.14所示。到达水平的线在右边缘附近更锐利，但中间的对角交叉线仍然模糊不清。问题是，当沿着纹理的对角线观察纹理时，会生成一个大矩形，其中许多纹素不位于要计算的像素附近。例如，假设一个长而细的矩形代表像素单元的反投影，该像素在图6.17的整个纹理对角线上。将返回整个纹理矩形的平均值，而不只是像素单元内的平均值。

​		求和面积表是所谓的各向异性过滤算法的一个例子[691]。这样的算法在非正方形区域上检索纹素值。但是，SAT能够在主要水平和垂直方向上最有效地做到这一点。还要注意，求和面积表对大小为16×16或更小的纹理的占用内存至少是其两倍，而较大的纹理则需要更高的精度。

​		求和面积表可以在现代GPU上实现，并以合理的整体内存消耗提供更高的质量[585]。改进的过滤对于高级渲染技术的质量至关重要。例如，Hensley等[718，719]提供了一种高效的实现方式，并展示了总面积采样如何改善光泽反射。可以通过SAT改进使用区域采样的其他算法，例如景深[585，719]，阴影贴图[988]和模糊反射[718]。

<font color=ff7200>无约束各向异性滤波</font>

​		对于当前的图形硬件，进一步改善纹理过滤的最常用方法是重用现有的mipmap硬件。基本思想是对像素单元进行反投影，然后对纹理上的这个四边形（四边形）进行几次采样，然后对样本进行合并。如上所述，每个mipmap样本都有一个位置和一个与其关联的正方形区域。该算法不使用单个mipmap样本来近似该四边形的覆盖范围，而是使用几个正方形覆盖四边形。可以使用四边形的较短边来确定d（不同于mipmapping中通常使用较长边的地方）；这会使每个Mipmap样本的平均面积变小（从而减少模糊）。四边形的较长边用于创建一条平行于较长边并穿过四边形中间的各向异性线。当各向异性的量在1：1和2：1之间时，沿着这条线采集两个样本（见图6.18）。在较高的各向异性比率下，沿轴将获取更多的样本。

​		![image-20191222221156723](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221156723.png)

​		<font size=2>图6.18。 各向异性过滤。 像素单元的反投影产生四边形。 在较长的边之间形成各向异性线。</font>

​		这种方案允许各向异性线在任何方向上运行，因此没有求和面积表的限制。它也不需要比mipmaps更多的纹理内存，因为它使用mipmap算法进行采样。各向异性过滤的一个例子如图6.19所示。

​		![image-20191222221210729](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221210729.png)

​		<font size=2>图6.19。 Mipmap与各向异性过滤。 左侧完成了三线性mipmapping，右侧进行了16：1各向异性过滤。 展望未来，各向异性过滤可提供更清晰的结果，同时具有最小的混叠。 （图片来自three.js示例webgl材料纹理各向异性[218]。）</font>

​		Schilling等人首先提出了沿轴采样的想法与他们的Texram动态存储设备[1564]。 Barkans描述了该算法在Talisman系统中的用法[103]。 McCormack等人提出了一个类似的系统，称为Feline。 [1161]。 Texram的原始方案是沿各向异性轴（也称为探针）的样品赋予相同权重。 Talisman在轴的相对两端将两个探针的重量减半。 Feline使用高斯滤波器内核对一组探针加权。 这些算法采用了高质量的软件采样算法，例如椭圆加权平均（EWA）滤波器，该滤波器将像素的影响区域转换为纹理上的椭圆，并通过滤波器内核对椭圆内的纹素进行加权[691]。 Mavridis和Papaioannou提出了几种在GPU上使用着色器代码实现EWA过滤的方法[1143]。

#### 6.2.3体积纹理

​		图像纹理的直接扩展是通过（u，v，w）（或（s，t，r）值）访问的三维图像数据。例如，医学成像数据可以被作为为三维网格生成。通过在该网格中移动多边形，可以查看这些数据的二维切片。一个相关的想法是以这种形式表示体积光。通过找到其在该体积内的位置值以及和光的方向组合，可以找到表面上某个点的照明。

​		大多数GPU支持对体积纹理进行mipmapping。由于在体积纹理的单个mipmap级别内进行过滤涉及三线性插值，因此在mipmap级别之间进行过滤需要四线性插值。由于这涉及对16个纹素的结果进行平均，因此可能会导致精度问题，可以使用更高精度的体积纹理来解决。 Sigg和Hadwiger [1638]讨论了与体积纹理有关的这个问题和其他问题，并提供了执行滤波和其他操作的有效方法。

​		尽管体积纹理具有更高的存储要求，并且过滤成本更高，但它们确实具有一些独特的优势。由于可以将三维位置直接用作纹理坐标，因此可以跳过为三维网格找到良好的二维参数化的复杂过程。这避免了二维参数化中常见的变形和接缝问题。体积纹理也可以用于表示诸如木材或大理石的材质的体积结构。具有这种纹理的纹理模型显得似乎是用这种材料雕刻而成的。

​		由于不使用绝大多数样本，因此使用体积纹理进行表面纹理化的效率非常低。 Benson和Davis [133]和DeBry等人[334]讨论了在稀疏八叉树结构中存储纹理数据。此方案非常适合交互式三维绘画系统，因为在创建时不需要为表面分配明确的纹理坐标，并且八叉树可以将纹理细节保持在所需的任何级别。 Lefebvre等[1017]讨论了在现代GPU上实现八叉树纹理的细节。 Lefebvre和Hoppe [1018]讨论了将稀疏体积数据打包为明显较小的纹理的方法。

#### 6.2.4立方体贴图

​		另一类纹理是立方体纹理或立方体贴图，它具有六个正方形纹理，每个纹理与一个立方体的一个面相关联。 使用三分量纹理坐标向量访问立方体贴图，该向量的方向为从立方体中心向外指向的射线方向。 射线与立方体相交的点如下。 选择具有最大幅度的纹理坐标相应的面（例如，矢量（-3.2,5.1，-8.4）选择-z面）。 其余两个坐标除以最大幅度坐标的绝对值，即8.4。 它们现在的范围是-1到1，并且只需将其重新映射到[0，1]即可计算纹理坐标。 例如，坐标（-3.2，5.1）映射为（（-3.2 / 8.4 + 1）/ 2，（5.1 / 8.4 + 1）/ 2）≈（0.31，0.80）。 立方体贴图可用于表示作为方向函数的值。 它们最常用于环境映射（第10.4.3节）。

#### 6.2.5纹理表示

​		当处理应用程序中的许多纹理时，有几种方法可以提高性能。纹理压缩在第6.2.6节中介绍，而本节的重点是纹理图集，纹理数组和无绑定纹理，所有这些目的都是为了避免在渲染时更改纹理的成本。在19.10.1和19.10.2节中，描述了纹理流和转码。

​		为了能够为GPU分配尽可能多的工作，通常建议尽可能少地改变状态（第18.4.2节）。为此，可以将多个图像放入一个较大的纹理中，称为纹理图集。这在图6.20的左侧说明。注意，子纹理的形状可以是任意的，如图6.6所示。 Noll和Stricker [1286]描述了子纹理放置图集的优化。由于mipmap的上层可能包含几个单独的，不相关的形状，因此也需要注意mipmap的生成和访问。 Manson和Schaefer [1119]提出了一种通过考虑表面的参数化来优化mipmap创建的方法，该方法可以产生明显更好的结果。 Burley和Lacewell [213]提出了一个称为Ptex的系统，其中细分曲面中的每个四边形都有自己的小纹理。优点是，这避免了在网格上分配唯一的纹理坐标，并且在纹理图集的不连续部分的接缝处没有伪影。为了能够跨四边形进行过滤，Ptex使用了邻接数据结构。当最初的目标是生产渲染时，Hillesland [746]提出了packed Ptex,，它将每个面的子纹理放入纹理集，并使用相邻面的填充来避免过滤时的间接性。 Yuksel [1955]提出了网格颜色纹理，该纹理在Ptex上有所改进。 Toth [1780]通过实现一种方法，在过滤器taps超出[0，1]^2的范围时将其丢弃，从而为类Ptex系统提供了跨面的高质量过滤。

​		![image-20191222221547478](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222221547478.png)

​		<font size=2>图6.20。 左：一个纹理图集，其中将九个较小的图像合成为一个大纹理。 正确：一种更现代的方法是将较小的图像设置为纹理数组，这是大多数API中都存在的概念。</font>

​		使用图集的一个难点是环绕/重复和镜像模式，这不会适当地影响子纹理，而只会影响整个纹理。为图集生成Mipmap时，可能会发生另一个问题，其中一个子纹理会渗入另一个子纹理。但是，可以通过在将每个子纹理放入大型纹理集之前分别为它们生成mipmap层次结构，并对子纹理使用2的幂次分辨率来避免这种情况[1293]。

​		解决这些问题的一种更简单的解决方案是使用一种称为纹理数组的API构造，该构造完全避免了mipmapping和重复模式的任何问题[452]。参见图6.20的右侧。纹理数组中的所有子纹理都必须具有相同的尺寸，格式，mipmap层次结构和MSAA设置。就像纹理图集一样，仅对纹理数组执行一次设置，然后可以在着色器中使用索引访问任何数组元素。这比绑定每个子纹理[452]快5倍。

​		API还支持无绑定纹理[1407]，这也可以帮助避免状态更改成本。如果没有无绑定纹理，则使用API将纹理绑定到特定的纹理单元。一个问题是纹理单元数量的上限，这使程序员感到麻烦。驱动程序确保纹理常驻于GPU端。对于无绑定纹理，纹理数量没有上限，因为每个纹理仅由一个64位指针（有时称为“句柄”）与其数据结构相关联。可以通过许多不同方式来访问这些句柄，例如，通过uniforms，通过变化的数据，其他纹理或从着色器存储缓冲区对象（SSBO）。应用程序需要确保纹理驻留在GPU端。无绑定纹理避免了驱动程序中的任何类型的绑定成本，从而使渲染速度更快。

#### 6.2.6纹理压缩

​		一种直接攻击内存和带宽问题以及缓存问题的解决方案是固定速率纹理压缩[127]。通过让GPU即时解码压缩的纹理，纹理可以需要更少的纹理内存，因此可以增加有效的缓存大小。至少同样重要的是，此类纹理的使用效率更高，因为它们在访问时消耗的内存带宽更少。一个相关但不同的用例是添加压缩以提供更大的纹理。例如，在$512^2$分辨率下每纹素使用3字节的非压缩纹理将占用768 kB。使用纹理压缩时，压缩比为6：1，$1024^2$纹理将仅占用512 kB。

​		图像文件格式（例如JPEG和PNG）中使用了多种图像压缩方法，但是在硬件中对其进行解码是昂贵的（尽管有关纹理转码的信息，请参见第19.10.1节）。 S3开发了一种称为S3纹理压缩（S3TC）[1524]的方案，该方案被选作DirectX的标准，并称为DXTC。在DirectX 10中，它称为BC（用于块压缩）。此外，它是OpenGL中的事实上的标准，因为几乎所有GPU都支持它。它的优点是可以创建固定大小的压缩图像，具有独立编码的片段，并且解码简单（因此快速）。图像的每个压缩部分都可以独立处理。没有共享的查找表或其他依赖项，从而简化了解码。

​		DXTC / BC压缩方案有七个变量，它们具有一些共同的属性。编码是在4×4纹素块（也称为图块）上完成的。每个块被单独编码。编码基于插值。对于每个编码量，存储两个参考值（例如，颜色）。将为该块中的每16个纹理像素保存一个插值因子。它沿着两个参考值之间的直线选择一个值，例如等于或从两个存储的颜色插值的颜色。压缩来自仅存储的两种颜色以及每个像素较短的索引值。

|   名字   |   存储   | 参考颜色 |  指数  |  Alpha   | 注解          |
| :------: | :------: | :------: | :----: | :------: | ------------- |
| BC1/DXT1 | 8B/4bpt  |    G     |  2bpt  |    -     | 1行           |
| BC2/DXT3 | 16B/8bpt | RGB565x2 |  2bpt  |  4bpt行  | 颜色和BC1一样 |
| BC3/DXT5 | 16B/8bpt | RGB565x2 |  2bpt  | 3bpt插值 | 颜色和BC1一样 |
|   BC4    | 8B/4bpt  |   R8x2   |  3bpt  |    -     | 1通道         |
|   BC5    | 16B/8bpt |    G     | 2x3bpt |    -     | 2xBC4         |
|   BC6H   | 16B/8bpt |  见文本  | 见文本 |    -     | 对于HDR1-2线  |
|   BC7    | 8B/4bpt  |  见文本  | 见文本 |   可选   | 1-3线         |

​		<font size=2>表6.1。 纹理压缩格式。 所有这些压缩块均为4×4纹素。 存储列显示每个块的字节数（B）和每个纹素的位数（bpt）。 参考颜色的表示法是首先是通道，然后是每个通道的位数。 例如，RGB565表示红色和蓝色为5位，而绿色通道为6位。</font>

​		确切的编码在这七个变量之间有所不同，表6.1中总结了这些变量。请注意，“ DXT”表示DirectX 9中的名称，“ BC”表示DirectX 10及更高版本中的名称。从表中可以看出，BC1具有两个16位参考RGB值（5位红色，6个绿色，5个蓝色），每个纹素具有2位插值因子，可以从参考值之一或两个中间值中进行选择。备用DXT1模式为透明像素保留四个可能的插值因子中的一个，从而将插值的数量限制为三个，即两个参考值及它们的平均值。与未压缩的24位RGB纹理相比，它表示6：1的纹理压缩率。 BC2以与BC1相同的方式对颜色进行编码，但为量化（raw）alpha值每纹素（bpt）添加4位。对于BC3，每个块都具有与DXT1块相同的RGB数据编码。另外，使用两个8位参考值和每个纹素3位插值因子对alpha数据进行编码。每个纹素可以选择参考alpha值之一或六个中间值之一。 BC4具有一个单一通道，像BC3中的alpha那样编码。 BC5包含两个通道，每个通道都像BC3中那样进行编码。

​		BC6H用于高动态范围（HDR）纹理，其中每个纹素初始化每个R，G和B通道都有16位浮点值。此模式使用16个字节，导致8 bpt。它具有用于单行的一种模式（类似于上述技术），以及用于两行的另一种模式，其中每个块可以从一小组分区中进行选择。两种参考颜色也可以进行增量编码以获得更高的精度，并且根据所使用的模式，它们也可以具有不同的精度。在BC7中，每个块可以包含一到三行，并存储8 bpt。目标是8位RGB和RGBA纹理的高质量纹理压缩。它与BC6H共享许多属性，但是是LDR纹理的格式，而BC6H是HDR的格式。请注意，在OpenGL中，BC6H和BC7分别称为BPTC_FLOAT和BPTC。这些压缩技术可以应用于立方体或体积纹理以及二维纹理。

​		这些压缩方案的主要缺点是它们是有损的。也就是说，通常无法从压缩版本中检索原始图像。对于BC1-BC5，仅使用四个或八个插值来表示16个纹素。如果图块中包含大量不同的值，则会有一些损失。实际上，如果正确使用，这些压缩方案通常会提供可接受的图像保真度。

​		BC1-BC5的问题之一是，用于块的所有颜色都位于RGB空间中的线上。例如，红色，绿色和蓝色不能在一个单独的块中表示。 BC6H和BC7支持更多的线路，因此可以提供更高的质量。

​		对于OpenGL ES，另一种称为爱立信纹理压缩（ETC）[1714]的压缩算法被选择并包含在API中。该方案具有与S3TC相同的功能，即快速解码，随机访问，无间接查找和固定速率。它将4×4纹素的块编码为64位，即每个纹素使用4位。基本思想如图6.21所示。每个2×4块（或4×2块，取决于哪个能提供最佳质量的块）都存储基础颜色。每个块还从一个小的静态查找表中选择由四个常量组成的集合，并且块中的每个纹素都可以选择添加该表中的一个值。这修改了每个像素的亮度。图像质量与DXTC相当。

​		![image-20191222223513995](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222223513995.png)

​		<font size=2>图6.21。 ETC（爱立信纹理压缩）对像素块的颜色进行编码，然后修改每个像素的亮度以创建最终的纹理像素颜色。 （图像由Jacob Ström压缩。）</font>

​		在OpenGL ES 3.0中包含的ETC2 [1715]中，未使用的位组合用于向原始ETC算法添加更多模式。未使用的位组合是压缩表示（例如64位），其被解压缩为与另一压缩表示相同的图像。例如，在BC1中，将两个参考颜色设置为相同是没有用的，因为这将指示恒定的色块，只要一个参考颜色包含该恒定颜色，则可以依次获得该恒定色块。在ETC中，还可以从具有带符号数字的第一种颜色开始对一种颜色进行增量编码，因此计算可能会上溢或下溢。这种情况被用来表示其他压缩模式。 ETC2添加了两种具有四种颜色的新模式，每个块具有不同的颜色，最后一种模式是RGB空间中的一个平面，用于处理平滑过渡。爱立信Alpha压缩（EAC）[1868]压缩具有一个分量（例如Alpha）的图像。这种压缩类似于基本的ETC压缩，但仅用于一个分量，因此，生成的图像每个纹素存储4位。可以选择将其与ETC2结合使用，此外，可以使用两个EAC通道来压缩法线（有关此主题的更多信息，请参见下文）。所有ETC1，ETC2和EAC都是OpenGL 4.0核心配置文件，OpenGL ES 3.0，Vulkan和Metal的一部分。

​		压缩法线贴图（在第6.7.2节中讨论）需要格外小心。 专为RGB颜色设计的压缩格式通常不适用于法线xyz数据。 大多数方法都利用这样的事实，即已知法线为单位长度，并进一步假设其z分量为正（正切空间法线的合理假设）。 这允许仅存储法线的x和y分量。 z分量是动态导出的
$$
n_z=\sqrt{1-n_{x}^2-n_y^2}.
\qquad\qquad(6.4)
$$
​		由于仅存储两个分量，而不是三个，因此它本身导致适度的压缩。由于大多数GPU本身都不支持三分量纹理，因此这也避免了浪费分量的可能性（或必须在第四分量中包装其他数量的分量）。通常通过将x和y分量存储在BC5 / 3Dc格式的纹理中来实现进一步的压缩。参见图6.22。由于每个块的参考值划分了最小和最大x分量和y分量值，因此可以将它们视为定义在xy平面上的边界框。三bit插值因子允许在每个轴上选择八个值，因此将边界框划分为8×8的可能法线网格。或者，可以使用两个EAC通道（分别用于x和y），然后按照上述定义计算z。

​		![image-20191222223607411](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222223607411.png)

​		<font size=2>图6.22。 左：球体上的法线单位只需要编码x和y分量。 右：对于BC4 / 3Dc，xy平面中的一个框将法线围起来，每4×4个法线块可在此框内使用8×8个法线（为清楚起见，此处仅显示4×4个法线）。</font>

​		在不支持BC5 / 3Dc或EAC格式的硬件上，常见的方法[1227]是使用DXT5格式的纹理并将两个分量存储在绿色和alpha分量中（因为这些组件的存储精度最高）。其他两个分量未被使用。

​		PVRTC [465]是Imagination Technology的称为PowerVR的硬件上可用的纹理压缩格式，其最广泛的用途是用于iPhone和iPad。它为每个纹素提供2位和4位的方案，并压缩4×4纹素的块。关键思想是提供图像的两个低频（平滑）信号，这些信号是使用相邻的像素数据块和插值获得的。然后，每个纹素使用1或2位在图像上的两个信号之间进行插值。

​		自适应可伸缩纹理压缩（ASTC）[1302]的不同之处在于，它将n×m纹素的块压缩为128位。块大小从4×4到12×12不等，这导致了不同的比特率，从每纹素低至0.89位，到每纹素高达8位。 ASTC使用多种技巧来实现紧凑的索引表示，并且每个块可以选择行数和端点编码。此外，ASTC可以处理每个纹理1至4个通道以及LDR和HDR纹理。 ASTC是OpenGL ES 3.2及更高版本的一部分。

​		上面介绍的所有纹理压缩方案都是有损的，并且在压缩纹理时，可以在此过程上花费不同的时间。花费数秒甚至数分钟进行压缩，可以获得更高的质量。因此，这通常是作为离线预处理完成的，并存储起来供以后使用。另外，压缩方案可能只花费几毫秒的时间，但结果质量较低，但是纹理可以实时压缩并立即使用。一个例子是天空盒（第13.3节），当云层可能已经略微移动了，就会每隔一秒左右就会重新生成一次。解压缩非常快，因为它是使用固定功能的硬件完成的。这种差异称为数据压缩不对称，其中压缩可以而且确实比解压缩花费更长的时间。

​		Kaplanyan [856]提出了几种可以改善压缩纹理质量的方法。对于包含颜色和法线贴图的纹理，建议对贴图使用每个分量16位进行创作。对于颜色纹理，方法然后执行直方图重归一化（在这16位上），然后使用着色器中的比例和偏置常数（每个纹理）反转其效果。直方图归一化是一种将图像中使用的值扩展到整个范围的技术，这实际上是一种对比度增强。每个分量使用16位可确保重新规范化后直方图中没有闲置的狭缝，从而减少了许多纹理压缩方案可能引入的条带失真。如图6.23所示。此外，如果75％的纹素高于116/255，Kaplanyan建议对纹理使用线性颜色空间，否则将纹理存储在sRGB中。对于法线贴图，他还指出BC5 / 3Dc通常独立于y来压缩x，这意味着并非总能找到最佳法线。作为代替，他建议对法线使用以下误差度量：
$$
e=\arccos
\begin{cases}
\frac{\mathbf{n}\cdot\mathbf{n}_c}{||\mathbf{n}|| ||\mathbf{n}_c||},
\end{cases}
\qquad\qquad(6.5)
$$
其中$\mathbf{n}$是原始法线，$\mathbf{n}_c$是相同的法线压缩，然后解压缩。

​		![image-20191222223644637](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222223644637.png)

​		<font size=2>图6.23。 每个分量使用16bit的效果，而纹理压缩时使用8bit的效果。 从左到右：原始纹理，DXT1从每个分量8bit压缩，DXT1从每个分量16bit压缩，并在着色器中进行了重新归一化。 为了更清楚地显示效果，已在强光下渲染了纹理。 （图片由Anton Kaplanyan提供。）</font>

应当注意，还可以在不同的颜色空间中压缩纹理，这可以用来加速纹理压缩。 常用的变换是RGB→YCoCg [1112]：
$$
\begin{gather*}
\begin{pmatrix}
\begin{matrix}
Y \\
C_o \\
C_g\\
\end{matrix}
\end{pmatrix}
\end{gather*}=

\begin{pmatrix}
\begin{matrix}
1/4&1/2&1/4 \\
1/2&0&-1/2 \\
-1/4&1/2&-1/4\\
\end{matrix}
\end{pmatrix}

\begin{pmatrix}
\begin{matrix}
R \\
G\\
B\\
\end{matrix}
\end{pmatrix},
\qquad\qquad(6.6)
$$
其中，Y是亮度项，Co和Cg是色度项。 逆变换也很便宜：
$$
G=(Y+C_g),\quad t=(Y-C_g),\quad R=t+C_o,\quad B=t-C_o,
\qquad\qquad(6.7)
$$
​		这相当于一些加法。 这两个变换是线性的，这可以从公式6.6中看出，它是矩阵向量乘法，其本身是线性的（请参见公式4.1和4.2）。 这很重要，因为可以存储YCoCg，而不是将RGB存储在纹理中。 纹理硬件仍可以在YCoCg空间中执行过滤，然后像素着色器可以根据需要转换回RGB。 应该注意的是，这种变换本身是有损的，这可能是或者不是问题。
还有另一个可逆的RGB→YCoCg变换，总结为
$$
\begin{cases}
C_o=R-B\\
t=B+(C_o>>1)\\
C_g=G-t\\
Y=t+(C_g>>1)
\end{cases}
\qquad\Leftrightarrow\qquad
\begin{cases}
t=y-(C_g>>1)\\
G=C_g+t\\
B=t-(C_o>>1)\\
R=B+C_o
\end{cases}

\qquad\qquad(6.8)
$$

$\gg$向右移动。这意味着可以在例如24位RGB颜色和相应的YCoCg表示之间进行来回转换而不会造成任何损失。应该注意的是，如果RGB中的每个分量都具有n bits，则Co和Cg均具有n +1 bits，以确保可逆变换。 Y只需要n bits。 Van Waveren和Castaño[1852]使用有损YCoCg变换在CPU或GPU上实现对DXT5 / BC3的快速压缩。它们将Y存储在alpha通道中（因为它具有最高的精度），而Co和Cg存储在RGB的前两个分量中。由于Y单独用于存储和压缩，因此压缩变得很快。对于Co和Cg分量，他们找到了二维边界框，并选择了产生最佳结果的对角线框。请注意，对于在CPU上动态创建的纹理，最好也在CPU上压缩纹理。通过在GPU上渲染来创建纹理时，通常最好也在GPU上压缩纹理。 YCoCg变换和其他亮度色度变换通常用于图像压缩，其中色度分量在2×2纹素上平均。这样可以减少50％的存储量，并且通常工作正常，因为色度趋于缓慢变化。 Lee-Steere和Harmon [1015]通过将其转换为色相饱和度值（HSV），在x和y中对色相和饱和度下采样4倍，并将值存储为单通道DXT1纹理，使这一步骤更进一步。 Van Waveren和Castaño还描述了法线图压缩的快速方法[1853]。

​		Griffin和Olano [601]的研究表明，将多个纹理应用于具有复杂着色模型的几何模型时，纹理的质量通常很低，而没有任何明显的差异。因此，根据使用情况，降低质量是可以接受的。 Fauconneau [463]提出了DirectX 11纹理压缩格式的SIMD实现。

### 6.3程序纹理

​		对于给定纹理空间位置，执行图像查找是生成纹理值的一种方法。另一个是评估函数，从而定义程序纹理。

​		尽管程序纹理通常在离线渲染应用程序中使用，图像纹理在实时渲染中更为常见。这是由于现代GPU中图像纹理化硬件的极高效率，它可以在一秒钟内执行数十亿次纹理访问。但是，GPU架构正在朝着更便宜的计算和（相对）更昂贵的内存访问发展。这些趋势已使过程纹理在实时应用程序中得到更多使用。

​		鉴于体积图像纹理的高存储成本，体积纹理是用于程序纹理的一种特别有吸引力的应用。可以通过多种技术来合成这种纹理。最常见的一种方法是使用一个或多个噪声函数来生成值[407、1370、1371、1372]。参见图6.24。噪声函数通常在连续的二次方频率（称为八度）上采样。每个八度都有权重，通常随着频率的增加而降低，这些加权样本的总和称为湍流函数。

![image-20191222224931279](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\image-20191222224931279.png)

​		<font size=2>图6.24。 使用体积纹理进行实时程序纹理化的两个示例。 左侧的大理石是使用射线行进渲染的半透明体积纹理。 在右侧，对象是使用复杂的程序木质着色器[1054]生成并在现实环境中合成的合成图像。 （左图为''玩大理石''的影棚，由圣埃法尼·古利特（St́ephane Guillitte提供）。右图由Autodesk，Inc.的尼古拉斯·萨瓦（Nicolas Savva）提供）</font>

​		由于评估噪声函数的成本，通常会预先计算三维数组中的格点，并将其用于纹理值插值。有多种使用颜色缓冲区混合来快速生成这些数组的方法[1192]。 Perlin [1373]提供了一种快速，实用的方法来对该噪声函数进行采样，并展示了一些用途。 Olano [1319]提供了噪声生成算法，允许在存储纹理和执行计算之间进行权衡。 McEwan等[1168]开发了无需任何查找即可在着色器中计算经典噪声和单工噪声的方法，并且提供了源代码。 Parberry [1353]使用动态编程在多个像素上摊销计算，以加快噪声计算。 Green [587]提供了一种更高质量的方法，但是对于接近交互的应用程序，它意味着更多的方法，因为它使用50像素着色器指令进行单次查找。 Perlin [1370，1371，1372]提出的原始噪声函数可以得到改善。 Cook和DeRose [290]提出了另一种表示形式，称为小波噪声，它避免了混叠问题，而评估成本仅增加了一点点。刘等。 [1054]使用各种噪声函数来模拟不同的木材纹理和表面光洁度。我们还推荐Lagae等人的最新报告。 [956]关于这个话题。

​		其他程序方法也是可能的。例如，通过测量一组散布在空间中的“特征点”的每个位置的距离来形成细胞纹理。以各种方式（例如更改颜色或着色法线）映射所得到的最接近距离，可以创建看起来像细胞，石板，蜥蜴皮和其他自然纹理的图案。 Griffiths [602]讨论了如何有效地找到最接近的邻居并在GPU上生成细胞纹理。

​		程序纹理的另一种类型是物理模拟或其他交互过程的结果，例如水波纹或扩展裂缝。在这种情况下，程序纹理可以对动态条件做出有效的无限变化。

​		当生成程序二维纹理时，参数化问题可能比创作的纹理面临更大的困难，在创作的纹理中，可以手动修改或解决拉伸或接缝伪像。一种解决方案是通过将纹理直接合成到表面上来完全避免参数化。在复杂的表面上执行此操作在技术上具有挑战性，并且是研究的活跃领域。参见Wei等。 [1861]此字段的概述。

​		程序纹理的抗锯齿比图像纹理的抗锯齿既困难又容易。一方面，诸如mipmapping之类的预计算方法不可用，这给程序员带来了负担。另一方面，程序纹理作者具有有关纹理内容的“内部信息”，因此可以对其进行裁剪以避免混叠。对于通过将多个噪声函数求和而创建的程序纹理尤其如此。每个噪声函数的频率都是已知的，因此可以丢弃任何会引起混叠的频率，从而实际上降低了计算成本。有多种技术可以消除其他类型的程序纹理的锯齿[407、605、1392、1512]。 Dorn等[371]讨论了先前的工作，并提出了一些处理用于重新构造纹理函数以避免高频（即，被频带限制）的过程。

### 6.4纹理动画

​		应用于表面的图像不必是静态的。例如，视频源可以用作逐帧变化的纹理。

​		纹理坐标也不必是静态的。应用程序设计人员可以在网格的数据本身中或通过应用在顶点或像素着色器中的函数，在帧之间显式更改纹理坐标。想象一下，已经对一个瀑布进行了建模，并用看起来像落水的图像对其进行了纹理处理。说v坐标是流向。为了使水运动，必须从每个连续帧的v坐标中减去一个量。从纹理坐标中减去的效果是使纹理本身看起来向前移动。

​		通过将矩阵应用于纹理坐标可以创建更精细的效果。除了平移之外，这还允许进行线性变换，例如缩放，旋转和剪切[1192，1904]，图像扭曲和变形变换[1729]和广义投影[638]。通过在CPU或着色器中应用功能，可以创建更多精致的效果。

​		通过使用纹理混合技术，可以实现其他动画效果。例如，通过从大理石质地开始并逐渐变为肉色质地，可以使雕像栩栩如生[1215]。

### 6.5材质纹理
纹理的常见用途是修改影响着色方程的材质属性。现实世界中的对象通常具有在其表面上变化的材质属性。为了模拟此类对象，像素着色器可以从纹理读取值，并使用它们在评估着色方程之前修改材质参数。最常被纹理修改的参数是表面颜色。这种纹理称为反照率颜色贴图或漫反射颜色贴图。但是，可以通过纹理修改任何参数：替换，乘以或以其他方式更改它。例如，在图6.25中，将三个不同的纹理应用于表面，以替换常量值。

图6.25。 金属砖和砂浆。 右侧是表面颜色，粗糙度（较浅）和凹凸贴图高度（较浅）的纹理。 （图片来自three.js示例webgl色调映射[218]。）

在材质中纹理的使用可以更进一步。代替修改方程式中的参数，可以使用纹理来控制像素着色器本身的流和函数。通过使一种指定纹理表面哪些区域具有哪种材质，可以将具有不同着色方程式和参数的两种或多种材质应用于表面，从而使每种材质执行不同的代码。例如，一个具有生锈区域的金属表面可以使用纹理指示生锈的位置，根据纹理查找有条件地执行着色器的生锈部分，否则执行有光泽的金属着色器（第9.5.2节） ）。

着色模型输入（例如表面颜色）与从着色器输出的最终颜色具有线性关系。因此，可以使用标准技术过滤包含此类输入的纹理，并避免混叠。包含非直线着色输入（例如粗糙度或凹凸贴图）的纹理（第6.7节）需要格外小心，以免产生锯齿。考虑到着色方程的滤波技术可以改善此类纹理的结果。这些技术在9.13节中讨论。

### 6.6alpha纹理

可以使用alpha混合或alpha测试将alpha值用于许多效果，例如高效地渲染树叶，爆炸和远处的物体，仅举几例。本部分讨论了将纹理与Alpha结合使用的方法，并指出了各种限制和解决方案。

一种与纹理相关的效果是贴花。例如，假设您想在茶壶上放一朵花的图片。您不想要整个图片，而只想要花所在的部分。通过将alpha=0分配给纹素，可以使其透明，从而使其无效。因此，通过正确设置贴花贴图的Alpha，您可以用贴花替换或混合基础表面。通常，clamp函数与透明边框一起使用，以将贴花的单个副本（相对于重复纹理）应用到表面。图6.26中显示了如何实现贴花的示例。有关贴花的更多信息，请参见第20.2节。

图6.26。 一种实现贴花的方法。 首先使用帧缓冲区渲染场景，然后渲染一个框，对于框内的所有点，贴花纹理都将投影到帧缓冲区的内容中。 最左边的纹素是完全透明的，因此不会影响帧缓冲区。 黄色纹素不可见，因为它将被投影到表面的隐藏部分上。

alpha的类似应用是在制作剪切图。假设您制作了灌木的贴图图像，并将其应用于场景中的矩形。其原理与贴花的原理相同，除了将灌木绘制在其背后的任何几何形状的顶部上，而不是与下面的表面齐平。这样，您可以使用单个矩形来渲染具有复杂轮廓的对象。

在灌木的情况下，如果围绕它旋转摄像机，则视觉会错误，因为灌木没有厚度。一种解决方法是复制此灌木矩形并将其沿树干旋转90度。这两个矩形构成了便宜的三维灌木丛，有时也称为“交叉树” [1204]，从地面上看时，这种视觉效果相当有效。参见图6.27。 Pelzer [1367]讨论了使用三个剪切图代表草的类似配置。在第13.6节中，我们讨论了一种称为广告牌的方法，该方法用于将这种渲染减少为单个矩形。如果观看者移至地面上方，则视觉效果就会打破，因为从上方看到灌木丛是两个切口。参见图6.28。为了解决这个问题，可以以不同的方式（切片，分支，图层）添加更多的剪切图，以提供更具说服力的模型。第13.6.5节讨论了一种生成此类模型的方法；第857页的图19.31显示了另一个。有关最终结果的示例，请参见第2和1049页上的图像。

图6.27。 在左侧，是灌木纹理贴图和下面的1位Alpha通道贴图。 在右边，灌木丛渲染在单个矩形上； 通过添加经过旋转90度的矩形的第二个副本，我们形成了便宜的三维灌木丛。

将alpha贴图和纹理动画结合可以产生令人信服的特效，例如火炬闪烁，植物生长，爆炸和大气效果。

有几种使用alpha贴图渲染对象的选项。 Alpha混合（第5.5节）允许使用分数透明度值，该值可以对对象边缘以及部分透明的对象进行抗锯齿。 但是，alpha混合需要在不透明的三角形之后和从后到前的顺序渲染混合的三角形。 一个简单的交叉树是两个剪切纹理的示例，其中没有正确的渲染顺序，因为每个四边形都位于另一个的前面。 即使理论上可以排序并获得正确的顺序，通常这样做效率也不高。 例如，一块田地可能有成千上万的草叶，由剪切图表示。 每个网格物体可以由许多单独的叶片制成。 明确分类每个叶片是不切实际的。

图6.28。 从离地面有点远的地方看“交叉树”灌木丛，然后再向上看，视觉效果在此破坏。

渲染时，可以通过几种不同的方法来改善此问题。 一种是使用Alpha测试，这是有条件地丢弃像素着色器中低于给定阈值的Alpha值的片段的过程。 描述如此：

\text{if (texture.a < alphaThreshold) discard};
\qquad\qquad(6.9)

其中texture.a是纹理查找中的alpha值，参数alphaThreshold是用户提供的阈值，该阈值确定哪些片段将被丢弃。该二分可见性测试使三角形可以以任何顺序呈现，因为透明片段被丢弃了。我们通常希望对alpha为0.0的任何片段执行此操作。丢弃完全透明的片段还有一个额外的好处，即可以节省进一步的着色器处理和合并成本，还可以避免将z缓冲区中的像素错误地标记为可见[394]。对于剪切图，我们通常将阈值设置为高于0.0，例如0.5或更高，然后采取进一步的步骤，然后完全忽略alpha值，而不是将其用于混合。这样做可以避免乱码。但是，由于只有两个级别的透明度（完全不透明和完全透明）可用，因此质量较低。另一种解决方案是对每个模型执行两次pass-一次遍历实体剪切，将其写入z缓冲区，另一遍进行半透明采样，而不是全透明采样。

图6.29。 顶部：带有mipmapping的alpha测试，没有任何更正。 下：alpha测试根据覆盖范围重新调整alpha值。 （图片来自“证人”，由伊格纳西奥·卡斯坦·罗（Ignacio Castan ̃o）提供。）

alpha测试还有两个其他问题，即放大倍数过多[1374]和缩小倍数过多[234，557]。 当将alpha测试与mipmapping一起使用时，如果处理方式不同，效果可能令人难以置信。 图6.29的顶部显示了一个示例，其中树的叶子变得比预期的更加透明。 这可以用一个例子来解释。 假设我们有一个具有四个alpha值的一维纹理，即（0.0，1.0，1.0，0.0）。 通过平均，下一个mipmap级别变为（0.5,0.5），然后最高级别为（0.5）。 现在，假设我们使用\alpha_t= 0.75。 访问mipmap级别0时，可以显示出4中的1.5纹素将通过丢弃测试。 但是，访问下两个级别时，由于0.5 <0.75，所有内容将被丢弃。 请参见图6.30。

图6.30。 顶部是具有混合功能的叶子图案的不同mipmap级别，较高的级别则进行缩放以提高可见性。 在底部，将显示mipmap，使用0.5的alpha测试对其进行处理，以显示对象后退时如何减少像素。 （图片由Ben Golus提供[557]。）

Castaño[234]提出了一个在mipmap创建期间完成的简单解决方案，效果很好。 对于mipmap级别k，覆盖率c_k定义为

c_k=\frac{1}{n_k}\sum_i(\alpha(k,i)>\alpha_t),
\qquad\qquad(6.10)


其中n_k是mipmap级别k中的纹素数，\alpha（k，i）是像素i处在mipmap级别k中的alpha值，而\alpha_t是用户在公式6.9中提供的alpha阈值。 在这里，我们假设\alpha（k，i）>alpha_t的结果为如果为真则结果为1，否则为0。 注意，k = 0表示最低的mipmap级别，即原始图像。 然后，对于每个mipmap级别，我们找到一个新的mipmap阈值alpha_k，而不是使用alpha_t，以使c_k等于c_0（或尽可能接近）。 可以使用二分搜索来完成。 最后，在mipmap级别k中所有纹素的alpha值按alpha_t/alpha_k缩放。 图6.29的底部使用了此方法，NVIDIA的纹理工具对此方法提供了支持。 Golus [557]给出了一个变形，其中未修改mipmap，但是随着mipmap级别的增加，alpha会在着色器中按比例放大。

Wyman和McGuire [1933]提出了另一种解决方案，其中理论上将等式6.9中的代码行替换为

\text{if (texture.a < random()) discard;}
\qquad\qquad(6.11)

随机函数在[0，1]中返回一个统一值，这意味着平均而言，它将得出正确的结果。例如，如果纹理查找的alpha值为0.3，则片段将以30％的机会被丢弃。这是一种随机透明的形式，每个像素只有一个样本[423]。在实践中，将随机函数替换为哈希函数，以避免时空高频噪声：

\text{float hash2D(x,y) \{ return fract(1.0e4*sin(17.0*x+0.1*y) * (0.1+abs(sin(13.0*y+x)))); \}}
\qquad\qquad(6.12)

通过对上述函数的嵌套调用来形成三维哈希，即float hash3D（x，y，z）{return hash2D（hash2D（x，y），z）; }，返回在[0,1）范围内的数字。哈希的输入是对象空间坐标除以对象空间坐标的最大屏幕空间导数（x和y），然后进行限制。需要进一步注意以获得z方向运动的稳定性，并且该方法最好与时间抗锯齿技术结合使用。该技术会随着距离的推移而逐渐变弱，因此在关闭时我们根本不会获得任何随机效果。这种方法的优点是每个片段平均来说都是正确的，而Castano的方法[234]为每个mipmap级别创建一个\alpha_k。但是，此值可能会在每个mipmap级别上有所不同，这可能会降低质量并需要美工干预。

alpha测试在放大下(magnification)显示波纹伪影，可以通过将alphat贴图预先计算为距离场[580]来避免（请参见第677页的讨论）。

Alpha to coverage（A2C）和类似的功能透明度自适应抗锯齿，采用片段的透明度值，并将其转换为一个像素内覆盖了多少个样本[1250]。这个想法就像5.5节中描述的屏幕门透明，但在子像素级别。想象每个像素有四个样本位置，并且一个片段覆盖了一个像素，但是由于剪切纹理的缘故，它的透明度为25％（不透明度为75％）。 A2C模式使片段变得完全不透明，但仅覆盖了四个样本中的三个。此模式对于重叠草叶的剪切纹理很有用，例如[887，1876]。由于每个绘制的样本都是完全不透明的，因此最接近的叶状体将沿其边缘以一致的方式将隐藏其后的对象。由于Alpha混合功能已关闭，因此无需排序即可正确混合半透明边缘像素。

Alpha to Coverage是抗锯齿Alpha测试的好方法，但是在Alpha混合时会显示伪影。例如，两个具有相同alpha覆盖率的alpha混合片段将使用相同的子像素图案，这意味着一个片段将完全覆盖另一个片段，而不是与其混合。 Golus [557]讨论了使用fwidth（）着色器指令为内容提供更清晰的边缘。见图6.31。

图6.31。 叶子纹理的不同渲染技术，边缘具有部分alpha覆盖。 从左到右：alpha测试，alpha混合，alpha to coverage以及带有锐化边缘的alpha to coverage。 （图片由Ben Golus提供[557]。）

对于alpha映射的任何使用，重要的是要了解双线性插值如何影响颜色值。想象一下彼此相邻的两个纹素：rgbα=（255,0,0,255）是纯红色，而它的邻居rgbα=（0,0,0,2）是黑色，几乎完全透明。正好在两个纹素之间的中间位置的rgbα是多少？简单插值得到（127，0，0，128），所得的rgb值就有一个“较暗”的红色。但是，此结果实际上并不是暗淡的，它是一个全红色，已预先乘以其alpha。如果您对Alpha值进行插值，为确保正确的插值，您需要确保在插值之前，已经对要用于插值的颜色进行了Alpha预乘。例如，假设将几乎透明的邻居设置为rgbα=（0，255，0，2），从而给出绿色的微小色调。该颜色不会与alpha预乘，在插值时会得到结果（127,127,0,128）——绿色的微小色调突然将结果变为（预乘）黄色样本。此邻居纹素的预乘版本为（0,2,0,2），它给出了适当的预乘结果（127，1，0，128）。这个结果更有意义，最终的预乘颜色主要是红色和一些难以察觉的绿色。

忽略双线性插值的结果给出预乘结果可能会导致贴花和剪切对象周围出现黑色边缘。 “较暗”的红色结果被管线的其余部分视为未相乘的颜色，并且边缘变为黑色。即使使用alpha测试，此效果也可以看到。最好的策略是在完成双线性插值之前进行预乘[490，648，1166，1813]。 WebGL API支持此功能，因为合成对于网页很重要。但是，双线性插值通常由GPU执行，并且在执行此操作之前，着色器无法完成对纹素值的操作。PNG等文件格式的图像不会以进行预乘，因为这样做会失去色彩精度。使用alpha映射时，默认情况下，这两个因素共同导致黑色边缘。一种常见的解决方法是对剪切图像进行预处理，使用从附近的不透明纹素获得的颜色来绘制透明的“黑色”纹理像素[490，685]。通常，所有透明区域都需要以这种方式手动或自动重新绘制，以使mipmap级别也避免出现边缘问题[295]。还值得注意的是，在形成具有Alpha值的Mipmap时应使用预乘值[1933]。

### 6.7凹凸贴图

本节描述了一大类小型细节表示技术，我们将其统称为凹凸贴图。所有这些方法通常都是通过修改每个像素的着色例行程序来实现的。与单独的纹理贴图相比，它们具有更高的三维外观，但没有添加任何其他几何形状。

一个对象的细节可以分为三个等级：覆盖许多像素的宏观特征，横跨几个像素的中间特征和实质上小于一个像素的微小特征。这些类别有些不稳定，因为在动画或交互式会话期间，观看者可能在许多距离处观察到同一对象。

宏观几何由顶点和三角形或其他几何图元表示。当创建一个三维角色时，通常以宏观尺度对肢体和头部进行建模。微小几何封装在着色模型中，该模型通常在像素着色器中实现，并使用纹理贴图作为参数。使用的着色模型可模拟表面微观几何形状的相互作用，例如，发光的物体在微观上是光滑的，而漫反射表面在微观上是粗糙的。角色的皮肤和衣服似乎具有不同的材质，因为它们使用不同的着色器，或者至少使用这些着色器中的不同参数。

中观几何描述了这两个尺度之间的一切。它包含的细节过于复杂，无法使用单个三角形进行有效渲染，但对于观察者来说，它足以分辨出几个像素上的表面曲率变化。角色脸上的皱纹，肌肉的细节以及衣服上的褶皱和凹凸都是中尺度的。中尺度建模通常使用一类统称为凹凸贴图技术的方法。这些方法调整像素级别的着色参数，以使观看者感觉到远离基本几何形状的微小干扰，而基本几何形状实际上保持平坦。不同种类的凹凸贴图之间的主要区别是它们如何表示细节特征。变量包括现实水平和细节特征的复杂性。例如，数字艺术家通常将细节雕刻到模型中，然后使用软件将这些几何元素转换为一种或多种纹理，例如凹凸纹理和缝隙变暗的纹理。

布林在1978年提出了在纹理中编码中尺度细节的想法[160]。他观察到，如果在着色过程中用稍微受扰动的表面法线代替真实表面，则表面似乎具有小范围的细节。他将描述微扰到表面法线的数据存储在数组中。

关键思想是，我们不使用纹理来更改光照方程式中的颜色分量，而是访问纹理来修改表面法线。表面的几何法线保持不变。我们仅修改光照方程式中使用的法线。此操作没有物理等效项。我们在表面法线上执行更改，但是表面本身在几何意义上保持平滑。正如具有每个顶点的法线会给人一种错觉，即三角形之间的表面是光滑的一样，修改每个像素的法线会更改三角形表面本身的感知，而不会更改其几何形状。

对于凹凸贴图，法线必须相对于某个参考系改变方向。为此，将切线框（也称为切线空间基底）存储在每个顶点上。该参考系用于将灯光转换到表面位置的空间（反之亦然），以计算干扰法线的效果。除了顶点法线外，在多边形表面上应用了法线贴图的情况下，我们还存储了切线和双切线向量。双切向量也被错误地称为双法线向量[1025]。

切线和切线向量表示法线贴图本身在对象空间中的轴，因为目标是将光照转换为相应的贴图。参见图6.32。
法线\mathbf{n}，切线\mathbf{t}和双切线\mathbf{b}这三个向量形成基本矩阵：

\begin{pmatrix}
\begin{matrix}
t_x&t_y&t_z&0\\
b_x&b_y&b_z&0\\
n_x&n_y&n_z&0\\
0&0&0&0\\
\end{matrix}
\end{pmatrix}
\qquad\qquad(6.13)

图6.32。 显示了一个球形三角形，其切线框显示在每个角上。 正如圆环上的纬度和经度线所示，球形和圆环等形状具有自然的切线空间基底。

这个矩阵有时缩写为TBN，它将光的方向（对于给定的顶点）从世界空间转换为切线空间。这些向量不必真正彼此垂直，因为法线贴图本身可能会变形以适合曲面。但是，非正交的基底会导致纹理倾斜，这可能意味着需要更多的存储空间，并且可能会对性能产生影响，即矩阵无法通过简单的转置来反转[494]。一种节省内存的方法是只在顶点存储切线和双切线，并取它们的叉积来计算法线。但是，只有在矩阵的手性始终相同的情况下，此技术才有效[1226]。通常，模型是对称的：飞机，人，文件柜和许多其他对象。由于纹理消耗大量内存，因此它们通常被镜像到对称模型上。因此，仅存储对象纹理的一侧，但是纹理映射将其放置在模型的两侧。在这种情况下，切线空间的手性在两侧会有所不同，因此无法假定。如果在每个顶点上存储了额外的信息位来指示手性，则在这种情况下仍然可以避免存储法线。如果已设置，则此位用于求反切线和双切线的叉积，以生成正确的法线。如果切线框架是正交的，则还可以将基础存储为四元数（第4.3节），这既节省空间，又可以节省每个像素的一些计算[494、1114、1154、1381、1639]。尽管在实践中很少见，但质量可能会略有下降。

切线空间的概念对于其他算法很重要。如下一章所述，许多着色方程仅依赖于曲面的法线方向。但是，诸如拉丝铝或天鹅绒之类的材料也需要知道观看者和照明相对于表面的相对方向。切线框可用于定义材质在表面上的方向。 Lengyel [1025]和Mittring [1226]的文章提供了该领域的广泛报道。 Schuφler[1584]提出了一种在像素着色器中动态计算切线空间的方法，而无需为每个顶点存储预先计算的切线框。 Mikkelsen [1209]对这一技术进行了改进，并推导了一种不需要任何参数化方法，而是使用表面位置的导数和高度场的导数来计算扰动法线的方法。但是，与使用标准切线空间映射相比，此类技术所导致的显示细节要少得多，并且可能会产生美术工作流问题[1639]。

#### 6.7.1Blinn方法

布林最初的凹凸贴图方法在纹理的每个纹素上存储两个有符号的值b_u和b_v。这两个值对应于沿图像的u和v轴改变法线的量。也就是说，这些纹理值通常是双线性插值的和用于缩放垂直于法线的两个向量。将这两个向量添加到法线以更改其方向。 b_u和b_v这两个值描述了表面在该点面向哪个方向。见图6.33。这种类型的凹凸贴图纹理称为偏移矢量凹凸贴图或偏移贴图。

图6.33。 在左侧，通过从凹凸纹理获取的（b_u，b_v）值在\mathbf{u}和\mathbf{v}方向上修改法线向量\mathbf{n}，得到\mathbf{n}'（未归一化）。 右侧显示了一个高度场及其对着色法线的影响。 可以在高度之间插值这些法线，以获得更平滑的外观。

表示凹凸的另一种方法是使用高度场来修改表面法线的方向。每个黑白纹理值代表一个高度，因此在纹理中，白色是高区域，黑色是低区域（反之亦然）。有关示例，请参见图6.34。这是首次创建或扫描凹凸贴图时使用的常见格式，它也是1978年由Blinn引入的。高度场用于导出u和v有符号的值，类似于第一种方法中使用的值。这是通过获取相邻列之间的差异来获得u的斜率以及相邻行之间的差异来获取v的[1567]。一种变形是使用Sobel滤波器，该滤波器赋予直接相邻的邻居更大的权重[535]。

图6.34。 波浪形的高度场凹凸图像及其在球体上的使用。

#### 6.7.2法线贴图

凹凸贴图的常见方法是直接存储法线贴图。算法和结果在数学上与布林的方法相同。只有存储格式和像素着色器计算会更改。

法线贴图编码（x，y，z）将其映射到[-1,1]，例如，对于8-bit纹理，x轴值0表示-1.0，255表示1.0。一个例子如图6.35所示。颜色[128，128，255]（浅蓝色）将代表所示颜色映射的平坦表面，即法线[0，0，1]。

法线图表示最初是作为世界空间法线贴图[274，891]引入的，在实际中很少使用。对于这种类型的贴图，扰动非常简单：在每个像素处，从贴图中检索法线，然后将其与光的方向一起直接使用，以计算表面上该位置的着色。还可以在对象空间中定义法线贴图，以便可以旋转模型，然后法线仍然有效。但是，世界和对象空间表示都将纹理绑定到特定方向的特定几何体，这限制了纹理的重复使用。

图6.35。 法线贴图随着凹凸贴图。 每个颜色通道实际上都是一个表面法线坐标。 红色通道是x偏差； 红色越多，指向右边的法线越多。 绿色是y偏差，蓝色是z。 右侧是使用法线贴图生成的图像。 注意立方体顶部的平整外观。 （图片由Manuel M. Oliveira和Fabio Policarpo提供。）

取而代之的是，通常在切线空间（即相对于表面本身）中检索扰动的法线。这允许表面变形以及法线纹理的最大重复使用。切线空间法线贴图也可以很好地压缩，因为z分量的符号（与未受扰动的表面法线对齐的符号）通常可以假定为正。
可以使用法线贴图来提高逼真度，见图6.36。

图6.36。 在类似游戏的场景中使用的法线贴图凹凸贴图的示例。 左上方：不应用右侧的两个法线贴图。 左下：已应用法线贴图。 右：法线贴图。 （3D模型和法线贴图由Dulce Isis SegarraLópez提供）

与过滤颜色纹理相比，过滤法线贴图是一个难题。通常，法线和着色颜色之间的不是线性关系，因此标准的过滤方法可能会导致难以接受的混叠。想象一下观察由闪亮的白色大理石块制成的楼梯。在某些角度下，楼梯的顶部或侧面可以捕捉光线并反射出明亮的镜面高光。但是，楼梯的平均法线为45度角。它会从与原始楼梯完全不同的方向捕获亮点。如果在没有正确过滤的情况下渲染具有清晰的镜面高光的凹凸贴图，则由于高光由于样本的位置而闪烁，会产生分散注意力的闪光效果。

朗伯曲面是一种特殊情况，其中法线贴图对着色几乎具有线性影响。 朗伯着色几乎完全是一个点积，它是线性运算。 平均一组法线并对其结果执行点积等于将单个点积与法线平均：

\mathbf{l}\cdot
\begin{cases}
\frac{\sum_{j=1}^{n}\mathbf{n}_j}{n}
\end{cases}
=\frac{\sum_{j=1}^{n}(\mathbf{l}\cdot\mathbf{n}_j)}{n}.
\qquad\qquad(6.14)

请注意，平均向量在使用前未归一化。公式6.14表明，对于郎伯曲面，标准过滤和mipmap几乎可以产生正确的结果。结果不是很正确，因为Lambertian着色方程不是点积。它是一个clamp点乘积-max（\mathbf{l}·\mathbf{n}，0）。clamp操作使其变为非线性。这将使表面过于暗淡，以至于无法直视光的方向，但是在实践中，这通常并不难以接受[891]。一个警告是，通常用于法线贴图的某些纹理压缩方法（如从其他两个法线重构z分量）不支持非单位长度的法线，因此使用非归一化的法线贴图可能会带来压缩困难。

在非朗伯曲面的情况下，可以通过将着色方程的输入作为一组过滤，而不是单独过滤法线贴图来产生更好的结果。在9.13节中讨论了这样做的技术。

最后，从高度图h（x，y）导出法线贴图可能很有用。如下进行[405]。首先，使用中心差为x来计算x和y方向上的导数近似值

h_x(x,y)=\frac{h(x+1,y)-h(x-1,y)}{2},\qquad
h_y(x,y)=\frac{h(x,y+1)-h(x,y-1)}{2}.\qquad\qquad(6.15)

然后在纹素（x，y）处的未归一化法线为

\mathbf{n}(x,y)=(-h_x(x,y),-h_y(x,y),1).
\qquad\qquad(6.16)

必须注意纹理的边界。

通过使凹凸块能够将阴影投射到其自身的表面上，可以使用“水平贴图” [1027]进一步增强法线贴图。 这是通过预先计算其他纹理（每个纹理与沿着表面平面的方向相关联）并为每个纹素存储该方向上的水平角度来完成的。 有关更多信息，请参见第11.4节。

### 6.8视差贴图

凹凸和法线贴图的问题在于，凹凸永远不会随视角移动位置，也不会相互阻挡。例如，如果您沿着真实的砖墙看，以某个角度看，您将看不到砖之间的砂浆。墙壁的凹凸贴图永远不会显示这种类型的遮挡，因为它只会改变法线。最好让凸块实际影响渲染表面上每个像素处的位置。

视差贴图的概念由Kaneko [851]于2001年提出，并由威尔士[1866]进行了完善和推广。视差指的是当观察者移动时，对象的位置相对于彼此移动的想法。当观察者移动时，凹凸应该看起来具有高度。视差映射的关键思想是通过检查发现的可见物体的高度来对像素中应该看到的物体进行有根据的猜测。

对于视差贴图，将凹凸存储在高度场纹理中。当观察在给定像素处的表面时，将在该位置检索高度场值，并将其用于移动纹理坐标以检索表面的不同部分。偏移量基于所获取的高度和眼睛与表面的角度。参见图6.37。高度场值要么存储在单独的纹理中，要么打包为其他纹理的未使用的颜色或Alpha通道（将不相关的纹理打包在一起时必须小心，因为这会对压缩质量产生负面影响）。在用于移动坐标之前，将对高度场值进行缩放和偏置。缩放决定了高度场要在表面上方或下方延伸的高度，并且偏差提供了不发生任何偏移的“海平面”高度。给定纹理坐标位置\mathbf{P}，调整后的高度场高度h和具有高度值v_z和水平分量v_{xy}的归一化视图向量\mathbf{v}，新的调整后视差纹理坐标\mathbf{P}adj为

\mathbf{P}_{adj}=\mathbf{P}+\frac{h\cdot\mathbf{v_{xy}}}{v_z}.
\qquad\qquad(6.17)

请注意，与大多数着色方程式不同，此处执行计算的空间很重要-视野向量必须在切线空间中。

图6.37。 左侧为目标：从视野向量穿过高度场的位置找到表面上的实际位置。 视差贴图通过获取矩形上某个位置的高度并使用它来查找新的位置\mathbf{P}_{adj}来进行一阶近似。 （根据威尔士[1866]。）

尽管是一个简单的近似值，但如果凸块的高度变化相对较慢[1171]，则这种移位在实践中效果很好。 这样，附近的相邻纹素的高度大约相同，因此使用原始位置的高度作为新位置高度的估计的想法是合理的。 但是，这种方法在较浅的视角下会破裂。 当视野向量接近表面的水平线时，高度变化较小会导致纹理坐标偏移较大。 近似失败，因为检索到的新位置与原始曲面位置几乎没有高度相关性。

为了改善这个问题，Welsh [1866]引入了偏移限制的思想。 想法是将移动量限制为永远不大于获取的高度。 等式是

\mathbf{P}_{adj}'=\mathbf{P}+h\cdot\mathbf{v}_{xy}

请注意，该公式的计算速度比原始公式要快。 从几何上讲，这种解释是，高度定义了一个半径，位置不能超出该半径。 如图6.38所示。

图6.38。 在视差偏移量限制中，偏移最多偏离原始位置的高度量，以虚线圆弧表示。 灰色偏移显示原始结果，黑色偏移显示有限结果。 右边是用该技术渲染的墙。 （图片由特里·威尔士（Terry Welsh）提供。）

陡峭的角度（面对面）时由于v_z接近1，所以该公式与原始公式几乎相同。在较小的角度时，偏移的作用受到限制。 从视觉上看，这使得在浅角度时的凹凸感降低了，但这比对纹理进行随机采样要好得多。 随着视图的改变，纹理游动也存在问题，或者对于立体渲染，观看者同时感知到两个必须给出一致的深度提示的视点[1171]。 即使有这些缺点，具有偏移限制的视差贴图也仅花费了一些额外的像素着色器程序指令，并且相对于基本法线映射而言，可提供相当可观的图像质量改进。 Shishkovtsov [1631]通过在凹凸贴图法线方向上移动估计位置来改善视差遮挡的阴影。

#### 6.8.1视差遮挡贴图

凹凸贴图不会基于高度场修改纹理坐标； 它仅在某个位置改变着色法线。 视差贴图提供了高度场效果的简单近似值，假设像素的高度与其相邻像素的高度大致相同。 这个假设可能很快就会崩溃。 凹凸也可能永远不会相互遮挡，也不会投射阴影。 我们想要的是在像素处可见的东西，即视野向量最先与高度场相交的地方。

为了以更好的方式解决此问题，一些研究人员建议沿视野矢量使用ray marching，直到找到一个（近似）交点。这项工作可以在像素着色器中完成，其中高度数据可以作为纹理访问。我们将对这些方法的研究归纳为视差映射技术的子集，该技术以一种或另一种方式利用ray marching[192，1171，1361，1424，1742，1743]。

这些类型的算法除其他名称外，称为视差遮挡映射（POM）或浮雕映射方法。关键思想是首先沿着投影向量测试固定数量的高度场纹理样本。通常会在掠射角度为视线生成更多样本，以免错过最近的交点[1742，1743]。检索沿射线的每个三维位置，将其转​​换为纹理空间，然后进行处理以确定其是否在高度场之上或之下。一旦找到一个高度场以下的样本，则其下方的数量以及上一个样本之上的数量将用于查找相交位置。见图6.39。然后该位置被用于表面着色，使用附加的法线贴图，颜色贴图和任何其他纹理。多层高度场可用于产生悬垂，独立的重叠表面以及双面地形测绘的代替。请参阅第13.7节。高度场跟踪方法也可以用于使凹凸不平的表面在自身上投射阴影，包括硬[1171、1424]和软[1742、1743]。比较请参见图6.40。

图6.39。 绿色的视点射线投射到表面上，以固定的时间间隔（紫色点）进行采样，并获取高度。 该算法找到了视点光线与黑线段的第一个交点，近似于弯曲的高度场。

图6.40。 与光线步进（右）相比，没有光线步进的视差贴图（左）。 不使用光线步进时，立方体的顶部会变平。 通过光线行进，也会产生自阴影效果。 （图片由Manuel M. Oliveira和Fabio Policarpo提供。）

关于这个话题有很多文献。尽管所有这些方法都沿着射线前进，但存在一些差异。可以使用简单的纹理来获取高度，但是也可以使用更高级的数据结构和更高级的寻根方法。一些技术可能涉及着色器丢弃像素或写入
到深度缓冲区，这可能会损害性能。下面我们总结了很多方法，但是请记住，随着GPU的发展，最好的方法也是如此。这种“最好”方法取决于光线行进期间的内容和完成的步骤数。

寻根问题是确定两个常规样本之间的实际交点的问题。实际上，高度场更多地被视为深度场，矩形的平面定义了表面的上限。这样，平面上的初始点在高度场上方。在找到高度场的上面的最后一个点和下面的第一个点之后，Tatarchuk [1742，1743]使用割线方法的单个步骤来找到近似解。 Policarpo等[1424]在发现的两个点之间使用二分搜索，以在更近的交点上进行磨练。 Risser等[1497]通过使用割线方法进行迭代来加快收敛速度​​。代价是可以并行进行常规采样，而迭代方法需要较少的总体纹理访问，但必须等待结果并执行较慢的依赖纹理提取。Brute-force方法似乎在整体上表现良好[1911]。

足够频繁地对高度场进行采样至关重要。 McGuire和McGuire [1171]建议对mipmap查找进行偏置，并使用各向异性的mipmap以确保对高频高度场（例如代表尖峰或头发的高频高度场）进行正确采样。人们还可以以比法线贴图更高的分辨率存储高度场纹理。最后，一些渲染系统甚至不存储法线贴图，而是倾向于使用交叉滤波器从高度场中动态导出法线[40]。第696页的公式16.1显示了该方法。

提高性能和采样精度的另一种方法是，首先不以固定的间隔对高度场进行采样，而是尝试跳过中间的空白空间。 Donnelly [367]将高度场预处理为一组体素，在每个体素中存储距高度场表面的距离。以这种方式，可以快速跳过中间空间，但要为每个高度场增加存储空间。 Wang等。 [1844]使用五维位移映射方案来保持从所有方向和位置到表面的距离。这允许复杂的曲面，自遮蔽和其他效果，但要消耗大量内存。 Mehra和Kumar [1195]出于类似目的使用定向距离图。 Dummer [393]引入了锥步映射的概念，而Policarpo和Oliveira [1426]对其进行了改进。这里的概念是还要为每个高度场位置存储一个圆锥半径。该半径定义了射线的间隔，在该间隔中与高度场最多有一个交点。该属性允许沿射线快速跳过而不会丢失任何可能的交点，但是以需要依赖纹理读取为代价。另一个缺点是创建圆锥台阶图所需的预计算，使得该方法无法用于动态更改高度场。 Schroders和Gulik [1581]提出了四叉树浮雕映射，这是一种在遍历期间跳过体积的分层方法。 Tevs等。 [1760]使用“最大mipmap”来允许跳过，同时将预计算成本降至最低。 Drobot [377]还使用存储在mipmap中的类似四叉树的结构来加快遍历速度，并提出了一种在不同的高度场之间进行混合的方法，其中一种地形类型转换为另一种地形类型。
上述所有方法的问题之一是幻觉沿着对象的轮廓边缘分解，这将显示原始表面的平滑轮廓。见图6.41。关键思想是渲染的三角形定义了应由像素着色器程序评估哪些像素，而不是表面实际位于的位置。另外，对于弯曲表面，轮廓问题变得更加复杂。 Oliveira和Policarpo [1325，1850]描述和开发了一种方法，该方法使用二次轮廓逼近技术。 Jeschke等。 [824]和Dachsbacher等。 [323]都给出了一种更通用，更鲁棒的方法（并回顾了以前的工作）来正确处理轮廓和曲面。最初由Hirche [750]探索，其总体思想是向外挤出网格中的每个三角形并形成一个棱镜。渲染此棱镜会强制评估可能会出现高度场的所有像素。这种方法称为壳映射，因为扩展的网格在原始模型上形成了一个单独的壳。通过保留棱镜与射线相交时的非线性特性，可以实现高度场的无伪影渲染，尽管计算成本很高。图6.42显示了这种技术的令人印象深刻的用法。

图6.42。 视差遮挡贴图（也称为浮雕贴图），用于使石头看起来更逼真的路径。 地面实际上是一组应用了高度场的简单三角形。 （图片来自“ Crysis”，由Crytek提供。）

### 6.8纹理灯光

纹理还可以用于为光源增加视觉丰富度，并允许复杂的强度分布或聚光灯功能。对于所有照明都限于圆锥形或截头圆锥形的灯，可以使用投影纹理来调制光强度[1192，1597，1904]。这样就可以使用聚光灯，图案灯甚至“幻灯机”效果（图6.43）。在专业剧院和电影照明中使用的切口术语之后，这些灯通常称为图案灯或曲奇灯。有关以类似方式投射阴影的投影映射的讨论，请参见第7.2节。
对于不限于平截头体但可以在所有方向照亮的灯光，可以使用立方体贴图来调制强度，而不是使用二维投影纹理。一维纹理可用于定义任意距离衰减函数。结合二维角度衰减图，可以考虑复杂的体积照明模式[353]。更普遍的可能性是使用三维（体积）纹理来控制灯光的衰减[353、535、1192]。这允许任意量的效果，包括光束。此技术占用大量内存（所有卷纹理也是如此）。如果光线的影响量沿三个轴对称，则可以通过将数据镜像到每个八分圆中来将内存占用空间减少八倍。
可以将纹理添加到任何灯光类型，以启用其他视觉效果。特制的灯光使艺术家可以轻松控制照明，他们可以简单地编辑所使用的纹理。
## 7.阴影

## 8.光和颜色

## 9.基于物理的着色

## 10.局部光照

## 11.全局光照

## 12.图像空间特效

## 13.超越多边形

## 14.体积和半透明渲染

## 15.非真实图像渲染

## 17.曲线和曲面

## 18管线优化

## 19.加速算法

## 20.高效着色

## 21.虚拟现实和增强现实

## 22.交叉测试方法

## 23.图形硬件
