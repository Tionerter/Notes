# 						Real-Time Rendering 4th

## 1.介绍

### 1.2符号和定义

​		首先，我们将解释本书中使用的数学符号。有关本节以及整本书中使用的许多术语的更详尽说明，请访问realtimerendering.com获取我们的线性代数附录。

​	**向量**：
$$
\vec v=
\begin{gather*}
\begin{pmatrix}
v_x \\v_y \\v_z\\v_w
\end{pmatrix}
\end{gather*}
$$
​	

|            类型            |                           注意事项                           |                             例子                             |
| :------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
|        角度(angle)         |                         小写希腊字母                         |          $$\alpha_i,\eta,\beta,\theta,\gamma_{60}$$          |
|        因子(scalar)        | 小写英文字母*<kbd><font color=#0099ff size=4>斜体</font></kbd>* |                    *$$a,b,c,u_k,w_{ij}$$*                    |
| 向量或点(vector or point)  |     小写英文字母<kbd><font size=4>**粗体**</font></kbd>      | $$\textbf{a},\textbf{u},\textbf{v}_s,\textbf{h}(\rho),\textbf{h}_z$$ |
|        矩阵(matrix)        |         大写<kbd><font size=4>**粗体**</font></kbd>          |   $$\textbf{T}(\textbf{t}),\textbf{X},\textbf{R}_x(\rho)$$   |
|        平面(plane)         |            $\pi$:法向量点乘平面内任意向量加上因子            | $$\pi:\textbf{n}\cdot\textbf{x}+d=0\\\pi_1:\textbf{n}_1\cdot\textbf{x}+d_1=0\\$$ |
|      三角形(triangle)      |                           △和3个点                           | $$\triangle{\textbf{v}_0\textbf{v}_1\textbf{v}_2},\triangle\textbf{cba}$$ |
|     线段(line segment)     |                            两个点                            |           $$\textbf{uv},\textbf{a}_i\textbf{b}_j$$           |
| 几何物体(geometric entity) |    大写*<kbd><font color=#0099f size=4>斜体</font></kbd>*    |                   *$$A_{OBB},T,B_{AABB}$$*                   |

大写，小写

希腊字母，英文字母

粗体，非粗体

斜体，非斜体

|      |                            运算符                            |    描述    |
| :--: | :----------------------------------------------------------: | :--------: |
|  1   |                          $$\cdot$$                           |    点乘    |
|  2   |                          $$\times$$                          |    叉乘    |
|  3   |                       $$\textbf{v}^T$$                       | 向量的转置 |
|  4   |                           $$\bot$$                           |            |
|  5   |               $$\lvert\quad\cdot\quad\rvert$$                |            |
|  6   |               $$\lvert\quad\cdot\quad\rvert$$                |            |
|  7   |               $$\lVert\quad\cdot\quad\rVert$$                |            |
|  8   |                          $$x^{+}$$                           |            |
|  9   |                         $$x^{\mp}$$                          |            |
|  10  |                            $$n!$$                            |            |
|  11  | $$\begin{gather*}\begin{pmatrix}n\\k\end{pmatrix}\end{gather*}$$ |            |


$$
x^{+}=

\begin{cases}
x,&x>0\\
0,&otherwise
\end{cases}
$$

$$
x^{\mp}=
\begin{cases}
1,\qquad if&x\geq1,\\
x,\qquad if&0<x<1,\\
0,&otherwise.
\end{cases}
$$



$$
n!=n(n-1)(n-2)\cdot\cdot\cdot3\cdot2\cdot1
$$


$$
\begin{gather*}\begin{pmatrix}n\\k\end{pmatrix}\end{gather*}=
\frac{n!}{k!(n-k!)!}
$$


|      |      函数      | 描述 |
| :--: | :------------: | :--: |
|  1   | $$atan2(y,x)$$ |      |
|  2   |   $$log(n)$$   |      |
















## 2.渲染管线

​		本章介绍了实时图形的核心组件，即图形渲染管道，也简称为“管道”。管道的主要功能是在给定虚拟摄像机的情况下生成或渲染二维图像，三维物体，光源等。因此，渲染管道是实时渲染的基础工具。使用管道的过程如图2.1所示。图像中对象的位置和形状由其几何形状，环境特征以及相机在该环境中的位置决定。对象的外观受材料属性，光源，纹理（应用于表面的图像）和着色方程的影响。

![1568991361207](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1568991361207.png)

​		<font size=2>图2.1。在左图中，虚拟摄像机位于金字塔的顶端（四条线会聚的点）。仅渲染视图体积内的基元。对于以透视方式呈现的图像（如这里的情况），视图体积是平截头体，即一个头部被截取的棱椎。右图显示了相机“看到的内容”。请注意，左图中的红色圆环形状不在右侧渲染中，因为它位于视锥体外。此外，左图像中的扭曲蓝色棱镜被夹在平截头体的顶平面上。</font>

​		我们将解释渲染管道的不同阶段，重点是功能而不是实现。应用这些阶段的相关细节将在后面的章节中介绍。

### 2.1结构

​		在物理世界中，管道概念以许多不同的形式表现出来，从工厂装配线到快餐厨房。它也适用于图形渲染。管道由若干阶段组成，每个阶段执行庞大任务的一部分。

​		流水线的每个阶段是并行执行的，每个阶段取决于前一阶段的结果。理想情况下，一个非流水线系统被划分成n个流水线阶段，可以带来n倍的速度提升。性能的提高是使用流水线操作的主要原因。例如，一堆数量庞大的三明治可以被一些分工好的工人快速准备好 —— 一个准备面包，另一个添加肉，另一个添加配料。每个人都将自己的结果传递给下一个人，并立即开始下一个三明治的工作。如果每个人花费20秒来执行他们的任务，则每20秒，每分钟三次，最大速率可以生产一个三明治。尽管流水线是并行执行的，但它们会被拖延直到最慢的阶段完成其任务。例如，假设肉类添加阶段变得更加复杂，需要30秒。现在最好的速度是一分钟两个三明治。在这个特殊的流水线，肉类阶段是瓶颈，因为它决定了整个生产的速度。于是配料阶段在等待肉类阶段的完成时处于饥饿状态（对于顾客也是）。

​		这种管道结构也可以在实时计算机图形的背景下找到。将实时渲染管线粗略划分为四个主要阶段 - **应用，几何处理，光栅化和像素处理** - 如图2.2所示。这种结构是渲染管线的核心在实时计算机图形应用程序中，因此是后续章节中讨论的重要基础。这些阶段通常又是一个管线，这意味着它由几个子阶段组成。我们区分这里显示的功能阶段和它们的实现结构。功能阶段有明确的任务要执行，但没有指定任务在管线中执行的方式。给定的实现可以将两个功能阶段组合成一个单元或者执行使用可编程核心，同时将另一个更耗时的功能阶段划分为多个硬件单元。

![1568994209724](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1568994209724.png)

<font size=2>		图2.2。渲染管道的基本构造，包括四个阶段：应用程序，几何处理，光栅化和像素处理。这些阶段中的每一个本身可以是管线，如几何处理阶段下面所示，或者阶段可以（部分）并行化，如像素处理阶段所示。在此图示中，应用程序阶段是单个进程，但此阶段也可以是流水线或并行化的。注意，光栅化找到图元内的像素，例如三角形。</font>

渲染速度可以以每秒帧数（FPS）表示，即每秒渲染的图像的数量。它也可以用赫兹（Hz）表示，它只是1 /秒的符号，即更新的频率。通常以毫秒（ms）表示渲染图像所需的时间。生成图像的时间通常会有所不同，具体取决于每帧期间执行的计算的复杂程度。每秒帧数用于表示特定帧的速率，或表示某个使用持续时间内的平均性能。赫兹用于硬件，例如显示器，其能被设置为固定速率。

​		顾名思义，应用程序阶段由应用程序驱动，因此通常由在通用CPU上运行的软件实现。这些CPU通常包括多个内核，这些内核能够并行处理多个执行线程。这使CPU可以高效地运行应用程序阶段负责的各种任务。传统上在CPU上执行的某些任务包括碰撞检测，全局加速算法，动画，物理仿真以及许多其他任务，具体取决于应用程序的类型。下一个主要阶段是几何处理，它处理变换，投影和所有其他类型的几何处理。此阶段计算要绘制的内容，应如何绘制以及应在何处绘制。几何阶段通常在包含许多可编程内核以及固定操作硬件的图形处理单元（GPU）上执行。光栅化阶段通常将三个顶点作为输入，形成一个三角形，然后找到该三角形内所有要考虑的像素，然后将其转发到下一个阶段。最后，像素处理阶段为每个像素执行一个程序以确定其颜色，并可以执行深度测试以查看其是否可见。它还可以执行每个像素的操作，例如将新计算的颜色与以前的颜色混合。光栅化和像素处理阶段也完全在GPU上进行处理。所有这些阶段及其内部管道将在接下来的四个部分中讨论。有关GPU如何处理这些阶段的更多详细信息，请参阅第3章。

### 2.2应用程序阶段

​		由于通常在CPU上执行，因此开发人员可以完全控制应用程序阶段发生的事情。因此，开发人员可以完全确定实现，以后可以对其进行修改以提高性能。此处的更改也会影响后续阶段的性能。例如，应用程序阶段算法或设置可以减少要渲染的三角形的数量。
​		综上所述，某些应用程序工作可以由GPU使用称为计算着色器的单独模式来执行。此模式将GPU视为高度并行的通用处理器，而忽略了专门用于渲染图形的特殊功能。在应用程序阶段结束时，要渲染的几何图形被传送到几何阶段。这些是渲染图元（rendering primitives），即点，线和三角形，它们最终可能最终出现在屏幕上（或使用的任何输出设备）。这是应用程序阶段最重要的任务。

​		此阶段基于软件的实现的结果是，它不像几何处理，光栅化和像素处理阶段那样分为子阶段。但是为了提高性能，该阶段通常在多个处理器上并行执行核心。在CPU设计中，这被称为超标量构造，因为它能够在同一阶段同时执行多个进程$$^1$$。第18.5节介绍了使用多个处理器内核的各种方法。

​		<font size =1.5>1.于CPU本身的流水线规模要小得多，因此可以说应用程序阶段可进一步细分为几个流水线阶段，但这与此处无关。</font>

​		在此阶段通常实现的是碰撞检测。在两个物体之间检测到碰撞之后，可以生成响应并将其发送回碰撞的物体以及力反馈设备。在应用程序阶段，还要处理来自其他来源的输入，例如键盘，鼠标或头戴式显示器。根据此输入，可以发生几种不同类型的动作。加速算法，例如特定的剔除算法（第19章），也在这里实现，以及渲染管线其余部分无法处理的其他任何事情。

###2.3几何阶段

​		GPU上的几何处理阶段负责大部分对每个三角形和每个顶点的操作。该阶段进一步分为以下功能阶段：顶点着色，投影，修剪和屏幕映射（图2.3）。

![1569161769020](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161769020.png)

​		<font size =2>图2.3几何阶段分为由几个功能阶段组成的管线。</font>

####2.3.1顶点着色

​		顶点着色有两个主要任务，即计算一个顶点的位置并评估程序员可能希望作为顶点输出数据的任何东西，例如法线和纹理坐标。在传统意义上，一个对象的大部分阴影是通过将光线应用于每个顶点的位置和法线并仅在顶点存储结果颜色来计算的。然后将这些颜色插值到整个三角形上。因此，该可编程顶点处理单元被称为顶点着色器[1049]。随着现代GPU的出现，以及每个像素发生部分或全部着色，此顶点着色阶段变得更加通用，并且可能根本无法评估任何着色方程式，具体取决于程序员的意图。现在，顶点着色器是一个更通用的单元，专用于设置与每个顶点关联的数据。例如，顶点着色器可以使用第4.4节和第4.5节中的方法对对象进行动画处理。

​		我们首先描述如何计算顶点位置，这是始终需要的一组坐标。在进入屏幕的过程中，模型被转换为几个不同的空间或坐标系。最初，模型驻留在其自己的模型空间中，这仅表示该模型根本没有进行转换。每个模型都可以与模型变换相关联，以便可以定位和定向。可能有多个模型变换与单个模型相关联。这允许同一模型的多个副本（称为实例(instances)）在同一场景中具有不同的位置，方向和大小，而无需复制基本几何图形。

​		模型变换变换的是模型的顶点和法线。对象(object)，这里指模型本身，的坐标称为模型坐标，并且在将模型变换应用于这些坐标之后，可以说模型位于世界坐标或世界空间中。世界空间是唯一的，在对模型进行了各自的模型变换后，所有模型都存在于同一空间中。

​		如前所述，仅被摄像机（或观察者）所看到的模型被渲染。摄像机在世界空间中具有特定方向来校准摄像机视角和在特定的位置来放置摄像机。为了便于投影和裁剪操作，使用视图变换对摄像机和所有模型进行变换。视图变换的目的是将摄影机放置在原点并将其对准目标，使其沿负z轴方向看，y轴指向上方，x轴指向右侧。我们使用-z轴约定；有些文字更喜欢看向+ z轴。区别主要是语义上的，因为彼此之间的转换很简单。应用视图变换后的实际位置和方向取决于基础应用程序编程接口（API）。如此划定的空间称为相机空间(camera space)，或更普遍地称为视野空间(view space)或眼睛空间。视图转换影响相机和模型的方式示例如图2.4所示。模型变换和视图变换都可以使用4×4矩阵实现，这是第4章的主题。但是，重要的是要认识到顶点的位置和法线都可以被程序员喜欢的任何方式来计算。

![1569161848796](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161848796.png)

​		<font size=2>图2.4。在左图中，自上而下的视图显示了在+ z轴朝上的世界中，按用户期望的方式定位和定向的相机。视图变换可重新定向世界，以使相机位于其原点，沿其负z轴看，而相机的+ y轴朝上，如右图所示。这样做是为了使剪切和投影操作更简单，更快捷。浅蓝色区域是视图体积。在此，假定透视图，因为视图体积为平截头体。类似的技术适用于任何类型的投影。</font>

​		接下来，我们描述顶点着色的第二种输出类型。要产生逼真的场景，仅渲染对象的形状和位置是不够的，但是还必须对它们的外观进行建模。此说明包括每个对象的材料，以及任何照在该对象上的光源的效果。材质和灯光可以采用多种方式建模，从简单的颜色表示到详尽的物理描述。

​		确定光线对材料的影响的这种操作称为着色(shading)。它涉及计算模型对象上各个点的着色方程式。通常，其中一些对模型顶点的计算是在的几何图形处理期间执行的，而其他一些计算可能是在逐像素处理期间执行的。每个顶点可以存储各种材料数据，例如点的位置，法线，颜色或任何评估着色方程式所需的其他数字信息。然后将顶点着色的结果（可以是颜色，矢量，纹理坐标以及任何其他种类的着色数据）发送到光栅化和像素处理阶段以进行插值，并用于计算表面的着色。
​		在本书中，尤其将更深入地讨论GPU顶点着色器的顶点着色形式，在第3章和第5章中。

​		作为顶点着色的一部分，渲染系统先进行投影然后进行裁剪操作，这会将视图体积转换为单位立方体，其顶点位于（-1，-1，-1）和（1、1、1）。并且可以使用定义相同体积但不同范围单位立方体，例如0≤z≤1。单位立方称为规范视图体积。进行投影操作，通常在GPU上由顶点着色器完成。有两种常用的投影方法，即正交投影（也称为平行投影）和透视投影。参见图2.5。实际上，正交投影只是平行投影的一种类型。特别是在建筑领域，还有其他一些用途，例如斜投影和轴测投影。旧的街机游戏Zaxxon从后者命名。

![1569161883414](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161883414.png)

<font size=2>		  图2.5 左侧是正交投影或平行投影；右边是透视图。</font>

​		请注意，投影操作表示为矩阵（第4.7节），因此有时可以将其与其余的几何变换连接在一起。

​		正交视图的视图体积通常是一个矩形框，而正交投影会将此视图体积转换为单位立方体。正交投影的主要特征是，平行线在变换后保持平行，此转换是平移和缩放的组合。

​		透视投影有点复杂。在这种类型的投影中，物体离相机越远，投影后出现的越小。此外，平行线可能会聚在地平线上。因此，透视变换模仿了我们感知物体尺寸的方式。从几何学上讲，视场称为视锥，是具有矩形底面的截顶金字塔。视锥也将转换为单位立方体。正交变换和透视变换都可以使用4×4矩阵构造（第4章），并且在进行任何变换之后，都将模型称为裁剪坐标。这些实际上是齐次坐标，将在第4章中进行讨论，因此，这发生在被w除之前。 GPU的顶点着色器必须始终输出此类型的坐标，以使下一个功能阶段（裁剪）正常工作。

​		尽管这些矩阵将一个体积转换为另一个体积，但它们被称为投影，因为在显示之后，z坐标不存储在生成的图像中，而是存储在z缓冲区中，如2.5节所述。这样，模型可以从三个维度投影到两个维度。

#### 2.3.2可选的顶点处理

​		每个管道都有刚刚描述的顶点处理。完成此处理后，GPU上将按照以下顺序进行几个可选阶段：细分(tessellation)，几何着色( geometry shading)和流输出(stream output)。它们的使用取决于硬件的功能（并非所有GPU都具有）以及程序员的需求。它们彼此独立，并且通常不常用。在第3章中将对每个进行更多说明。

​		第一个可选阶段是细分。假设您有一个弹跳的球物体。如果用一组三角形表示它，则可能会遇到质量或性能问题。您的球从5米远处看起来可能不错，但近距离可以看到各个三角形，尤其是沿着轮廓的三角形。如果用更多的三角形制作球以提高质量，则当球太远且仅覆盖屏幕上的几个像素时，可能会浪费大量的处理时间和内存。通过细分，可以生成具有适当数量的三角形的曲面。

​		我们已经讨论了一些三角形，但是到目前为止，我们只处理了顶点。这些可用于表示点，线，三角形或其他对象。顶点可用于描述曲面，例如球。这样的表面可以由一组面片指定，每个面片由一组顶点组成。细分阶段本身包含一系列阶段（船体着色器，细分和域着色器），这些阶段将这些面片顶点集转换为（通常）更大的顶点集，然后用于创建新的三角形集。场景的摄像头可用于确定生成了多少个三角形：靠近时会生成许多三角形，而远离时会生成很少的三角形。

​		下一个可选阶段是几何着色器。该着色器早出现于曲面细分着色器，因此在GPU上更常见。就像曲面细分着色器一样，它可以吸收各种图元并可以产生新的顶点。这是一个非常简单的阶段，因为此创建的范围受到限制，输出基元的类型受到更多的限制。几何着色器有多种用途，其中最流行的一种是粒子生成。想象一下模拟烟花爆炸。每个火球都可以由一个点，单个顶点表示。几何着色器可以获取每个点并将其变成面向观察者并覆盖多个像素的正方形（由两个三角形组成），从而为我们提供了更具说服力的图元进行着色。

​		最后一个可选阶段称为流输出。在此阶段，我们可以将GPU用作几何引擎。此时，我们可以选择将其输出到数组以进行进一步处理，而不是将处理后的顶点向下发送到要渲染到屏幕的剩余管线中。这些数据可以在以后的过程中由CPU或GPU本身使用。此阶段通常用于粒子模拟，例如我们的烟花示例。
​		这三个阶段按此顺序执行（细分，几何体着色和流输出），并且每个阶段都是可选的。不管使用哪个（如果有）选项，如果我们继续沿管线移动，我们都有一组具有齐次坐标的顶点，不论如何都可以在相机视图中查看它们。

#### 2.3.3裁剪

​		只需要将全部或部分视锥体内的图元传递到光栅化阶段（以及随后的像素处理阶段），然后将其绘制在屏幕上。完全位于视锥体内的图元将原样传递到下一个阶段。完全不在视图体积之外的基元不会进一步传递，因为它们不会被渲染。只是部分在视锥体内的图元需要被裁剪。例如，有一条直线有一个顶点在视锥体内另一个顶点在视锥体外那么这条直线需要被视锥体裁剪，将外部顶点替换为位于该线和视图体积的交点处的新顶点。投影矩阵的使用意味着将变换后的图元剪裁在单位立方体上。在裁剪之前执行视图转换和投影的优点是使裁剪问题一致。图元总是被裁剪在单位立方体上。

​		裁剪过程如图2.6所示。除了单位立方体的六个剪切平面之外，用户还可以定义其他剪切平面以可视方式剪切对象。在第818页的图19.1中显示了显示这种类型的可视化效果的图像，称为切片

​		裁剪步骤使用投影产生的4值齐次坐标执行裁剪。在透视空间中，值通常不会跨三角形线性内插。需要第四个坐标，以便在使用透视投影时正确地插入和剪切数据。最后，执行透视划分，将所得三角形的位置放入三维归一化的设备坐标中。如前所述，此视图的体积范围是（-1，-1，-1）到（1,1,1）。几何阶段的最后一步是从该空间转换为窗口坐标

![1569161909685](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161909685.png)

​		<font size=2>图2.6。投影变换后，仅将单位立方体内的图元（对应于视锥中的图元）进行后续处理。因此，完全位于单位立方体外的图元将被丢弃，并完全保留完全位于单位立方体内的图元。与单位立方体相交的图元被裁剪到单位立方体上，从而生成新的顶点，而旧的顶点被丢弃。</font>

#### 2.3.4屏幕映射

​		只有视图体积内的（剪切后）图元传递到屏幕映射阶段，进入该阶段时坐标仍然是三维的。每个图元的x坐标和y坐标都将转换为屏幕坐标。屏幕坐标和z坐标也称为窗口坐标。假定场景应渲染到窗口中，最小角在（x1，y1）处，最大角在（x2，y2），其中x1 <x2并且y1 <y2。然后，屏幕映射是平移，随后是缩放操作。新的x和y坐标称为屏幕坐标。 z坐标（对于OpenGL为[−1，+1]，对于DirectX为[0，1]）也映射到[z1，z2]，其中z1 = 0和z2 = 1为默认值。但是，可以使用API进行更改。窗口坐标以及此重新映射的z值将传递到光栅化器阶段。屏幕映射过程如图2.7所示。

![1569161927375](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569161927375.png)

​		<font size =2>图2.7。投影变换后，图元位于单位立方体中，并且屏幕映射过程会在屏幕上查找坐标。</font>

​		接下来，我们描述整数和浮点值与像素（和纹理坐标）的关系。给定水平像素数组并使用笛卡尔坐标，最左像素的左边界在浮点坐标中为0.0。 OpenGL一直使用此方案，DirectX 10及其后续版本使用它。该像素的中心为0.5。因此，像素[0，9]的范围覆盖了[0.0，10.0）的范围。转换很简单
$$
d=floot(c)\qquad\qquad\qquad (2.1)
\\
c=d+0.5\qquad\quad\quad\qquad (2.2)
$$
其中d是像素的离散（整数）索引，c是像素内的连续（浮点）值。

​		尽管所有API的像素位置值都从左到右增加，但在某些情况下OpenGL和DirectX之间的上下边界零位置不一致。$$^2$$OpenGL始终偏爱笛卡尔系统，将左下角视为值最低的元素，而DirectX有时会根据上下文将左上角定义为此元素。每种都有逻辑，在不同之处没有正确答案。例如，（0，0）位于OpenGL中图像的左下角，而在DirectX中位于左上角。从一个API迁移到另一个API时，必须考虑到这一差异。

​		<font size=1>2.“ Direct3D”是DirectX的三维图形API组件。 DirectX包括其他API元素，例如输入和音频控件。除了在指定特定版本时编写“ DirectX”和在讨论该特定API时编写“ Direct3D”之间，我们没有区别，而是通篇编写“ DirectX”来遵循常用用法。</font>

### 2.4光栅化

​		给定经过变换操作和投影操作的顶点及其关联的阴影数据（全部来自几何阶段），下一阶段的目标是查找要渲染的图元（例如三角形）内的所有像素（图片元素的简称）。我们称这种过程为光栅化，它分为两个功能子阶段：三角形设置（也称为图元装配）和三角形遍历。这些显示在图2.8的左侧。注意，它们也可以处理点和线，但是由于三角形是最常见的，因此子阶段的名称中带有“三角形”。光栅化，也称为扫描转换，是从屏幕空间中的二维顶点（每个顶点具有z值（深度值）以及与每个顶点相关的各种阴影信息）到屏幕上的像素的转换。光栅化也可以被视为几何处理阶段和像素处理阶段之间的同步点，因为在这里，三角形是由三个顶点形成的，并最终传递到像素处理阶段。

​		三角形是否被视为与像素重叠取决于您如何设置GPU管线。例如，您可以使用点采样来确定“内部”。最简单的情况是在每个像素的中心使用一个点采样，因此，如果该中心点在三角形内部，则相应的像素也被认为在三角形内部。您还可以使用超采样或多采样抗锯齿技术对每个像素使用一个以上的采样（第5.4.2节）。还有一种方法是使用保守光栅化，其定义是，如果像素的至少一部分与三角形重叠，则该像素“位于三角形内”（第23.1.2节）。

![1569244367703](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569244367703.png)

​		<font size=2>图2.8。左：光栅化分为两个功能阶段，称为三角形建立和三角形遍历。右图：像素处理分为两个功能阶段，即像素处理和合并。</font>

#### 2.4.1三角形建立

​		在这一阶段，计算三角形的微分，边方程和其他数据。这些数据可用于三角形遍历（第2.4.2节），以及用于内插几何阶段产生的各种阴影数据。固定功能的硬件用于此任务。

#### 2.4.2三角形遍历

​		在这里检查每个中心（或样本）被三角形覆盖的像素，并为与三角形重叠的像素部分生成一个片段。更多详细的采样方法可以在第5.4节中找到。查找哪些样本或像素在三角形内通常被称为三角形遍历。每个三角形片段的属性都是使用在三个三角形顶点之间插值的数据生成的（第5章）。这些属性包括片段的深度，以及来自几何图形阶段的任何阴影数据。 McCormack. [1162]提供了更多关于三角形遍历的信息。在这里，也可以在三角形上执行透视校正内插[694]（第23.1.1节）。然后将图元内部的所有像素或样本发送到像素处理阶段，如下所述。

### 2.5像素处理

​		在这一点上，由于所有先前阶段的组合，已经找到了在三角形或其他图元内部考虑的所有像素。像素处理阶段分为像素着色和合并，如图2.8右侧所示。像素处理是对图元内部的像素或样本执行每个像素或每个样本的计算和操作的阶段。

#### 2.5.1像素着色

​		使用插值的着色数据作为输入，此处可以执行任何每个像素的着色计算。最终结果是一种或多种颜色将传递到下一个阶段。与通常由硬件执行的三角形设置和遍历阶段不同，像素着色阶段由可编程GPU内核执行。为此，程序员为像素着色器（或片段着色器，在OpenGL中众所周知）提供了一个程序，该程序可以包含任何所需的计算。这里可以使用多种技术，其中最重要的一种是纹理化。在第6章中将更详细地讨论纹理化。简单地说，对一个对象进行纹理化意味着出于各种目的将一个或多个图像“粘合”到该对象上。此过程的一个简单示例如图2.9所示。图像可以是一维，二维或三维图像，其中二维图像是最常见的。最简单的说，最终产品是每个片段的颜色值，并将它们传递到下一个子阶段。

![1569244499368](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569244499368.png)

​		<font size=2>图2.9左上方显示了没有纹理的龙模型。图片中的碎片，将纹理“粘合”到龙上，结果显示在左下方。</font>

#### 2.5.2合并

​		每个像素的信息都存储在颜色缓冲区中，颜色缓冲区是颜色的矩形阵列（每种颜色的红色，绿色和蓝色分量）。合并阶段负责将像素着色阶段产生的片段颜色与当前存储在缓冲区中的颜色进行组合。此阶段也称为ROP，代表“光栅操作（管道）”或“渲染输出单元”，具体取决于您要求的人。与着色阶段不同，执行此阶段的GPU子单元通常不是完全可编程的。但是，它是高度可配置的，可实现各种效果。

​		此阶段还负责解决可见性。这意味着在渲染整个场景后，颜色缓冲区应包含场景中从相机的角度可见的基元的颜色。对于大多数甚至所有图形硬件，这都是通过z缓冲区（也称为深度缓冲区）算法[238]完成的。 Z缓冲区的大小和形状与颜色缓冲区相同，并且对于每个像素，Z缓冲区将z值存储到当前最接近的图元。这意味着，当将图元渲染到某个像素时，该图元在该像素处的z值将被计算并与同一像素处z缓冲区的内容进行比较。如果新的z值小于z缓冲区中的z值，则正在渲染的图元比之前在那个像素处最接近相机的图元更接近相机。因此，该像素的z值和颜色将使用所绘制图元的z值和颜色进行更新。如果计算的z值大于z缓冲区中的z值，则保持颜色缓冲区和z缓冲区不变。 z缓冲区算法很简单，具有O（n）收敛（其中n是要渲染的图元的数量），并且适用于可以为每个（相关）像素计算z值的任何绘图图元。还要注意，该算法允许大多数图元以任何顺序呈现，这是其普及的另一个原因。但是，z缓冲区仅在屏幕上的每个点存储一个深度，因此不能用于部分透明的图元。透明图元必须在所有不透明基元之后渲染，以从后到前的顺序或使用单独的独立于顺序的算法（第5.5节）呈现这些内容。透明度是基本z缓冲区的主要弱点之一。

​		我们已经提到了颜色缓冲区用于存储颜色，而z缓冲区用于存储每个像素的z值。但是，还有其他通道和缓冲区可用于筛选和捕获片段信息。 Alpha通道与颜色缓冲区关联，并为每个像素存储相关的不透明度值（第5.5节）。在较早的API中，alpha通道还用于通过alpha测试功能选择性地丢弃像素。如今，可以将丢弃操作插入到像素着色器程序中，并且可以使用任何类型的计算来触发丢弃。可以使用这种类型的测试来确保完全透明的片段不会影响z缓冲区（第6.6节）。

​		模板缓冲区是一个屏幕外缓冲区，用于记录渲染图元的位置。它通常每个像素包含8位。可以使用各种功能将基元渲染到模板缓冲区中，然后可以使用缓冲区的内容来控制渲染到颜色缓冲区和z缓冲区中。例如，假设已将填充圆绘制到模板缓冲区中。允许以填充圆作为父物体的后续图元和填充圆组合渲染到颜色缓冲区中。模板缓冲区可以是生成某些特殊效果的强大工具。流水线末端的所有这些功能都称为光栅操作（ROP）或混合操作。可以将当前颜色缓冲区中的颜色与三角形内要处理的像素的颜色混合。这可以实现诸如透明度或颜色样本累积的效果。如前所述，混合通常可以使用API进行配置，而不是完全可编程的。但是，某些API支持光栅顺序视图，也称为像素着色器顺序，可启用可编程混合功能。

​		帧缓冲区通常由系统上的所有缓冲区组成。
​		当图元到达并通过光栅化阶段时，从相机的角度可见的图元将显示在屏幕上。屏幕显示颜色缓冲区的内容。为了避免让人类观看者在对其进行栅格化并将其发送到屏幕时看到它们，使用了双重缓冲。这意味着场景的渲染发生在屏幕后方的缓冲区中。将场景渲染到后缓冲区中后，后缓冲区的内容将与先前在屏幕上显示的前缓冲区的内容交换。交换通常发生在垂直回扫过程中，这是安全的时间。
​		有关不同缓冲区和缓冲方法的更多信息，请参见第5.4.2、23.6和23.7节

### 2.6纵观渲染管线

​		点，线和三角形是用于构建模型或对象的渲染图元。假设该应用程序是交互式计算机辅助设计（CAD）应用程序，并且用户正在检查华夫饼制作机的设计。在这里，我们将在整个图形渲染管道中使用此模型，包括四个主要阶段：应用程序，几何，光栅化和像素处理。通过透视投影将场景渲染到屏幕上的窗口中。在这个简单的示例中，华夫饼制作机模型同时包含线（以显示零件的边缘）和三角形（以显示表面）。华夫饼制作机的盖子可以打开。一些三角形是由带有制造商徽标的二维图像制成的。对于此示例，除了在光栅化阶段发生的纹理应用之外，表面着色是在几何阶段完全计算出来的。

#### 应用程序阶段

​		CAD应用程序允许用户选择和移动模型的各个部分。例如，用户可以选择盖子，然后移动鼠标将其打开。应用阶段必须将鼠标移动转换为相应的旋转矩阵，然后确认呈现该矩阵时已将其正确应用于盖子。另一个示例：播放动画，使动画沿预定路径移动，以从不同的角度显示华夫饼制作机。然后必须由应用程序根据时间更新相机参数，例如位置和视图方向。对于要渲染的每个帧，应用程序阶段将相机的位置，照明和模型的图元传入管线中的下一个主要阶段-几何阶段。

#### 几何阶段

​		对于透视图，我们在此假定应用程序已提供了投影矩阵。同样，对于每个对象，应用程序都已计算出一个矩阵，该矩阵描述了视图变换以及对象本身的位置和方向。在我们的示例中，华夫饼制造商的底座将具有一个矩阵，而盖子则具有另一个矩阵。在几何阶段，使用此矩阵转换对象的顶点和法线，从而将对象变化到视图空间。然后，可以使用材质和光源属性来计算顶点处的阴影或其他计算。然后使用单独的用户提供的投影矩阵执行投影，将对象转换为代表眼睛所见的单位立方体的空间。单位立方体外部的所有图元都将被丢弃。将与该单位立方体相交的所有图元都裁剪到该单位立方体上，以便获得一组完全位于单位立方体内的图元。然后将这些顶点映射到屏幕上的窗口中。在完成所有这些按三角形和按顶点进行的操作之后，将所得数据传递到光栅化阶段。

#### 光栅化

​		然后光栅化所有在上一阶段幸存下来的图元，这意味着找到了图元内部的所有像素，并将它们进一步发送到管线以进行像素处理。

#### 像素处理

​		此处的目标是计算每个可见图元的每个像素的颜色。那些与任何纹理（图像）相关联的三角形将根据需要应用这些图像进行渲染。可见性通过z缓冲区算法以及可选的丢弃和模板测试来解决。依次处理每个对象，然后将最终图像显示在屏幕上。

### 结语

​		渲染管线源于针对实时渲染应用程序的数十年的API和图形硬件演变。重要的是要注意，这不是唯一的渲染管线。离线渲染管道经历了不同的进化路径。电影制作的渲染通常是通过微多边形管线完成的[289，1734]，但是光线追踪和路径追踪近来已取而代之。 11.2.2节中介绍的这些技术，这些技术也可以用于建筑和设计的预可视化。

​		多年来，应用程序开发人员使用此处描述的过程的唯一方法是通过使用中的图形API定义的固定功能管道。固定功能管道之所以如此命名，是因为实现它的图形硬件包含无法灵活编程的元素。主要的固定功能机器的最后一个例子是2006年推出的Nintendo的Wii。另一方面，可编程GPU使得可以确切确定在整个生产流程的各个子阶段中应用了哪些操作。对于本书的第四版，我们假设所有开发都是使用可编程GPU完成的。

### 进一步阅读和资源

​		布林的著作《A Trip Down the Graphics Pipeline 》 [165]是一本关于从头开始编写软件渲染器的旧书。它是学习实现渲染管线的一些精妙之处，解释关键算法（例如裁剪和透视插值）的好资源。古老的（至今仍经常更新）《 OpenGL编程指南》（又称“红皮书”）[885]提供了图形管道的完整描述以及与其使用相关的算法。本书的网站realtimerendering.com提供了指向各种管线图，渲染引擎实现等的链接。















## 3.GPU

​		从历史上看，图形加速始于在与三角形重叠的每个像素扫描线上插入颜色，然后显示这些值。包括访问图像数据的功能，可以将纹理应用于表面。添加用于内插和测试z深度的硬件，提供了内置的可见性检查。由于它们的频繁使用，因此将此类过程专用于专用硬件以提高性能。连续几代中添加了渲染管线的更多部分，以及每个部分的更多功能。专用图形硬件相对于CPU的唯一计算优势是速度，但速度至关重要

​		在过去的二十年中，图形硬件经历了不可思议的转变。 1999年交付的第一款包含硬件顶点处理的消费类图形芯片（NVIDIA的GeForce256）。NVIDIA创造了图形处理单元（GPU）一词，以将GeForce 256与以前可用的仅光栅化的芯片区分开来，并且始终如一。在接下来的几年中，GPU从复杂的固定功能管道的可配置实现发展到高度可编程的空白状态，开发人员可以在其中实现自己的算法。各种可编程着色器是控制GPU的主要方法。为了提高效率，流水线的某些部分仍然是可配置的，而不是可编程的，但是趋势是朝着可编程性和灵活性的方向发展[175]。

​		GPU通过专注于一组高度可并行化的任务而获得了卓越的速度。他们拥有专用于实现z缓冲区，快速访问纹理图像和其他缓冲区以及查找例如三角形覆盖的像素的定制芯片。这些元素如何执行其功能将在第23章中介绍。更重要的是，早期要知道GPU如何实现其可编程着色器的并行性。

​		3.3节介绍了着色器的功能。目前，您需要知道的是着色器核心是一个小型处理器，可以执行一些相对隔离的任务，例如将顶点从其在世界上的位置转换为屏幕坐标，或者计算被一个三角形覆盖的一个像素的颜色。。每帧有成千上万个三角形发送到屏幕，每秒可能有数十亿次着色器调用，即运行着色器程序的单独实例。

​		首先，延迟是所有处理器都面临的问题。访问数据需要花费一些时间。考虑延迟的一种基本方法是，信息离处理器越远，等待时间就越长。第23.3节详细介绍了延迟。存储在存储芯片中的信息将比本地寄存器中的信息花费更长的时间。 18.4.1节将更深入地讨论内存访问。关键是等待数据检索意味着处理器停滞了，这降低了性能。

### 3.1数据并行架构

​		不同的处理器体系结构使用各种策略来避免停顿。对CPU进行了优化，以处理各种数据结构和大型代码库。 CPU可以具有多个处理器，但是每个CPU都以串行方式运行代码，有限的SIMD矢量处理是次要的例外。为了最大程度地减少延迟的影响，CPU的许多芯片都由快速本地缓存组成，这些内存中填充了接下来可能需要的数据。 CPU还通过使用诸如分支预测，指令重新排序，寄存器重命名和缓存预取之类的巧妙技术来避免停顿。[715]

​		GPU采用不同的方法。 GPU的大部分芯片区域专用于称为着色器核心的大量处理器，通常数量多达数千个。 GPU是流处理器，其中依次处理相似数据的有序集合。由于这种相似性（例如，一组顶点或像素），GPU可以大规模并行地处理这些数据。另一个重要的元素是这些调用尽可能地独立，因此它们不需要来自相邻调用的信息，并且不共享可写的存储位置。有时会破坏该规则以允许新的有用功能，但是此类异常的代价是潜在的延迟，因为一个处理器可能会等待另一个处理器完成其工作。
​		GPU针对吞吐量进行了优化，吞吐量定义为可以处理数据的最大速率。但是，这种快速处理具有成本。由于专用于高速缓存存储器和控制逻辑的芯片面积较小，因此每个着色器内核的等待时间通常比CPU处理器遇到的等待时间长得多[462]。

​		假设网格已栅格化，并且两千个像素具有要处理的片段；像素着色器程序将被调用2000次。想象只有一个着色器处理器，这是世界上最弱的GPU。它开始为2000的第一个片段执行着色器程序。着色器处理器对寄存器中的值执行一些算术运算。寄存器是本地的，可以快速访问，因此不会发生停顿。然后，着色器处理器会执行一条指令，例如纹理访问；例如，对于给定的表面位置，程序需要知道应用于网格的图像的像素颜色。纹理是一个完全独立的资源，而不是像素程序本地内存的一部分，并且纹理访问可能会涉及到一定程度。内存提取可能需要数百到数千个时钟周期，在此期间GPU处理器不执行任何操作。此时，着色器处理器将停止运行，等待纹理的颜色值返回

​		为了使这个糟糕的GPU变得更好，请为每个片段提供一些用于其本地寄存器的存储空间。现在，允许着色器处理器切换并执行另一个片段，即两千个第二个片段，而不是停止纹理获取。此切换速度非常快，除了注意第一条指令正在执行哪条指令之外，第一段或第二段中的内容均不受影响。现在执行第二个片段。与第一个相同，执行一些算术函数，然后再次遇到纹理获取。着色器核心现在切换到另一个片段，即第三个片段。最终，所有两千个片段都以这种方式处理。此时，着色器处理器将返回片段编号1。此时，纹理颜色已被获取并且可以使用，因此着色器程序可以继续执行。处理器以相同的方式进行处理，直到遇到另一个已知会暂停执行的指令，或者程序完成。与着色器处理器始终专注于一个片段相比，执行单个片段所需的时间更长，但是整个片段的总体执行时间将大大减少。

​		在这种架构中，通过切换到另一个片段使GPU保持忙碌来隐藏延迟。 GPU通过将指令执行逻辑与数据分离开来，使该设计更进一步。称为单指令多数据（SIMD）的这种安排可以在固定数量的着色器程序上以锁定步骤执行同一命令。 SIMD的优点是，与使用单独的逻辑和调度单元运行每个程序相比，用于处理数据和交换的硅（和功率）要少得多。将我们的2000片段示例转换成现代的GPU术语，片段的每个像素着色器调用都称为线程。这种类型的线程与CPU线程不同。它由用于着色器输入值的一点内存以及着色器执行所需的任何寄存器空间组成。使用相同着色器程序的线程被分为几组，被NVIDIA称为warp，被AMD称为wavefronts。计划通过一些SIMD处理功能，在8到64之间的任意数量的GPU着色器内核中执行扭曲/波前。每个线程都映射到SIMD通道。

​		假设我们有两千个线程要执行。 NVIDIA GPU的扭曲包含32个线程。这将产生2000/32 = 62.5个经纱，这意味着分配了63个经纱，其中一个经纱是一半为空。扭曲的执行类似于我们的单个GPU处理器示例。着色器程序在所有32个处理器上以锁定步骤执行。遇到内存提取时，所有线程都会同时遇到它，因为对所有线程执行相同的指令。提取信号表明线程扭曲将停止，所有线程都在等待它们的（不同的）结果。不会停顿，而是将warp换成32个线程的另一个warp，然后由32个内核执行。这种交换的速度与我们的单处理器系统一样快，因为在将warp换入或换出时，每个线程内的数据都不会被触及。每个线程都有自己的寄存器，每个线程束都跟踪其正在执行的指令。交换新线程只是将一组核心指向另一组要执行的线程即可。没有其他开销。扭曲执行或换出，直到全部完成。参见图3.1。

​		在我们的简单示例中，纹理获取内存的等待时间可能导致翘曲掉出。实际上，因为交换成本非常低，所以可以将经线换成较短的延迟。还有其他几种用于优化执行的技术[945]，但翘曲交换是所有GPU使用的主要延迟隐藏机制。此过程的效率如何涉及多个因素。例如，如果线程很少，那么几乎不会创建任何扭曲，从而使延迟隐藏成为问题。

​		着色器程序的结构是影响效率的重要特征。一个主要因素是每个线程使用的寄存器数量。在我们的示例中，我们假设一次可以将2000个线程全部驻留在GPU上。与每个线程相关联的着色器程序所需的寄存器越多，则线程中可以驻留的线程越少，因此扭曲也就越少。经线不足可能意味着无法通过交换来减轻失速。驻留的经线被称为“飞行中”，这个数字称为占用率。高占用率意味着有许多可用于处理的扭曲，因此空闲处理器的可能性较小。占用率低通常会导致性能不佳。内存提取的频率也影响需要多少延迟隐藏。 Lauritzen [993]概述了着色器使用的寄存器数量和共享内存如何影响占用率。 Wronski [1911，1914]讨论了理想的占用率如何根据着色器执行的操作类型而变化。

​		影响整体效率的另一个因素是由“ if”语句和循环引起的动态分支。假设在着色器程序中遇到“ if”语句。如果所有线程求值并采用同一分支，则warp可以继续进行而不必担心其他分支。但是，如果某些线程甚至一个线程采用了替代路径，那么warp必须执行两个分支，从而丢弃每个特定线程不需要的结果[530，945]。这个问题称为线程发散，其中一些线程可能需要执行循环迭代或执行“ war”路径，而warp中的其他线程则不这样做，从而使它们在此期间处于空闲状态。

​		所有GPU都实现了这些架构思想，从而导致系统具有严格的限制，但每瓦的计算能力却很大。了解该系统的运行方式将有助于您作为程序员充分利用其提供的功能。在以下各节中，我们讨论GPU如何实现渲染管线，可编程着色器如何运行以及每个GPU阶段的演变和功能。

![1569425237916](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425237916.png)

​		<font size=2>图3.1。简化的着色器执行示例。三角形的碎片（称为螺纹）被收集成经线。每个经线显示为四个线程，但实际上有32个线程。要执行的着色器程序长五个指令。四个GPU着色器处理器的集合在第一次扭曲时执行这些指令，直到在“ txr”命令上检测到停顿条件为止，这需要时间来获取其数据。交换第二个扭曲，并对其应用着色器程序的前三个指令，直到再次检测到停顿为止。交换第三个经线并使其停止后，通过交换第一个经线并继续执行，继续执行。如果此时尚未返回其“ txr”命令的数据，则执行将真正停止，直到这些数据可用为止。每个翘曲依次完成</font>

![1569425269701](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425269701.png)

​		<font size=2>图3.2。渲染管线的GPU实现。这些阶段根据用户对其操作的控制程度进行颜色编码。绿色阶段是完全可编程的。虚线表示可选阶段。黄色阶段是可配置的，但不是可编程的，例如，可以为合并阶段设置各种混合模式。蓝色阶段的功能完全固定。</font>

### 3.2GPU管线概述

​		GPU实现了第2章中描述的概念几何处理，栅格化和像素处理流水线阶段。这些阶段分为几个硬件阶段，这些阶段具有不同程度的可配置性或可编程性。图3.2显示了根据各个阶段的可编程性或可配置性对其进行颜色编码的各个阶段。请注意，这些物理阶段的划分与第二章中介绍的功能阶段有所不同。

​		我们在这里描述了GPU的逻辑模型，它是由API作为程序员向您公开的逻辑模型。正如第18和23章所讨论的那样，此逻辑管道（物理模型）的实现取决于硬件供应商。通过将命令添加到相邻的可编程阶段，可以在GPU上执行逻辑模型中固定功能的阶段。流水线中的单个程序可以分为由单独的子单元执行的元素，也可以由单独的遍历完全执行。逻辑模型可以帮助您推断出哪些因素会影响性能，但不要误以为GPU实际实现管道的方式。

​		顶点着色器是一个完全可编程的阶段，用于实现几何处理阶段。几何着色器是一个完全可编程的阶段，可在图元的顶点（点，线或三角形）上运行。它可用于执行每个图元的着色操作，销毁图元或创建新的图元。镶嵌级和几何着色器都是可选的，并非所有GPU都支持它们，尤其是在移动设备上。

​		裁剪，三角形设置和三角形遍历阶段由固定功能硬件实现。屏幕映射受窗口和视口设置的影响，在内部形成简单的比例尺并重新定位。像素着色器阶段是完全可编程的。尽管合并阶段不是可编程的，但是它是高度可配置的，可以设置为执行多种操作。它实现了“合并”功能阶段，负责修改颜色，z缓冲区，混合，模板和任何其他与输出相关的缓冲区。像素着色器的执行与合并阶段一起构成了第2章中介绍的概念性像素处理阶段。

​		随着时间的流逝，GPU管道已从硬编码操作演变为增加灵活性和控制能力。可编程着色器阶段的引入是这一发展过程中最重要的一步。下一节描述了各个可编程阶段的通用功能

### 3.3可编程着色器阶段

​		现代着色器程序使用统一的着色器设计。这意味着与顶点，像素，几何和镶嵌相关的着色器共享一个公共的编程模型。在内部，它们具有相同的指令集体系结构（ISA）。实现此模型的处理器在DirectX中称为“通用着色器核心”，据说具有此类核心的GPU具有统一的着色器体系结构。这种架构背后的想法是，着色器处理器可以在各种角色中使用，GPU可以根据需要分配它们。例如，与每个由两个三角形组成的大正方形相比，一组带有小三角形的网格将需要更多的顶点着色器处理。具有单独的顶点和像素着色器核心池的GPU意味着严格确定了使所有核心繁忙的理想工作分配。使用统一的着色器核心，GPU可以决定如何平衡此负载。

​		描述整个着色器编程模型已经超出了本书的范围，并且已经有许多文档，书籍和网站。着色器使用类似C的着色语言进行编程，例如DirectX的高级着色语言（HLSL）和OpenGL着色语言（GLSL）。 DirectX的HLSL可以编译为虚拟机字节码，也称为中间语言（IL或DXIL），以提供硬件独立性。中间表示还可以允许着色器程序被编译和离线存储。驱动程序将此中间语言转换为特定GPU的ISA。控制台编程通常避免中间语言步骤，因为那时系统只有一个ISA。

​		基本数据类型是32位单精度浮点标量和向量，尽管向量只是着色器代码的一部分，并且如上所述在硬件中不受支持。在现代GPU上，本机还支持32位整数和64位浮点数。浮点向量通常包含位置（xyzw），范数，矩阵行，颜色（rgba）或纹理坐标（uvwq）等数据。整数最常用于表示计数器，索引或位掩码。还支持聚合数据类型，例如结构，数组和矩阵。

​		绘制调用调用图形API来绘制一组基元，从而使图形管道执行并运行其着色器。每个可编程着色器阶段都有两种类型的输入：统一输入，其值在整个绘制调用期间保持不变（但可以在绘制调用之间进行更改），以及变化的输入，即来自三角形顶点或栅格化的数据。例如，像素着色器可以将光源的颜色提供为统一的值，并且三角形表面的位置每像素变化，因此也变化。纹理是一种特殊的统一输入，它曾经总是应用于表面的彩色图像，但现在可以认为是任何大型数据数组。

​		基础虚拟机为不同类型的输入和输出提供特殊的寄存器。用于制服的可用常数寄存器的数量比用于变化的输入或输出的可用寄存器的数量大得多。发生这种情况是因为需要为每个顶点或像素分别存储变化的输入和输出，因此对于需要多少个输入存在自然的限制。统一输入存储一次，并在绘制调用中的所有顶点或像素之间重复使用。虚拟机还具有用于暂存空间的通用临时寄存器。可以使用临时寄存器中的整数值对所有类型的寄存器进行数组索引。着色器虚拟机的输入和输出如图3.3所示。

![1569425303277](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425303277.png)

​		<font size=2>图3.3。 Shader Model 4.0下的统一虚拟机体系结构和寄存器布局。每个资源旁边都会显示最大可用数量。用斜杠分隔的三个数字表示顶点，几何和像素着色器的限制（从左到右）。</font>

​		图形计算中常见的操作可在现代GPU上高效执行。着色语言通过*和+等运算符公开了这些运算中最常见的运算（例如加法和乘法）。其余的通过内在函数公开，例如atan（），sqrt（），log（）以及为GPU优化的许多其他函数。对于更复杂的操作，也存在函数，例如矢量归一化和反射，叉积，矩阵转置和行列式计算。

​		术语流控制是指使用分支指令来更改代码执行流。与流控制相关的指令用于实现高级语言构造，例如“ if”和“ case”语句，以及各种类型的循环。着色器支持两种类型的流控制。静态流量控制分支基于统一输入的值。这意味着代码流在绘图调用中是恒定的。静态流控制的主要好处是允许将相同的着色器用于各种不同的情况（例如，不同数量的灯光）。由于所有调用都采用相同的代码路径，因此没有线程差异。动态流控制基于变化的输入的值，这意味着每个片段可以不同地执行代码。这比静态流控制功能强大得多，但会降低性能，尤其是在着色器调用之间代码流发生不规则变化时。

### 3.4可编程着色器和API的演变

​		可编程阴影框架的构想可以追溯到1984年，当时库克（Cook）的阴影树[287]。一个简单的着色器及其相应的着色树如图3.4所示。 RenderMan着色语言[63，1804]是在1980年代后期从这个想法发展而来的。如今，它与其他不断发展的规范（例如开放着色语言（OSL）项目[608]）一起用于电影制作渲染。

​		消费级图形硬件是3dfx Interactive于1996年10月1日首次成功引入的。有关今年的时间表，请参见图3.5。他们的Voodoo图形卡能够以高品质和性能渲染《 Quake》游戏，因此很快就被采用。该硬件始终实现了固定功能的流水线。在GPU原生支持可编程着色器之前，曾多次尝试通过多次渲染实时实现可编程着色操作。 Quake III：Arena脚本语言是1999年在该领域的首个广泛商业成功。如本章开头所述，NVIDIA的GeForce256是第一个被称为GPU的硬件，但它不是可编程的。但是，它是可配置的。

![1569425341790](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425341790.png)

​		<font size=2>图3.4。一个简单的铜着色器的着色树及其相应的着色器语言程序。 （在库克[287]之后。）</font>

![1569425360463](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425360463.png)

​		<font size=2>图3.5。一些API和图形硬件版本的时间表。</font>

​		在2001年初，NVIDIA的GeForce 3是第一个支持可编程顶点着色器[1049]的GPU，该着色器通过DirectX 8.0和OpenGL扩展公开。这些着色器以一种类似于汇编的语言进行编程，该语言被驱动程序即时转换为微代码。像素着色器也包含在DirectX 8.0中，但是像素着色器没有达到实际的可编程性-驱动程序将受支持的有限“程序”转换为纹理混合状态，然后将其连接到硬件“寄存器组合器”。这些“程序”是不仅限于长度（不超过12条指令），而且缺少重要的功能。 Peercy等人确定了相关的纹理读取和浮点数据。 [1363]对于真正的可编程性至关重要，来自他们对RenderMan的研究。

​		着色器此时不允许进行流控制（分支），因此必须通过计算两个项以及在结果之间进行选择或内插来模拟条件。 DirectX定义了着色器模型（Shader Model，SM）的概念，以区分具有不同着色器功能的硬件。 2002年，包括Shader Model 2.0在内的DirectX 9.0发行了，该版本具有真正可编程的顶点和像素着色器。在OpenGL下，使用各种扩展也公开了类似的功能。添加了对任意依赖的纹理读取的支持以及16位浮点值的存储，最终完成了Peercy等人确定的一组要求。诸如指令，纹理和寄存器之类的着色器资源的限制增加了，因此着色器变得能够实现更复杂的效果。还增加了对流量控制的支持。着色器的长度和复杂性不断增长，使得汇编编程模型变得越来越麻烦。幸运的是，DirectX 9.0还包含HLSL。这种着色语言是由Microsoft与NVIDIA合作开发的。大约在同一时间，OpenGL ARB（架构审查委员会）发布了GLSL，一种与OpenGL非常相似的语言[885]。这些语言在很大程度上受到C编程语言的语法和设计理念的影响，其中包括来自RenderMan着色语言的元素。

​		Shader Model 3.0于2004年推出，并添加了动态流控制，使着色器功能更加强大。它还将可选功能转变为需求，进一步增加了资源限制，并增加了对顶点着色器中纹理读取的有限支持。当在2005年末（微软的Xbox 360）和2006年末（索尼计算机娱乐公司的PLAYSTATION 3系统）推出新一代游戏机时，它们配备了Shader Model 3.0级GPU。任天堂的Wii控制台是最后一批著名的固定功能GPU之一，该GPU最初于2006年末交付。纯固定功能流水线在这一点上早已一去不复返了。着色器语言已经发展到可以使用各种工具来创建和管理它们的地步。图3.6显示了使用库克（Cook）的阴影树概念的一种此类工具的屏幕截图。

​		可编程性的下一个重大步骤也是在2006年底左右。DirectX 10.0 [175]中包含的Shader Model 4.0引入了几个主要功能，例如几何体着色器和流输出。 Shader Model 4.0包括适用于所有着色器（顶点，像素和几何图形）的统一编程模型，这是先前描述的统一着色器设计。资源限制进一步增加，并且增加了对整数数据类型（包括按位运算）的支持。 OpenGL 3.3中GLSL 3.30的引入提供了类似的着色器模型。

![1569425383020](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425383020.png)

​		<font size=2>图3.6。用于着色器设计的可视着色器图形系统。各种操作封装在功能框中，可在左侧选择。选中后，每个功能框都有可调参数，如右图所示。每个功能框的输入和输出相互链接以形成最终结果，如中间框架的右下方所示。 （摘自“心理磨坊”，mental images inc。）</font>

​		2009年发布了DirectX 11和Shader Model 5.0，添加了细分阶段着色器和计算着色器，也称为DirectCompute。该版本还专注于更有效地支持CPU多处理，这是第18.5节中讨论的主题。 OpenGL在4.0版中添加了细分，在4.3版中添加了计算着色器。 DirectX和OpenGL的发展不同。两者都设置了特定版本发行所需的一定级别的硬件支持。 Microsoft控制DirectX API，因此直接与独立硬件供应商（IHV）（例如AMD，NVIDIA和Intel）以及游戏开发商和计算机辅助设计软件公司合作，以确定要公开的功能。 OpenGL由非营利组织Khronos Group管理的硬件和软件供应商联盟开发。由于涉及的公司数量众多，API功能通常在DirectX中引入OpenGL之后的一段时间内就会出现。但是，OpenGL允许特定于供应商的或更广泛的扩展，这些扩展允许在发行版正式支持之前使用最新的GPU功能。

​		API的下一个重大变化是由AMD在2013年推出了MantleAPI。Mantle与视频游戏开发商DICE合作开发的，其目的是消除大部分图形驱动程序的开销，并将此控件直接交给开发人员。除了这种重构之外，还进一步支持有效的CPU多处理。这类新的API专注于大大减少CPU在驱动程序中花费的时间，以及更有效的CPU多处理器支持（第18章）。在Mantle中开创的创意被Microsoft采纳，并在2015年以DirectX 12的形式发布。请注意，DirectX 12并不专注于公开新的GPU功能-DirectX 11.3公开了相同的硬件功能。这两个API均可用于将图形发送到虚拟现实系统，例如Oculus Rift和HTC Vive。但是，DirectX 12是对API的彻底重新设计，可以更好地映射到现代GPU架构。低开销的驱动程序对于以下应用程序很有用：CPU驱动程序成本引起瓶颈，或者使用更多CPU处理器进行图形处理可能会提高性能[946]。从较早的API移植可能很困难，并且天真的实现可能会导致性能降低[249、699、1438]。

​		苹果在2014年发布了自己的低开销API（称为Metal）。Metal首次在iPhone 5S和iPad Air等移动设备上可用，一年后，可通过OS X El Capitan访问较新的Macing。除效率外，减少CPU使用率还可以节省功耗，这是移动设备上的重要因素。该API具有自己的着色语言，适用于图形和GPU计算程序。

​		AMD将其Mantle工作捐赠给了Khronos Group，后者于2016年初发布了自己的新API，名为Vulkan。与OpenGL一样，Vulkan可在多个操作系统上工作。 Vulkan使用一种称为SPIR-V的新高级中间语言，该语言可用于着色器表示和一般GPU计算。预编译的着色器是可移植的，因此可以在支持所需功能的任何GPU上使用[885]。 Vulkan也可以用于非图形GPU计算，因为它不需要显示窗口[946]。 Vulkan与其他低开销驱动程序的显着区别是，它旨在与多种系统一起使用，从工作站到移动设备。

​		在移动设备上，规范是使用OpenGL ES。 “ ES”代表嵌入式系统，因为该API是为移动设备而开发的。当时的标准OpenGL在其某些调用结构中相当庞大且缓慢，并且需要支持很少使用的功能。 OpenGL ES 1.0于2003年发布，是OpenGL 1.3的简化版本，描述了固定功能的管道。虽然DirectX的发布与支持它们的图形硬件的发布是同步的，但是开发针对移动设备的图形支持的方式却并不相同。例如，2010年发布的第一台iPad实施了OpenGL ES 1.1。 OpenGL ES 2.0规范于2007年发布，提供了可编程的阴影。它基于OpenGL 2.0，但没有固定功能组件，因此与OpenGL ES 1.1不向后兼容。 OpenGL ES 3.0于2012年发布，提供了多个渲染目标，纹理压缩，变换反馈，实例化，更广泛的纹理格式和模式以及着色器语言改进等功能。 OpenGL ES 3.1添加了计算着色器，而3.2添加了几何和曲面细分着色器，以及其他功能。第23章将更详细地讨论移动设备架构。

​		OpenGL ES的一个分支是基于浏览器的API WebGL，可通过JavaScript调用。该API的第一版于2011年发布，可在大多数移动设备上使用，因为它的功能等效于OpenGL ES 2.0。与OpenGL一样，扩展允许访问更高级的GPU功能。 WebGL 2假定支持OpenGL ES 3.0。

​		WebGL特别适合在教室中试用功能或使用：

* 它是跨平台的，可在所有个人计算机和几乎所有移动设备上使用。
* 驱动程序批准由浏览器处理。即使一个浏览器不支持特定的GPU或扩展，通常另一个浏览器也支持。
* 代码被解释而不是编译，并且仅需要文本编辑器即可进行开发。
* 大多数浏览器都内置了调试器，可以检查在任何网站上运行的代码。
* 可以通过将程序上传到网站或Github来进行部署。

​		更高级别的场景图形和效果库（例如three.js [218]）使您可以轻松访问代码，以获取各种更复杂的效果，例如阴影算法，后处理效果，基于物理的阴影和延迟渲染。

### 3.5顶点着色器

​		顶点着色器是图3.2所示功能管线中的第一阶段。虽然这是直接在程序员控制下的第一阶段，但值得注意的是，一些数据操作在此阶段之前发生。在DirectX所谓的输入汇编器[175、530、1208]中，可以将几个数据流编织在一起，以形成沿管道发送的一组顶点和图元。例如，一个对象可以由一个位置阵列和一个颜色阵列表示。输入汇编器将通过创建具有位置和颜色的顶点来创建此对象的三角形（或直线或点）。第二个对象可以使用相同的位置数组（以及不同的模型转换矩阵）和不同的颜色数组表示。数据表示将在16.4.5节中详细讨论。输入汇编器中也支持执行实例化。这允许一个对象被绘制多次，每个实例具有一些不同的数据，所有这些都可以通过一个绘制调用进行。第18.4.2节介绍了实例化的使用。

​		三角形网格由一组顶点表示，每个顶点与模型表面上的特定位置相关联。除了位置之外，每个顶点还有其他可选属性，例如颜色或纹理坐标。曲面法线也定义在网格顶点上，这似乎是一个奇怪的选择。从数学上讲，每个三角形都有一个定义明确的表面法线，直接将三角形的法线用于阴影似乎更有意义。但是，渲染时，通常使用三角形网格来表示基础曲面，而使用顶点法线来表示该表面的方向，而不是三角形网格本身的方向。 16.3.4节将讨论计算顶点法线的方法。图3.7显示了两个三角形网格的侧视图，这些三角形网格代表曲面，一个是平滑的，另一个是带有锐利折痕的三角形。

​		顶点着色器是处理三角形网格的第一阶段。顶点着色器无法获得描述形成三角形的数据。顾名思义，它专门处理传入的顶点。顶点着色器提供了一种修改，创建或忽略与每个三角形的顶点关联的值的方法，例如其颜色，法线，纹理坐标和位置。通常，顶点着色器程序会将顶点从模型空间转换为同构剪辑空间（第4.7节）。顶点着色器至少必须始终输出此位置。

![1569425413580](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425413580.png)

​		<font size=2>图3.7。三角形曲面（黑色，具有顶点法线）的侧视图，代表曲面（红色）。在左侧，平滑的顶点法线用于表示平滑表面。在右侧，中间顶点已被复制并指定了两个法线，表示折痕。</font>

​		顶点着色器与前面描述的统一着色器几乎相同。传入的每个顶点都由顶点着色器程序处理，该程序然后输出在三角形或直线上内插的多个值。顶点着色器既不能创建也不能破坏顶点，并且一个顶点生成的结果不能传递到另一个顶点。由于每个顶点都是独立处理的，因此可以将GPU上任意数量的着色器处理器并行应用于传入的顶点流。

​		输入汇编通常表示为在执行顶点着色器之前发生的过程。这是一个物理模型通常与逻辑模型不同的示例。从物理上讲，获取数据以创建顶点的操作可能发生在顶点着色器中，并且驱动程序将悄悄地为每个着色器添加适当的指令，这些指令对于程序员是不可见的。

​		接下来的章节介绍了几种顶点着色器效果，例如用于动画关节的顶点混合和轮廓渲染。顶点着色器的其他用途包括：

  * 对象生成，通过仅创建一次网格并使其由顶点着色器变形即可。

  * 使用蒙皮和变形技术对角色的身体和面部进行动画处理。

  * 程序变形，例如旗帜，布料或水的移动[802，943]。

  * 通过发送退化的（无区域）网格沿管道生成粒子，并根据需要为其分配区域。

  * 通过将整个帧缓冲区的内容用作经过屏幕变形的屏幕对齐网格上的纹理，可以使镜头变形，热雾，水波纹，页面卷曲和其他效果。

  * 通过使用顶点纹理获取[40，1227]应用地形高度场。 


​		使用顶点着色器完成的一些变形如图3.8所示。

​		顶点着色器的输出可以通过几种不同的方式使用。然后为每个实例的图元（例如三角形）生成常用路径，并对其进行栅格化，生成的各个像素片段将发送到像素着色器程序以进行继续处理。在某些GPU上，数据也可以发送到细分阶段或几何着色器，或存储在内存中。这些可选
以下各节将讨论这些阶段。

![1569425434435](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425434435.png)

​		<font size=2>图3.8。左边是一个普通的茶壶。由顶点着色器程序执行的简单剪切操作将生成中间图像。在右侧，噪声函数会创建一个使模型失真的字段。 （图像由FX Composer 2制作，由NVIDIA Corporation提供。）</font>

### 3.6曲面细分阶段

​		细分阶段允许我们渲染曲面。 GPU的任务是获取每个表面描述，并将其变成一组代表性的三角形。此阶段是可选的GPU功能，该功能首先在DirectX 11中可用（并且是DirectX 11所必需的）。OpenGL4.0和OpenGL ES 3.2也支持该功能。

​		使用细分阶段有几个优点。曲面描述通常比提供相应的三角形本身更紧凑。除了节省内存外，此功能还可以防止CPU和GPU之间的总线成为其形状在改变每一帧的动画角色或对象的瓶颈。通过为给定视图生成适当数量的三角形，可以有效地渲染表面。例如，如果一个球远离相机，则仅需要几个三角形。近距离观察时，最好用数千个三角形来表示。这种控制细节水平的能力还可以使应用程序控制其性能，例如，在较弱的GPU上使用较低质量的网格以保持帧速率。通常用平坦表面表示的模型可以转换为三角形的细网格，然后根据需要进行变形[1493]，或者可以对其进行细分，以便更不频繁地执行昂贵的阴影计算[225]。

​		细分阶段始终由三个元素组成。使用DirectX的术语，它们是船体着色器，细分和域着色器。在OpenGL中，外壳着色器是曲面细分控制着色器，而域着色器是曲面细分评估着色器，虽然较为冗长，但更具描述性。固定功能细分器在OpenGL中称为原始生成器，并且可以看到，确实是它的功能。

​		在第17章中详细讨论了如何指定和细分曲面和曲线。在此，我们简要概述了每个细分阶段的目的。首先，外壳着色器的输入是一个特殊的补丁原语。它由几个控制点组成，这些控制点定义了细分曲面，贝泽尔面片或其他类型的弯曲元素。外壳着色器具有两个功能。首先，它告诉镶嵌器应生成多少个三角形以及采用哪种配置。其次，它对每个控制点执行处理。同样，可选地，外壳着色器可以修改传入的补丁说明，根据需要添加或删除控制点。船体着色器将其控制点集以及细分控制数据输出到域着色器。参见图3.9。

![1569425459428](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425459428.png)

​		<font size=2>图3.9。细分阶段。外壳着色器采用由控制点定义的补丁。它将细分因子（TF）和类型发送给固定功能细分器。控制点集由外壳着色器根据需要进行转换，并与TF和相关的修补程序常量一起发送到域着色器。镶嵌对象将创建一组顶点及其重心坐标。然后由域着色器对其进行处理，从而生成三角形网格（显示控制点以供参考）。</font>

​		镶嵌细分是管线中的固定功能阶段，仅与镶嵌细分着色器一起使用。它的任务是为域着色器添加多个新顶点以进行处理。船体着色器向镶嵌器发送有关所需镶嵌曲面类型的信息：三角形，四边形或等值线。等值线是线带的集合，有时用于毛发渲染[1954]。船体着色器发送的其他重要值是细分因子（OpenGL中的细分级别）。它们有两种类型：内边缘和外边缘。这两个内部因素决定了三角形或四边形内部发生了多少细分。外部因素决定每个外部边缘被分割多少（第17.6节）。图3.10显示了增加镶嵌因子的示例。通过允许使用单独的控件，我们可以使相邻曲面的边缘在镶嵌中匹配，而无论内部如何镶嵌。匹配的边缘可避免在补丁相遇之处出现裂缝或其他阴影瑕疵。为顶点分配了重心坐标（第22.8节），这些值指定了所需表面上每个点的相对位置。

​		船体着色器始终输出补丁，一组控制点位置。但是，它可以通过向镶嵌器发送零或更低（或非数字，NaN）的外部镶嵌水平来发出信号，表示将要丢弃补丁。否则，镶嵌器将生成网格并将其发送到域着色器。域着色器的每次调用都使用来自外壳着色器的曲面的控制点，以计算每个顶点的输出值。域着色器具有类似于顶点着色器的数据流模式，来自镶嵌细分器的每个输入顶点都经过处理并生成相应的输出顶点。然后将形成的三角形沿管道向下传递。

![1569425478635](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425478635.png)

​		<font size=2>图3.10。改变镶嵌因子的效果。犹他州茶壶由32个小块组成。从左到右的内部和外部镶嵌因子分别为1、2、4和8（Rideout和Van Gelder [1493]通过演示生成的图像。）</font>

​		尽管此系统听起来很复杂，但为提高效率而采用这种结构，每个着色器可能都非常简单。传递到船体着色器中的修补程序通常很少或根本不做修改。该着色器还可以使用补丁的估计距离或屏幕大小来动态计算镶嵌因子，就像地形渲染一样[466]。或者，外壳着色器可以简单地为应用程序计算和提供的所有修补程序传递一组固定的值。镶嵌器执行一个涉及但固定功能的过程，生成顶点，为其指定位置并指定它们形成的三角形或直线。此数据放大步骤是在着色器外部执行的，以提高计算效率[530]。域着色器采用为每个点生成的重心坐标，并在补丁的评估方程式中使用这些坐标，以生成位置，法线，纹理坐标以及所需的其他顶点信息。有关示例，请参见图3.11。

![1569425494925](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425494925.png)

​		<font size=2>图3.11。左侧是大约6000个三角形的基础网格。在右侧，使用PN三角形细分细分每个三角形并进行置换。 （图像由NVIDIA公司提供，来自NVIDIA SDK 11 [1301]的示例，由4A Games提供的Metro 2033型号。）</font>

![1569425512835](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425512835.png)

​		<font size=2>图3.12。几何着色器程序的几何着色器输入为某些单一类型：点，线段，三角形。最右边的两个图元包括与直线和三角形对象相邻的顶点。更精细的补丁类型是可能的。</font>

### 3.7几何着色器

​		几何着色器可以将图元转换为其他图元，这是销售阶段无法做到的。例如，可以通过让每个三角形创建线边缘，将三角形网格转换为线框视图。或者，可以将这些线替换为面向观察者的四边形，从而使线框渲染的边缘更粗[1492]。几何着色器是在2006年底随DirectX 10发行版添加到硬件加速的图形管道中的。它位于管道中的细分着色器之后，并且可以选择使用。虽然是Shader Model 4.0的必需部分，但在较早的着色器模型中未使用它。 OpenGL 3.2和OpenGL ES 3.2也支持这种类型的着色器。

​		几何着色器的输入是单个对象及其关联的顶点。对象通常由带状，线段或简单点中的三角形组成。扩展的图元可以由几何着色器定义和处理。特别是，可以传入三角形外部的三个附加顶点，并且可以使用折线上的两个相邻顶点。参见图3.12。使用DirectX 11和Shader Model 5.0，您可以传入多达32个控制点的更精细的补丁程序。也就是说，细分阶段对于补丁生成更有效[175]。

​		几何着色器处理该图元并输出零个或多个顶点，这些顶点被视为点，折线或三角形带。请注意，几何着色器根本无法生成任何输出。通过这种方式，可以通过编辑顶点，添加新图元以及删除其他图元来选择性地修改网格。

​		几何着色器设计用于修改传入的数据或制作有限数量的副本。例如，一种用途是生成六个转换后的数据副本，以同时渲染立方体贴图的六个面；参见第10.4.3节。它也可以用来有效地创建级联的阴影贴图，以生成高质量的阴影。利用几何着色器的其他算法包括从点数据创建尺寸可变的粒子，沿着轮廓拉伸鳍以进行毛发渲染，以及为阴影算法找到对象边缘。有关更多示例，请参见图3.13。这些和其他用途将在本书的其余部分中讨论。

​		DirectX 11增加了几何着色器使用实例化的功能，其中几何着色器可以在任何给定的图元上运行设定的次数[530，1971]。在OpenGL 4.0中，这是通过调用计数指定的。几何着色器最多也可以输出四个流。可以在渲染管道上发送一个流以进行进一步处理。所有这些流都可以选择发送到流输出渲染目标。

![1569425554991](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425554991.png)

​		<font size=2>图3.13。几何着色器（GS）的某些用途。在左侧，使用GS快速进行元球等值面细分。在中间，使用GS完成线段的分形细分并将其输出，而GS生成广告牌以显示闪电。在右侧，通过使用流出的顶点和几何着色器执行布料模拟。 （图片来自NVIDIA SDK 10 [1300]示例，由NVIDIA Corporation提供。）</font>

​		保证几何着色器以与输入相同的顺序从图元输出结果。这会影响性能，因为如果多个着色器内核并行运行，则必须保存和排序结果。此因素和其他因素不利于在单个调用中用于复制或创建大量几何图形的几何着色器[175，530]。

​		发出绘制调用后，管线中只有三个位置可以在GPU上创建工作：栅格化，细分阶段和几何体着色器。其中，考虑到所需的资源和内存，几何着色器的行为是最不可预测的，因为它是完全可编程的。实际上，几何着色器通常用很少，因为它无法很好地映射到GPU的优势。在某些移动设备上，它是通过软件实现的，因此在此积极地建议不要使用它[69]。

#### 3.7.1流输出

​		GPU管道的标准用法是通过顶点着色器发送数据，然后栅格化生成的三角形并在像素着色器中进行处理。过去，总是通过管道传递数据，而中间结果无法访问。流输出的想法是在Shader Model 4.0中引入的。在顶点着色器（以及可选的细分和几何着色器）处理了顶点之后，除了可以发送到栅格化阶段之外，还可以将它们输出到流（即有序数组）中。实际上，光栅化可以完全关闭，然后将流水线纯粹用作非图形流处理器。可以将通过这种方式处理的数据通过管道发送回去，从而允许进行迭代处理。如第13.8节所述，这种类型的操作可用于模拟流水或其他粒子效果。它也可以用于为模型蒙皮，然后使这些顶点可重复使用（第4.4节）。

​		流输出仅以浮点数的形式返回数据，因此可能会产生明显的内存开销。流输出在图元上起作用，而不是在顶点上起作用。如果将网格沿管道发送，则每个三角形将生成自己的三个输出顶点集。原始网格中共享的所有顶点都将丢失。因此，更典型的用法是仅通过管道将顶点发送为点集图元。在OpenGL中，流输出阶段称为变换反馈，因为它的大部分使用重点是变换顶点并将其返回以进行进一步处理。保证按输入顺序将基元发送到流输出目标，这意味着将保持顶点顺序[530]。

### 3.8像素着色器

​		顶点，曲面细分和几何体着色器执行完操作后，便会裁剪并设置图元以进行栅格化，如上一章所述。流水线的这一部分在其处理步骤中是相对固定的，即，不是可编程的，而是有些可配置的。遍历每个三角形以确定其覆盖哪些像素。光栅化器还可以粗略计算出三角形覆盖每个像素的像元区域的数量（第5.4.2节）。部分或完全重叠像素的三角形称为片段。

​		三角形顶点的值（包括z缓冲区中使用的z值）将在每个像素的三角形表面上插值。这些值将传递到像素着色器，然后由该着色器处理片段。在OpenGL中，像素着色器称为片段着色器，这也许是一个更好的名称。为了保证一致性，我们在本书中始终使用“像素着色器”。沿管线发送的点和线图元也会为所覆盖的像素创建片段。

​		跨整个三角形执行的插值类型由像素着色器程序指定。通常，我们使用透视校正内插法，以使像素表面位置之间的世界空间距离随着对象后退距离的增加而增加。一个示例是渲染延伸到地平线的铁轨。铁轨在铁轨较远的地方间距更近，因为每个接近地平线的连续像素行进的距离都更大。其他插值选项也可用，例如屏幕空间插值，其中不考虑透视投影。 DirectX 11进一步控制何时以及如何执行插值[530]。

​		用编程术语来说，顶点着色器程序的输出（插在三角形（或线）上）实际上成为像素着色器程序的输入。随着GPU的发展，其他输入也已公开。例如，片段的屏幕位置可用于Shader Model 3.0及更高版本中的像素着色器。同样，三角形的哪一侧可见是输入标志。该知识对于一次通过每个三角形的正面和背面渲染不同的材质非常重要。

![1569425576993](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425576993.png)

​		<font size=2>图3.14。用户定义的剪切平面。在左侧，单个水平裁剪平面将对象切片。在中间，嵌套球被三个平面修剪。在右侧，仅当球体的曲面在所有三个剪切平面的外部时，才对其进行剪切。 （来自Three.js示例中的webgl剪切和webgl剪切交集[218]。）</font>

​		有了输入，通常像素着色器会计算并输出片段的颜色。它还可能会产生不透明度值，并可以选择修改其z深度。在合并期间，这些值用于修改存储在像素处的内容。光栅化阶段生成的深度值也可以由像素着色器修改。模板缓冲区值通常是不可修改的，而是传递到合并阶段。 DirectX 11.3允许着色器更改此值。雾计算和Alpha测试等操作已从合并操作转变为成为SM 4.0中的像素着色器计算[175]。

​		像素着色器还具有丢弃传入片段（即不产生任何输出）的独特功能。图3.14显示了如何使用碎片丢弃的一个示例。剪切平面功能以前是固定功能管道中的可配置元素，后来在顶点着色器中指定。有了片段丢弃功能之后，就可以用像素着色器中所需的任何方式来实现此功能，例如确定剪切量应进行“与”运算还是“或”运算。

​		最初，像素着色器只能输出到合并阶段，以进行最终显示。随着时间的推移，像素着色器可以执行的指令数量已大大增加。这种增加引起了多个渲染目标（MRT）的想法。不仅可以将像素着色器程序的结果仅发送到颜色和z缓冲区，还可以为每个片段生成多组值并将其保存到不同的缓冲区，每个缓冲区称为渲染目标。渲染目标通常具有相同的x和y维度；一些API允许使用不同的大小，但是渲染区域将是其中最小的。一些架构要求渲染目标必须具有相同的位深，甚至可能具有相同的数据格式。取决于GPU，可用的渲染目标数量为四个或八个。

​		即使有这些限制，MRT功能还是更有效地执行渲染算法的有力辅助。一次渲染过程可以在一个目标中生成彩色图像，在另一个目标中生成对象标识符，在第三个目标中生成世界空间距离。此功能还引起了另一种类型的渲染管道，称为延迟着色，其中可见性和着色是在单独的通道中完成的。第一遍存储有关每个像素处对象位置和材质的数据。然后，连续通过可以有效地施加照明和其他效果。此类渲染方法在第20.1节中进行了描述。

​		像素着色器的局限性在于，它通常只能在传递给目标的片段位置上写入渲染目标，而不能从相邻像素读取当前结果。也就是说，执行像素着色器程序时，它无法将其输出直接发送到相邻像素，也无法访问其他人的最新更改。而是，它计算仅影响其自身像素的结果。但是，此限制并不像听起来那样严重。一次通过创建的输出图像可以让像素着色器在后续通过中访问其任何数据。可以使用第12.1节中所述的图像处理技术来处理相邻像素。

​		像素着色器无法了解或影响相邻像素的结果的规则是有例外的。一种是像素着色器可以在计算梯度或导数信息时立即访问相邻片段的信息（尽管是间接的）。像素着色器具有沿x和y屏幕轴每个像素的任何插值变化的量。这些值可用于各种计算和纹理寻址。这些梯度对于诸如纹理过滤（第6.2.2节）之类的操作尤为重要，因为我们想知道多少图像覆盖了一个像素。所有现代GPU都通过以2×2为一组处理片段（称为四边形）来实现此功能。当像素着色器请求梯度值时，将返回相邻片段之间的差异。参见图3.15。统一核心具有访问相邻数据（保留在同一扭曲中的不同线程中）的功能，因此可以计算用于像素着色器的渐变。此实现的一个结果是，无法在受动态流控制影响的着色器的某些部分（例如，“ if”语句或具有可变迭代次数的循环）中访问渐变信息。一组中的所有片段都必须使用相同的指令集进行处理，以便所有四个像素的结果对于计算梯度都是有意义的。这是一个基本限制，即使在脱机渲染系统中也存在[64]。

​		DirectX 11引入了一种缓冲区类型，该类型允许对任何位置（无序访问视图（UAV））的写访问。最初仅适用于像素和计算着色器，对UAV的访问已扩展到DirectX 11.1中的所有着色器[146]。 OpenGL 4.3将此称为着色器存储缓冲区对象（SSBO）。这两个名称以其自己的方式进行描述。像素着色器以任意顺序并行运行，并且此存储缓冲区在它们之间共享。

​		通常需要某种机制来避免数据竞争情况（也称为数据危险），在这种情况下，两个着色器程序都在“竞相”以影响相同的值，从而可能导致任意结果。例如，如果两次调用像素着色器试图在大约同一时间将其添加到相同的检索值中，则可能会发生错误。两者都将检索原始值，都将在本地对其进行修改，但是，无论哪个调用最后写入其结果，都将抹去另一个调用的作用，只会发生一次添加。 GPU通过使用着色器可以访问的专用原子单元来避免此问题[530]。但是，原子意味着某些着色器可能在等待访问另一个着色器进行读/修改/写操作的存储位置时停滞。

![1569425601443](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425601443.png)

​		<font size=2>图3.15。在左侧，将三角形栅格化为四边形，每组2×2像素。然后，在右侧显示了带有黑点标记的像素的梯度计算。针对四边形中四个像素位置的每一个，显示了v的值。请注意，三角形中没有覆盖三个像素，但是GPU仍对其进行处理，以便可以找到渐变。通过使用左下像素的两个四边形邻居，可以计算出x和y屏幕方向上的渐变。</font>

​		尽管原子避免了数据危害，但许多算法都需要特定的执行顺序。例如，您可能需要绘制一个更远的透明蓝色三角形，然后再用红色透明三角形覆盖它，将红色混合在蓝色上面。一个像素可能对一个像素进行两次像素着色器调用，每个三角形调用一次，以这样一种方式执行：红色三角形的着色器先于蓝色着色器完成。在标准管道中，片段结果将在合并阶段进行排序，然后再进行处理。在DirectX 11.3中引入了栅格化程序顺序视图（ROV）以强制执行顺序。这些就像无人机。着色器可以以相同的方式读取和写入它们。关键区别在于ROV保证以正确的顺序访问数据。这大大增加了这些着色器可访问缓冲区的有用性[327、328]。例如，ROV使像素着色器可以编写自己的混合方法，因为它可以直接访问和写入ROV中的任何位置，因此不需要合并阶段[176]。代价是，如果检测到乱序访问，像素着色器调用可能会停顿，直到处理了先前绘制的三角形。

### 3.9合并阶段

​		如第2.5.2节所述，合并阶段是将各个片段（在像素着色器中生成）的深度和颜色与帧缓冲区组合在一起。 DirectX将此阶段称为输出合并； OpenGL将其称为每个样本的操作。在大多数传统管线图（包括我们自己的管线图）上，此阶段是模具缓冲区和z缓冲区操作发生的地方。如果片段可见，则此阶段中发生的另一种操作是颜色混合。对于不透明的表面，不涉及真正的混合，因为片段的颜色会简单地替换以前存储的颜色。片段和所存储颜色的实际混合通常用于透明度和合成操作（第5.5节）。

​		想象一下，通过光栅化生成的片段通过像素着色器运行，然后在应用z缓冲区时被某些先前渲染的片段隐藏。这样就不需要在像素着色器中进行所有处理。为了避免这种浪费，许多GPU在执行像素着色器之前执行一些合并测试[530]。片段的z深度（以及其他正在使用的东西，例如模板缓冲区或剪刀）用于测试可见性。如果隐藏该片段，则将其剔除。此功能称为Early-z [1220，1542]。像素着色器具有更改片段的z深度或完全丢弃片段的能力。如果发现像素着色器程序中存在这两种类型的操作，则通常无法使用Early-Z，然后通常将其关闭，这通常会使管线效率降低。 DirectX 11和OpenGL 4.2允许像素着色器强制进行Early-Z测试，尽管有很多限制[530]。有关早期z和其他z缓冲区优化的更多信息，请参见第23.7节。有效使用Early-z会对性能产生很大影响，这将在18.4.5节中详细讨论。

​		合并阶段占据了固定功能阶段（例如三角形设置）和完全可编程着色器阶段之间的中间地带。尽管它不是可编程的，但它的操作是高度可配置的。可以将颜色混合设置为执行大量不同的操作。最常见的是涉及颜色和Alpha值的乘法，加法和减法的组合，但是其他操作（例如最小值和最大值）以及按位逻辑运算也是可能的。 DirectX 10添加了将像素着色器中的两种颜色与帧缓冲区颜色混合的功能。此功能称为双源颜色混合，不能与多个渲染目标一起使用。 MRT否则支持混合，DirectX 10.1引入了在每个单独的缓冲区上执行不同混合操作的功能。

​		如上一节末尾所述，DirectX 11.3提供了一种通过ROV进行混合编程的方法，尽管这是以性能为代价的。 ROV和合并阶段都保证了绘制顺序，也就是输出不变性。不管生成像素着色器结果的顺序如何，API要求都按照输入结果的顺序（对象，对象和三角形，以及三角形）对结果进行排序并将其发送到合并阶段。

### 3.10计算着色器

​		除了实现传统的图形管线外，GPU还可以用于更多用途。在计算领域，有许多非图形用途，例如计算股票期权的估计价值和训练用于深度学习的神经网络。以这种方式使用硬件称为GPU计算。诸如CUDA和OpenCL之类的平台可作为大型并行处理器来控制GPU，而无需真正的需求或访问特定于图形的功能。这些框架通常使用带有扩展功能的C或C ++等语言以及为GPU制作的库。

​		DirectX 11中引入了计算着色器，它是GPU计算的一种形式，因为它是未锁定在图形管线中某个位置的着色器。它与渲染过程紧密相关，因为它由图形API调用。它与顶点，像素和其他着色器一起使用。它使用与管道中使用的统一着色器处理器池相同的池。与其他着色器一样，它是着色器，因为它具有一组输入数据，并且可以访问缓冲区（例如纹理）以进行输入和输出。扭曲和线程在计算着色器中更明显。例如，每个调用都会获取一个可以访问的线程索引。还有一个线程组的概念，它由DirectX 11中的1到1024个线程组成。这些线程组由x，y和z坐标指定，主要是为了简化在着色器代码中的使用。每个线程组都有少量的内存，这些内存在线程之间共享。在DirectX 11中，这等于32 kB。计算着色器由线程组执行，因此保证该组中的所有线程可以同时运行[1971]。

​		计算着色器的一个重要优点是它们可以访问在GPU上生成的数据。从GPU向CPU发送数据会产生延迟，因此如果可以将处理和结果保留在GPU上，则可以提高性能[1403]。在后期处理中，以某种方式修改了渲染的图像，这是计算着色器的常见用法。共享内存意味着来自采样图像像素的中间结果可以与相邻线程共享。例如，已经发现使用计算着色器确定图像的分布或平均亮度的运行速度是在像素着色器上执行此操作的两倍[530]。

​		计算着色器还可用于粒子系统，网格处理（例如面部动画[134]，剔除[1883、1884]，图像过滤[1102、1710]，提高深度精度[991]，阴影[865]，景深[ 764]，以及可以承担一组GPU处理器的任何其他任务。 Wihlidal [1884]讨论了计算着色器如何比曲面细分船体着色器更有效。其他用途请参见图3.16。

​		至此，我们对GPU的渲染管线实现的审查结束了。有多种方法可以使用和组合GPU功能来执行各种与渲染相关的过程。调整以利用这些功能的相关理论和算法是本书的重点。现在，我们将重点放在变换和着色上。

![1569425627411](C:\Users\tionerter\AppData\Roaming\Typora\typora-user-images\1569425627411.png)

​		<font size=2>图3.16。计算着色器示例。左侧是计算着色器，用于模拟受风影响的头发，并使用细分阶段渲染头发本身。在中间，计算着色器执行快速模糊操作。在右侧，模拟了海浪。 （图像来自NVIDIA SDK 11 [1301]示例，由NVIDIA Corporation提供。）</font>

### 进一步阅读和资源

​		吉森（Giesen）的图形管道之旅[530]详细讨论了GPU的许多方面，并解释了元素为何以它们的方式工作。 Fatahalian和Bryant的课程[462]在一系列详细的讲义幻灯片集中讨论了GPU并行性。尽管着眼于使用CUDA进行GPU计算，但Kirk和Hwa的书[903]的介绍部分讨论了GPU的发展和设计理念。

​		要学习着色器编程的形式方面，需要花费一些工作。诸如OpenGL Superbible [1606]和OpenGL Programming Guide [885]之类的书都包含有关着色器编程的材料。旧书OpenGL Shading Language [1512]没有涵盖较新的着色器阶段，例如几何和细分着色器，但确实专注于与着色器相关的算法。有关最新和推荐的图书，请参见本书的网站realtimerendering.com。





​		



​			

​							

​    

​    

​    

## 4.变换

## 5.着色基础

## 6.纹理

## 7.阴影

## 8.光和颜色

## 9.基于物理的着色

## 10.局部光照

## 11.全局光照

## 12.图像空间特效

## 13.超越多边形

## 14.体积和半透明渲染

## 15.非真实图像渲染

## 17.曲线和曲面

## 18管线优化

## 19.加速算法

## 20.高效着色

## 21.虚拟现实和增强现实

## 22.交叉测试方法

## 23.图形硬件



